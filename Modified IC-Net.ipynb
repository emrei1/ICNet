{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9ocu0d9T8fF",
        "outputId": "aa19a73f-5ac4-43b8-c624-3160f6401baf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ui7wo3eSVLa",
        "outputId": "aeff1703-70ff-4b73-f8f1-587c1b3477c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSRbKkGbSEiY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "b8fd77127a6146e1aafe6c6b0d31b8c1",
            "567e8cbb8a264147ba7b899f588299a4",
            "81ffcf3cf49b4e2c8cd58194e32f3c3e",
            "f77f89096d594bdb9477e4298653a6a0",
            "b69bd6dbba7c41519f5427ae4055c36e",
            "3d1ce70b87114c8e903b109b76ac4b74",
            "4c2fc700d9e544f4a3534ce6fadb2392",
            "3efb2228a0ff4fb8ac35136cd8c337ac",
            "22ab8e9bde6e427eb622fca0bc0055a5",
            "88ad27a0bd714772933961ec28b062ff",
            "3bd00ffe85ab47eab01c9a56385293a5"
          ]
        },
        "outputId": "7e1cf51d-5914-4173-9eb8-5ba06b84bf66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b8fd77127a6146e1aafe6c6b0d31b8c1"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from torchvision.models import resnet18, resnet34, resnet50, resnet101, resnet152\n",
        "\n",
        "from torchvision.models import ResNet18_Weights, ResNet34_Weights, ResNet50_Weights, ResNet101_Weights, ResNet152_Weights\n",
        "\n",
        "base_model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKLr58eETEgB"
      },
      "source": [
        "# RESNET FIRST PASSES THROUGH HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tX1OJ4qNlD4H"
      },
      "outputs": [],
      "source": [
        "\"\"\"Base Model for Semantic Segmentation\"\"\"\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "__all__ = ['SegBaseModel']\n",
        "\n",
        "class SegBaseModel(nn.Module):\n",
        "    \"\"\"Base Model for Semantic Segmentation\n",
        "    Parameters\n",
        "    ----------\n",
        "    backbone : string\n",
        "        Pre-trained dilated backbone network type (default:'resnet50'; 'resnet50',\n",
        "        'resnet101' or 'resnet152').\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, nclass, backbone='resnet50', pretrained_base=True, **kwargs):\n",
        "        super(SegBaseModel, self).__init__()\n",
        "        dilated = True # Not used.\n",
        "        self.nclass = nclass\n",
        "        if backbone == 'resnet18':\n",
        "          self.pretrained = base_model\n",
        "        elif backbone == 'resnet34':\n",
        "          self.pretrained = base_model\n",
        "        elif backbone == 'resnet50':\n",
        "          self.pretrained = base_model\n",
        "        elif backbone == 'resnet101':\n",
        "          self.pretrained = base_model\n",
        "        elif backbone == 'resnet152':\n",
        "          self.pretrained = base_model\n",
        "        else:\n",
        "            raise RuntimeError('unknown backbone: {}'.format(backbone))\n",
        "\n",
        "    def base_forward(self, x):\n",
        "        \"\"\"forwarding pre-trained network\"\"\"\n",
        "        x = self.pretrained.conv1(x)\n",
        "        x = self.pretrained.bn1(x)\n",
        "        x = self.pretrained.relu(x)\n",
        "        x = self.pretrained.maxpool(x)\n",
        "        c1 = self.pretrained.layer1(x)\n",
        "        c2 = self.pretrained.layer2(c1)\n",
        "        c3 = self.pretrained.layer3(c2)\n",
        "        c4 = self.pretrained.layer4(c3)\n",
        "        \n",
        "        return c1, c2, c3, c4\n",
        "\n",
        "    def evaluate(self, x):\n",
        "        \"\"\"evaluating network with inputs and targets\"\"\"\n",
        "        return self.forward(x)[0]\n",
        "\n",
        "    def demo(self, x):\n",
        "        pred = self.forward(x)\n",
        "        return pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59AdArZxTKkB"
      },
      "source": [
        "# ICNET MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUCFOh_2k3nO"
      },
      "outputs": [],
      "source": [
        "\"\"\"Image Cascade Network\"\"\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#from .segbase import SegBaseModel\n",
        "from torchsummary import summary\n",
        "\n",
        "__all__ = ['ICNet', 'get_icnet', 'get_icnet_resnet50_citys',\n",
        "           'get_icnet_resnet101_citys', 'get_icnet_resnet152_citys']\n",
        "\n",
        "class ICNet(SegBaseModel):\n",
        "    \"\"\"Image Cascade Network\"\"\"\n",
        "    \n",
        "    def __init__(self, nclass = 19, backbone='resnet50', pretrained_base=True):\n",
        "        super(ICNet, self).__init__(nclass,backbone, pretrained_base=pretrained_base)\n",
        "        self.conv_sub1 = nn.Sequential(\n",
        "            _ConvBNReLU(3, 32, 3, 2),#_ConvBNReLU(3, 128, 3, 2),  #in,out,kernel_size,stride\n",
        "            _ConvBNReLU(32, 32, 3, 2),#_ConvBNReLU(128, 128, 3, 2),\n",
        "            _ConvBNReLU(32, 64, 3, 2)#_ConvBNReLU(128, 64, 3, 2)\n",
        "        )\n",
        "        \n",
        "        self.ppm = PyramidPoolingModule()\n",
        "\n",
        "        self.head = _ICHead(nclass, backbone)\n",
        "\n",
        "        self.__setattr__('exclusive', ['conv_sub1', 'head'])\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # sub 1\n",
        "        x_sub1 = self.conv_sub1(x)\n",
        "\n",
        "        # sub 2\n",
        "        x_sub2 = F.interpolate(x, scale_factor=0.5, mode='bilinear', align_corners=True) # scale_factor = 0.5\n",
        "        _, x_sub2, _, _ = self.base_forward(x_sub2)\n",
        "        \n",
        "        # sub 4\n",
        "        x_sub4 = F.interpolate(x, scale_factor=0.25, mode='bilinear', align_corners=True) # scale_factor = 0.25\n",
        "        _, _, _, x_sub4 = self.base_forward(x_sub4)\n",
        "        # add PyramidPoolingModule\n",
        "        x_sub4 = self.ppm(x_sub4)\n",
        "        \n",
        "        outputs = self.head(x_sub1, x_sub2, x_sub4)\n",
        "\n",
        "\n",
        "\n",
        "        \n",
        "        return tuple(outputs)\n",
        "\n",
        "class PyramidPoolingModule(nn.Module):\n",
        "\tdef __init__(self, pyramids=[1,2,3,6]):\n",
        "\t\tsuper(PyramidPoolingModule, self).__init__()\n",
        "\t\tself.pyramids = pyramids\n",
        "\n",
        "\tdef forward(self, input):\n",
        "\t\tfeat = input\n",
        "\t\theight, width = input.shape[2:]\n",
        "\t\tfor bin_size in self.pyramids:\n",
        "\t\t\tx = F.adaptive_avg_pool2d(input, output_size=bin_size)\n",
        "\t\t\tx = F.interpolate(x, size=(height, width), mode='bilinear', align_corners=True)\n",
        "\t\t\tfeat  = feat + x\n",
        "\t\treturn feat\n",
        "    \n",
        "class _ICHead(nn.Module):\n",
        "    def __init__(self, nclass, backbone='resnet50', norm_layer=nn.BatchNorm2d, **kwargs):\n",
        "        super(_ICHead, self).__init__()\n",
        "        if backbone == 'resnet18':\n",
        "          #self.cff_12 = CascadeFeatureFusion(128, 64, 128, nclass, norm_layer, **kwargs) # For ResNet-50 and bigger\n",
        "          self.cff_12 = CascadeFeatureFusion(128, 64, 128, nclass, norm_layer, **kwargs) # For ResNet-34 and smaller \n",
        "          #                               cff_24:out/xsub1:in/cff_12:out\n",
        "          #self.cff_24 = CascadeFeatureFusion(2048, 512, 128, nclass, norm_layer, **kwargs) # For ResNet-50 and bigger\n",
        "          self.cff_24 = CascadeFeatureFusion(512, 128, 128, nclass, norm_layer, **kwargs) # For ResNet-34 and smaller\n",
        "          #                               xsub4:in/xsub2:in/cff_24:out\n",
        "          #                               512, 128, 128, ...\n",
        "        elif backbone == 'resnet34':\n",
        "          self.cff_12 = CascadeFeatureFusion(128, 64, 128, nclass, norm_layer, **kwargs)\n",
        "          self.cff_24 = CascadeFeatureFusion(512, 128, 128, nclass, norm_layer, **kwargs)\n",
        "        elif backbone == 'resnet50':\n",
        "          self.cff_12 = CascadeFeatureFusion(128, 64, 128, nclass, norm_layer, **kwargs)\n",
        "          self.cff_24 = CascadeFeatureFusion(2048, 512, 128, nclass, norm_layer, **kwargs)\n",
        "        elif backbone == 'resnet101':\n",
        "          self.cff_12 = CascadeFeatureFusion(128, 64, 128, nclass, norm_layer, **kwargs)\n",
        "          self.cff_24 = CascadeFeatureFusion(2048, 512, 128, nclass, norm_layer, **kwargs)\n",
        "        elif backbone == 'resnet152':\n",
        "          self.cff_12 = CascadeFeatureFusion(128, 64, 128, nclass, norm_layer, **kwargs)\n",
        "          self.cff_24 = CascadeFeatureFusion(2048, 512, 128, nclass, norm_layer, **kwargs)\n",
        "        \n",
        "        self.conv_cls = nn.Conv2d(128, nclass, 1, bias=False)\n",
        "\n",
        "    def forward(self, x_sub1, x_sub2, x_sub4):\n",
        "        outputs = list()\n",
        "        x_cff_24, x_24_cls = self.cff_24(x_sub4, x_sub2)\n",
        "        outputs.append(x_24_cls)\n",
        "        # x_cff_12, x_12_cls = self.cff_12(x_sub2, x_sub1)\n",
        "        x_cff_12, x_12_cls = self.cff_12(x_cff_24, x_sub1)\n",
        "        outputs.append(x_12_cls)\n",
        "\n",
        "        up_x2 = F.interpolate(x_cff_12, scale_factor=2, mode='bilinear', align_corners=True) # scale_factor = 2\n",
        "        up_x2 = self.conv_cls(up_x2)\n",
        "        outputs.append(up_x2)\n",
        "        up_x8 = F.interpolate(up_x2, scale_factor=4, mode='bilinear', align_corners=True) # scale_factor = 4\n",
        "        outputs.append(up_x8)\n",
        "        # 1 -> 1/4 -> 1/8 -> 1/16\n",
        "        outputs.reverse()\n",
        "\n",
        "        return outputs\n",
        "\n",
        "\n",
        "class _ConvBNReLU(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, dilation=1,\n",
        "                 groups=1, norm_layer=nn.BatchNorm2d, bias=False, **kwargs):\n",
        "        super(_ConvBNReLU, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias)\n",
        "        self.bn = norm_layer(out_channels)\n",
        "        self.relu = nn.ReLU(True)#self.relu = nn.GELU()#self.relu = nn.LeakyReLU(0.05)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class CascadeFeatureFusion(nn.Module):\n",
        "    \"\"\"CFF Unit\"\"\"\n",
        "\n",
        "    def __init__(self, low_channels, high_channels, out_channels, nclass, norm_layer=nn.BatchNorm2d, **kwargs):\n",
        "        super(CascadeFeatureFusion, self).__init__()\n",
        "        self.conv_low = nn.Sequential(\n",
        "            nn.Conv2d(low_channels, out_channels, 3, padding=2, dilation=2, bias=False),\n",
        "            norm_layer(out_channels)\n",
        "        )\n",
        "        self.conv_high = nn.Sequential(\n",
        "            nn.Conv2d(high_channels, out_channels, 1, bias=False),\n",
        "            norm_layer(out_channels)\n",
        "        )\n",
        "        self.conv_low_cls = nn.Conv2d(out_channels, nclass, 1, bias=False)\n",
        "\n",
        "    def forward(self, x_low, x_high):\n",
        "        x_low = F.interpolate(x_low, size=x_high.size()[2:], mode='bilinear', align_corners=True)\n",
        "        x_low = self.conv_low(x_low)\n",
        "\n",
        "        x_high = self.conv_high(x_high)\n",
        "        x = x_low + x_high\n",
        "        x = F.relu(x, inplace=True)#x = F.gelu(x)#x = F.leaky_relu(x, 0.05,inplace=True)\n",
        "        x_low_cls = self.conv_low_cls(x_low)\n",
        "\n",
        "        return x, x_low_cls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "guT2zM_iZeuz"
      },
      "outputs": [],
      "source": [
        "# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.\n",
        "import logging\n",
        "import os\n",
        "import sys\n",
        "\n",
        "__all__ = ['SetupLogger']\n",
        "\n",
        "# reference from: https://github.com/facebookresearch/maskrcnn-benchmark/blob/master/maskrcnn_benchmark/utils/logger.py\n",
        "def SetupLogger(name, save_dir, distributed_rank, filename=\"log.txt\", mode='w'):\n",
        "    logger = logging.getLogger(name)\n",
        "    logger.setLevel(logging.DEBUG)\n",
        "    # don't log results for the non-master process\n",
        "    if distributed_rank > 0:\n",
        "        return logger\n",
        "    ch = logging.StreamHandler(stream=sys.stdout)\n",
        "    ch.setLevel(logging.DEBUG)\n",
        "    formatter = logging.Formatter(\"%(asctime)s %(name)s %(levelname)s: %(message)s\")\n",
        "    ch.setFormatter(formatter)\n",
        "    logger.addHandler(ch)\n",
        "    \n",
        "    if save_dir:\n",
        "        if not os.path.exists(save_dir):\n",
        "            os.makedirs(save_dir)\n",
        "        fh = logging.FileHandler(os.path.join(save_dir, filename), mode=mode)  # 'a+' for add, 'w' for overwrite\n",
        "        fh.setLevel(logging.DEBUG)\n",
        "        fh.setFormatter(formatter)\n",
        "        logger.addHandler(fh)\n",
        "\n",
        "    return "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jLaivAyTXdj"
      },
      "source": [
        "# TRAIN "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yUrnWiFzlYE4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import datetime\n",
        "import yaml\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "\n",
        "#from dataset import CityscapesDataset\n",
        "#from models import ICNet\n",
        "#from utils import ICNetLoss, IterationPolyLR, SegmentationMetric, SetupLogger\n",
        "\n",
        "class Trainer(object):\n",
        "    def __init__(self, cfg, load = False, loadPath = None):\n",
        "        #self.logger = logger\n",
        "        self.cfg = cfg\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.dataparallel = torch.cuda.device_count() > 1\n",
        "        self.losses = []\n",
        "        self.IoU_list = []\n",
        "        \n",
        "        # dataset and dataloader\n",
        "        train_dataset = CityscapesDataset(root = cfg[\"train\"][\"cityscapes_root\"], \n",
        "                                          split='train', \n",
        "                                          base_size=cfg[\"model\"][\"base_size\"], \n",
        "                                          crop_size=cfg[\"model\"][\"crop_size\"])\n",
        "        val_dataset = CityscapesDataset(root = cfg[\"train\"][\"cityscapes_root\"], \n",
        "                                        split='val',\n",
        "                                        base_size=cfg[\"model\"][\"base_size\"], \n",
        "                                        crop_size=cfg[\"model\"][\"crop_size\"])\n",
        "        self.train_dataloader = data.DataLoader(dataset=train_dataset,\n",
        "                                                batch_size=cfg[\"train\"][\"train_batch_size\"],\n",
        "                                                shuffle=True,\n",
        "                                                num_workers=4,\n",
        "                                                pin_memory=True,\n",
        "                                                drop_last=False)\n",
        "        self.val_dataloader = data.DataLoader(dataset=val_dataset,\n",
        "                                              batch_size=cfg[\"train\"][\"valid_batch_size\"],\n",
        "                                              shuffle=False,\n",
        "                                              num_workers=4,\n",
        "                                              pin_memory=True,\n",
        "                                              drop_last=False)\n",
        "        \n",
        "        self.iters_per_epoch = len(self.train_dataloader)\n",
        "        self.max_iters = cfg[\"train\"][\"epochs\"] * self.iters_per_epoch\n",
        "\n",
        "        # create network\n",
        "        self.model = ICNet(nclass = train_dataset.NUM_CLASS, backbone='resnet50').to(self.device) # Backbone choice made here.\n",
        "        \n",
        "        # create criterion\n",
        "        self.criterion = ICNetLoss(ignore_index=train_dataset.IGNORE_INDEX).to(self.device)\n",
        "        \n",
        "        # optimizer, for model just includes pretrained, head and auxlayer\n",
        "        params_list = list()\n",
        "        if hasattr(self.model, 'pretrained'):\n",
        "            params_list.append({'params': self.model.pretrained.parameters(), 'lr': cfg[\"optimizer\"][\"init_lr\"]})\n",
        "        if hasattr(self.model, 'exclusive'):\n",
        "            for module in self.model.exclusive:\n",
        "                params_list.append({'params': getattr(self.model, module).parameters(), 'lr': cfg[\"optimizer\"][\"init_lr\"] * 10})\n",
        "        # Base optimizer.\n",
        "        self.optimizer = torch.optim.SGD(params = self.model.parameters(),\n",
        "                                          lr = cfg[\"optimizer\"][\"init_lr\"],\n",
        "                                          momentum=cfg[\"optimizer\"][\"momentum\"],\n",
        "                                          weight_decay=cfg[\"optimizer\"][\"weight_decay\"])\n",
        "        \n",
        "        # AdamW optimizer.\n",
        "        #self.optimizer = torch.optim.AdamW(params = params_list, \n",
        "        #                                   lr = 1e-2,\n",
        "        #                                   betas = (0.9, 0.999),\n",
        "        #                                   eps = 1e-8,\n",
        "        #                                   weight_decay = 1e-2)\n",
        "\n",
        "        # Base optimizer.\n",
        "        # self.optimizer = torch.optim.SGD(params = self.model.parameters(),\n",
        "        #                                  lr = cfg[\"optimizer\"][\"init_lr\"],\n",
        "        #                                  momentum=cfg[\"optimizer\"][\"momentum\"],\n",
        "        #                                  weight_decay=cfg[\"optimizer\"][\"weight_decay\"])\n",
        "        \n",
        "        # LambdaLR scheduler.\n",
        "        #schedule_fn = lambda epoch: 0.95 ** epoch\n",
        "        #self.lr_scheduler = torch.optim.lr_scheduler.LambdaLR(self.optimizer, lr_lambda=schedule_fn)\n",
        "        \n",
        "        # base lr scheduler\n",
        "        self.lr_scheduler = IterationPolyLR(self.optimizer,\n",
        "                                            max_iters=self.max_iters,\n",
        "                                            power=0.9)\n",
        "        \n",
        "        # dataparallel\n",
        "        if(self.dataparallel):\n",
        "             self.model = nn.DataParallel(self.model)\n",
        "\n",
        "        # evaluation metrics\n",
        "        self.metric = SegmentationMetric(train_dataset.NUM_CLASS)\n",
        "\n",
        "        self.current_mIoU = 0.0\n",
        "        self.best_mIoU = 0.0\n",
        "        \n",
        "        self.epochs = cfg[\"train\"][\"epochs\"]\n",
        "        self.current_epoch = 0\n",
        "        self.current_iteration = 0\n",
        "\n",
        "        if load == True:\n",
        "          checkpoint = torch.load(load_path) ###### TODO ######\n",
        "          self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "          self.optimizer.load_state_dict(checkpoint['optim_state_dict'])\n",
        "          self.current_epoch = checkpoint['current_epoch']\n",
        "        \n",
        "    def train(self):\n",
        "        epochs, max_iters = self.epochs, self.max_iters\n",
        "        log_per_iters = self.cfg[\"train\"][\"log_iter\"]\n",
        "        val_per_iters = self.cfg[\"train\"][\"val_epoch\"] * self.iters_per_epoch\n",
        "        \n",
        "        start_time = time.time()\n",
        "        print('Start training, Total Epochs: {:d} = Total Iterations {:d}'.format(epochs, max_iters))\n",
        "        #logger.info('Start training, Total Epochs: {:d} = Total Iterations {:d}'.format(epochs, max_iters))\n",
        "        \n",
        "        self.model.train()\n",
        "        \n",
        "        for _ in range(self.epochs): \n",
        "            self.current_epoch += 1\n",
        "            lsit_pixAcc = []\n",
        "            list_mIoU = []\n",
        "            list_loss = []\n",
        "            self.metric.reset()\n",
        "            for i, (images, targets, _) in enumerate(self.train_dataloader):  \n",
        "                self.current_iteration += 1\n",
        "                \n",
        "                self.lr_scheduler.step() # Use this for the base lr scheduler.\n",
        "\n",
        "                images = images.to(self.device)\n",
        "                targets = targets.to(self.device)\n",
        "                \n",
        "                outputs = self.model(images)\n",
        "                loss = self.criterion(outputs, targets)\n",
        "\t\t\n",
        "                self.metric.update(outputs[0], targets)\n",
        "                pixAcc, mIoU = self.metric.get()\n",
        "                lsit_pixAcc.append(pixAcc)\n",
        "                list_mIoU.append(mIoU)\n",
        "                list_loss.append(loss.item())\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                eta_seconds = ((time.time() - start_time) / self.current_iteration) * (max_iters - self.current_iteration)\n",
        "                eta_string = str(datetime.timedelta(seconds=int(eta_seconds)))\n",
        "                \n",
        "                if self.current_iteration % log_per_iters == 0:\n",
        "                  print(\"Epochs: {:d}/{:d} || Iters: {:d}/{:d} || Lr: {:.6f} || Train Loss: {:.4f} || mIoU: {:.4f} || Cost Time: {} || Estimated Time: {}\".format(\n",
        "                            self.current_epoch, self.epochs, \n",
        "                            self.current_iteration, max_iters, \n",
        "                            self.optimizer.param_groups[0]['lr'], \n",
        "                            loss.item(), \n",
        "                            mIoU,\n",
        "                            str(datetime.timedelta(seconds=int(time.time() - start_time))), \n",
        "                            eta_string))\n",
        "                    #logger.info(\n",
        "                     #   \"Epochs: {:d}/{:d} || Iters: {:d}/{:d} || Lr: {:.6f} || Loss: {:.4f} || mIoU: {:.4f} || Cost Time: {} || Estimated Time: {}\".format(\n",
        "                      #      self.current_epoch, self.epochs, \n",
        "                       #     self.current_iteration, max_iters, \n",
        "                        #    self.optimizer.param_groups[0]['lr'], \n",
        "                         #   loss.item(), \n",
        "                          #  mIoU,\n",
        "                           # str(datetime.timedelta(seconds=int(time.time() - start_time))), \n",
        "                            #eta_string))\n",
        "\t\t\n",
        "            #self.lr_scheduler.step() # Use this for the lr schedulers which changes with epoch.\n",
        "\n",
        "            average_pixAcc = sum(lsit_pixAcc)/len(lsit_pixAcc)\n",
        "            average_mIoU = sum(list_mIoU)/len(list_mIoU)\n",
        "            average_loss = sum(list_loss)/len(list_loss)\n",
        "            self.losses.append(average_loss)\n",
        "            self.IoU_list.append(average_mIoU)\n",
        "            print(\"Epochs: {:d}/{:d}, Average loss: {:.3f}, Average mIoU: {:.3f}, Average pixAcc: {:.3f}\".format(self.current_epoch, self.epochs, average_loss, average_mIoU, average_pixAcc))\n",
        "            #logger.info(\"Epochs: {:d}/{:d}, Average loss: {:.3f}, Average mIoU: {:.3f}, Average pixAcc: {:.3f}\".format(self.current_epoch, self.epochs, average_loss, average_mIoU, average_pixAcc))\n",
        "\t\t\n",
        "            if self.current_iteration % val_per_iters == 0:\n",
        "                self.validation()\n",
        "                self.model.train()\n",
        "\n",
        "        total_training_time = time.time() - start_time\n",
        "        total_training_str = str(datetime.timedelta(seconds=total_training_time))\n",
        "        print(\"Total training time: {} ({:.4f}s / it)\".format(\n",
        "            total_training_str, total_training_time / max_iters))\n",
        "        #logger.info(\n",
        "         #   \"Total training time: {} ({:.4f}s / it)\".format(\n",
        "          #  total_training_str, total_training_time / max_iters))\n",
        "        return self.model\n",
        "\n",
        "    def validation(self):\n",
        "        is_best = False\n",
        "        self.metric.reset()\n",
        "        if self.dataparallel:\n",
        "            model = self.model.module\n",
        "        else:\n",
        "            model = self.model\n",
        "        model.eval()\n",
        "        lsit_pixAcc = []\n",
        "        list_mIoU = []\n",
        "        list_loss = []\n",
        "        for i, (image, targets, filename) in enumerate(self.val_dataloader):\n",
        "            image = image.to(self.device)\n",
        "            targets = targets.to(self.device)\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                outputs = model(image)\n",
        "                loss = self.criterion(outputs, targets)\n",
        "            self.metric.update(outputs[0], targets)\n",
        "            pixAcc, mIoU = self.metric.get()\n",
        "            lsit_pixAcc.append(pixAcc)\n",
        "            list_mIoU.append(mIoU)\n",
        "            list_loss.append(loss.item())\n",
        "\n",
        "        average_pixAcc = sum(lsit_pixAcc)/len(lsit_pixAcc)\n",
        "        average_mIoU = sum(list_mIoU)/len(list_mIoU)\n",
        "        average_loss = sum(list_loss)/len(list_loss)\n",
        "        self.current_mIoU = average_mIoU\n",
        "        print(\"Validation: Average loss: {:.3f}, Average mIoU: {:.3f}, Average pixAcc: {:.3f}\".format(average_loss,  average_mIoU, average_pixAcc))\n",
        "        #self.logger.info(\"Validation: Average loss: {:.3f}, Average mIoU: {:.3f}, Average pixAcc: {:.3f}\".format(average_loss,  average_mIoU, average_pixAcc))\n",
        "\n",
        "        save_checkpoint(self, self.model, self.optimizer, average_mIoU, average_loss, self.cfg, self.current_epoch, is_best, self.current_mIoU, self.dataparallel)\n",
        "        \n",
        "        #if self.current_mIoU > self.best_mIoU:\n",
        "        #    is_best = True\n",
        "        #    self.best_mIoU = self.current_mIoU\n",
        "        #if is_best:\n",
        "           # save_checkpoint(self.model, self.optimizer, self.losses, self.cfg, self.current_epoch, is_best, self.current_mIoU, self.dataparallel)\n",
        "\n",
        "def save_checkpoint(trainer, model, optimizer, valid_mIoU, valid_loss, cfg, epoch = 0, is_best=False, mIoU = 0.0, dataparallel = False):\n",
        "    \"\"\"Save Checkpoint\"\"\"\n",
        "    directory = os.path.expanduser(cfg[\"train\"][\"ckpt_dir\"])\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "    filename = '{}_{}_{}_{:.3f}.pth'.format(cfg[\"model\"][\"name\"], cfg[\"model\"][\"backbone\"],epoch,mIoU)\n",
        "    filename = os.path.join(directory, filename)\n",
        "    if dataparallel:\n",
        "        model = model.module\n",
        "    #if is_best:\n",
        "    best_filename = '{}_{}_{}_{:.3f}_best_model.pth'.format(cfg[\"model\"][\"name\"], cfg[\"model\"][\"backbone\"],epoch,mIoU)\n",
        "    best_filename = os.path.join(directory, best_filename)\n",
        "    torch.save(\n",
        "        {\n",
        "            'model_state_dict': model.state_dict(), \n",
        "            'optim_state_dict': optimizer.state_dict(),\n",
        "            'current_epoch': epoch,\n",
        "            'valid_loss': valid_loss,\n",
        "            'valid_mIoU': valid_mIoU,\n",
        "            'train_loss': trainer.losses[-1],\n",
        "            'train_mIoU': trainer.IoU_list[-1]\n",
        "        }, best_filename)\n",
        "    save_to_drive(best_filename)\n",
        "        \n",
        "\n",
        "#if __name__ == '__main__':\n",
        "def main(load = False, path = None):\n",
        "    # Set config file\n",
        "    config_path = \"./icnet.yaml\"\n",
        "    with open(config_path, \"r\") as yaml_file:\n",
        "        cfg = yaml.full_load(yaml_file.read())\n",
        "        #print(cfg)\n",
        "        #print(cfg[\"model\"][\"backbone\"])\n",
        "        #print(cfg[\"train\"][\"specific_gpu_num\"])\n",
        "    \n",
        "    # Use specific GPU\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(cfg[\"train\"][\"specific_gpu_num\"])\n",
        "    num_gpus = len(cfg[\"train\"][\"specific_gpu_num\"].split(','))\n",
        "    print(\"torch.cuda.is_available(): {}\".format(torch.cuda.is_available()))\n",
        "    print(\"torch.cuda.device_count(): {}\".format(torch.cuda.device_count()))\n",
        "    print(\"torch.cuda.current_device(): {}\".format(torch.cuda.current_device()))\n",
        "\n",
        "    # Set logger\n",
        "    #logger = SetupLogger(name = \"semantic_segmentation\", \n",
        "     #                     save_dir = cfg[\"train\"][\"ckpt_dir\"], \n",
        "      #                    distributed_rank = 0,\n",
        "       #                   filename='{}_{}_log.txt'.format(cfg[\"model\"][\"name\"], cfg[\"model\"][\"backbone\"]))\n",
        "    #logger.info(\"Using {} GPUs\".format(num_gpus))\n",
        "    #logger.info(\"torch.cuda.is_available(): {}\".format(torch.cuda.is_available()))\n",
        "    #logger.info(\"torch.cuda.device_count(): {}\".format(torch.cuda.device_count()))\n",
        "    #logger.info(\"torch.cuda.current_device(): {}\".format(torch.cuda.current_device()))\n",
        "    #logger.info(cfg)\n",
        "    \n",
        "    # Start train\n",
        "    trainer = Trainer(cfg, load, path) # trainer = Trainer(cfg,logger)\n",
        "    model = trainer.train()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDiiEpUqT49y"
      },
      "source": [
        "# RUN THE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61JpK993IXHI",
        "outputId": "46736f68-fb51-470d-c5e3-52cff0ff4f50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.cuda.is_available(): True\n",
            "torch.cuda.device_count(): 1\n",
            "torch.cuda.current_device(): 0\n",
            "Found 2975 images in the folder /content/drive/MyDrive/multiclass-seg/cityscapes/leftImg8bit/train\n",
            "Found 500 images in the folder /content/drive/MyDrive/multiclass-seg/cityscapes/leftImg8bit/val\n",
            "Start training, Total Epochs: 20 = Total Iterations 8500\n",
            "Epochs: 1/20 || Iters: 10/8500 || Lr: 0.010000 || Train Loss: 1.5219 || mIoU: 0.1498 || Cost Time: 0:00:05 || Estimated Time: 1:20:03\n",
            "Epochs: 1/20 || Iters: 20/8500 || Lr: 0.010000 || Train Loss: 1.4440 || mIoU: 0.1734 || Cost Time: 0:00:09 || Estimated Time: 1:05:04\n",
            "Epochs: 1/20 || Iters: 30/8500 || Lr: 0.010000 || Train Loss: 1.1151 || mIoU: 0.1946 || Cost Time: 0:00:13 || Estimated Time: 1:04:02\n",
            "Epochs: 1/20 || Iters: 40/8500 || Lr: 0.010000 || Train Loss: 0.9602 || mIoU: 0.2046 || Cost Time: 0:00:17 || Estimated Time: 1:00:02\n",
            "Epochs: 1/20 || Iters: 50/8500 || Lr: 0.010000 || Train Loss: 1.1924 || mIoU: 0.2198 || Cost Time: 0:00:21 || Estimated Time: 1:00:10\n",
            "Epochs: 1/20 || Iters: 60/8500 || Lr: 0.010000 || Train Loss: 0.8379 || mIoU: 0.2288 || Cost Time: 0:00:24 || Estimated Time: 0:58:15\n",
            "Epochs: 1/20 || Iters: 70/8500 || Lr: 0.010000 || Train Loss: 0.8795 || mIoU: 0.2361 || Cost Time: 0:00:29 || Estimated Time: 0:59:16\n",
            "Epochs: 1/20 || Iters: 80/8500 || Lr: 0.010000 || Train Loss: 0.9397 || mIoU: 0.2413 || Cost Time: 0:00:33 || Estimated Time: 0:58:04\n",
            "Epochs: 1/20 || Iters: 90/8500 || Lr: 0.010000 || Train Loss: 0.9519 || mIoU: 0.2476 || Cost Time: 0:00:38 || Estimated Time: 0:59:29\n",
            "Epochs: 1/20 || Iters: 100/8500 || Lr: 0.010000 || Train Loss: 1.4097 || mIoU: 0.2525 || Cost Time: 0:00:41 || Estimated Time: 0:58:35\n",
            "Epochs: 1/20 || Iters: 110/8500 || Lr: 0.010000 || Train Loss: 0.9838 || mIoU: 0.2592 || Cost Time: 0:00:46 || Estimated Time: 0:58:46\n",
            "Epochs: 1/20 || Iters: 120/8500 || Lr: 0.010000 || Train Loss: 0.6851 || mIoU: 0.2620 || Cost Time: 0:00:49 || Estimated Time: 0:58:04\n",
            "Epochs: 1/20 || Iters: 130/8500 || Lr: 0.010000 || Train Loss: 0.5637 || mIoU: 0.2650 || Cost Time: 0:00:54 || Estimated Time: 0:58:27\n",
            "Epochs: 1/20 || Iters: 140/8500 || Lr: 0.010000 || Train Loss: 0.8369 || mIoU: 0.2680 || Cost Time: 0:00:57 || Estimated Time: 0:57:35\n",
            "Epochs: 1/20 || Iters: 150/8500 || Lr: 0.010000 || Train Loss: 0.8016 || mIoU: 0.2695 || Cost Time: 0:01:02 || Estimated Time: 0:58:02\n",
            "Epochs: 1/20 || Iters: 160/8500 || Lr: 0.010000 || Train Loss: 1.0844 || mIoU: 0.2720 || Cost Time: 0:01:06 || Estimated Time: 0:57:31\n",
            "Epochs: 1/20 || Iters: 170/8500 || Lr: 0.010000 || Train Loss: 0.6564 || mIoU: 0.2740 || Cost Time: 0:01:10 || Estimated Time: 0:57:36\n",
            "Epochs: 1/20 || Iters: 180/8500 || Lr: 0.010000 || Train Loss: 0.6014 || mIoU: 0.2754 || Cost Time: 0:01:14 || Estimated Time: 0:57:38\n",
            "Epochs: 1/20 || Iters: 190/8500 || Lr: 0.010000 || Train Loss: 0.5676 || mIoU: 0.2766 || Cost Time: 0:01:19 || Estimated Time: 0:57:48\n",
            "Epochs: 1/20 || Iters: 200/8500 || Lr: 0.010000 || Train Loss: 1.1171 || mIoU: 0.2782 || Cost Time: 0:01:22 || Estimated Time: 0:57:19\n",
            "Epochs: 1/20 || Iters: 210/8500 || Lr: 0.010000 || Train Loss: 0.7774 || mIoU: 0.2803 || Cost Time: 0:01:27 || Estimated Time: 0:57:19\n",
            "Epochs: 1/20 || Iters: 220/8500 || Lr: 0.010000 || Train Loss: 1.1172 || mIoU: 0.2829 || Cost Time: 0:01:30 || Estimated Time: 0:56:49\n",
            "Epochs: 1/20 || Iters: 230/8500 || Lr: 0.010000 || Train Loss: 0.8337 || mIoU: 0.2850 || Cost Time: 0:01:34 || Estimated Time: 0:56:52\n",
            "Epochs: 1/20 || Iters: 240/8500 || Lr: 0.010000 || Train Loss: 0.8640 || mIoU: 0.2872 || Cost Time: 0:01:38 || Estimated Time: 0:56:34\n",
            "Epochs: 1/20 || Iters: 250/8500 || Lr: 0.010000 || Train Loss: 0.7241 || mIoU: 0.2885 || Cost Time: 0:01:43 || Estimated Time: 0:56:50\n",
            "Epochs: 1/20 || Iters: 260/8500 || Lr: 0.010000 || Train Loss: 0.9038 || mIoU: 0.2892 || Cost Time: 0:01:47 || Estimated Time: 0:56:34\n",
            "Epochs: 1/20 || Iters: 270/8500 || Lr: 0.010000 || Train Loss: 0.7772 || mIoU: 0.2911 || Cost Time: 0:01:51 || Estimated Time: 0:56:45\n",
            "Epochs: 1/20 || Iters: 280/8500 || Lr: 0.010000 || Train Loss: 0.5967 || mIoU: 0.2921 || Cost Time: 0:01:54 || Estimated Time: 0:56:14\n",
            "Epochs: 1/20 || Iters: 290/8500 || Lr: 0.010000 || Train Loss: 0.9690 || mIoU: 0.2939 || Cost Time: 0:01:59 || Estimated Time: 0:56:20\n",
            "Epochs: 1/20 || Iters: 300/8500 || Lr: 0.010000 || Train Loss: 0.6054 || mIoU: 0.2955 || Cost Time: 0:02:03 || Estimated Time: 0:56:04\n",
            "Epochs: 1/20 || Iters: 310/8500 || Lr: 0.010000 || Train Loss: 0.8320 || mIoU: 0.2967 || Cost Time: 0:02:07 || Estimated Time: 0:56:06\n",
            "Epochs: 1/20 || Iters: 320/8500 || Lr: 0.010000 || Train Loss: 0.8792 || mIoU: 0.2986 || Cost Time: 0:02:11 || Estimated Time: 0:55:50\n",
            "Epochs: 1/20 || Iters: 330/8500 || Lr: 0.010000 || Train Loss: 0.9040 || mIoU: 0.3004 || Cost Time: 0:02:15 || Estimated Time: 0:56:02\n",
            "Epochs: 1/20 || Iters: 340/8500 || Lr: 0.010000 || Train Loss: 0.9653 || mIoU: 0.3014 || Cost Time: 0:02:19 || Estimated Time: 0:55:44\n",
            "Epochs: 1/20 || Iters: 350/8500 || Lr: 0.010000 || Train Loss: 0.9088 || mIoU: 0.3029 || Cost Time: 0:02:23 || Estimated Time: 0:55:48\n",
            "Epochs: 1/20 || Iters: 360/8500 || Lr: 0.010000 || Train Loss: 0.7026 || mIoU: 0.3046 || Cost Time: 0:02:27 || Estimated Time: 0:55:42\n",
            "Epochs: 1/20 || Iters: 370/8500 || Lr: 0.010000 || Train Loss: 0.9622 || mIoU: 0.3061 || Cost Time: 0:02:31 || Estimated Time: 0:55:22\n",
            "Epochs: 1/20 || Iters: 380/8500 || Lr: 0.010000 || Train Loss: 0.7324 || mIoU: 0.3069 || Cost Time: 0:02:35 || Estimated Time: 0:55:21\n",
            "Epochs: 1/20 || Iters: 390/8500 || Lr: 0.010000 || Train Loss: 0.7621 || mIoU: 0.3082 || Cost Time: 0:02:39 || Estimated Time: 0:55:07\n",
            "Epochs: 1/20 || Iters: 400/8500 || Lr: 0.010000 || Train Loss: 0.6398 || mIoU: 0.3096 || Cost Time: 0:02:43 || Estimated Time: 0:55:17\n",
            "Epochs: 1/20 || Iters: 410/8500 || Lr: 0.010000 || Train Loss: 0.7848 || mIoU: 0.3113 || Cost Time: 0:02:47 || Estimated Time: 0:55:03\n",
            "Epochs: 1/20 || Iters: 420/8500 || Lr: 0.010000 || Train Loss: 1.0123 || mIoU: 0.3130 || Cost Time: 0:02:52 || Estimated Time: 0:55:08\n",
            "Epochs: 1/20, Average loss: 0.912, Average mIoU: 0.269, Average pixAcc: 0.839\n",
            "Validation: Average loss: 0.938, Average mIoU: 0.342, Average pixAcc: 0.859\n",
            "Epochs: 2/20 || Iters: 430/8500 || Lr: 0.009500 || Train Loss: 0.8975 || mIoU: 0.3538 || Cost Time: 0:03:28 || Estimated Time: 1:05:06\n",
            "Epochs: 2/20 || Iters: 440/8500 || Lr: 0.009500 || Train Loss: 0.6445 || mIoU: 0.3667 || Cost Time: 0:03:31 || Estimated Time: 1:04:42\n",
            "Epochs: 2/20 || Iters: 450/8500 || Lr: 0.009500 || Train Loss: 0.6591 || mIoU: 0.3618 || Cost Time: 0:03:36 || Estimated Time: 1:04:28\n",
            "Epochs: 2/20 || Iters: 460/8500 || Lr: 0.009500 || Train Loss: 0.9297 || mIoU: 0.3634 || Cost Time: 0:03:39 || Estimated Time: 1:04:02\n",
            "Epochs: 2/20 || Iters: 470/8500 || Lr: 0.009500 || Train Loss: 0.7826 || mIoU: 0.3699 || Cost Time: 0:03:44 || Estimated Time: 1:03:51\n",
            "Epochs: 2/20 || Iters: 480/8500 || Lr: 0.009500 || Train Loss: 0.8599 || mIoU: 0.3722 || Cost Time: 0:03:48 || Estimated Time: 1:03:30\n",
            "Epochs: 2/20 || Iters: 490/8500 || Lr: 0.009500 || Train Loss: 0.8782 || mIoU: 0.3723 || Cost Time: 0:03:52 || Estimated Time: 1:03:19\n",
            "Epochs: 2/20 || Iters: 500/8500 || Lr: 0.009500 || Train Loss: 0.7068 || mIoU: 0.3708 || Cost Time: 0:03:56 || Estimated Time: 1:02:58\n",
            "Epochs: 2/20 || Iters: 510/8500 || Lr: 0.009500 || Train Loss: 0.6333 || mIoU: 0.3769 || Cost Time: 0:04:00 || Estimated Time: 1:02:49\n",
            "Epochs: 2/20 || Iters: 520/8500 || Lr: 0.009500 || Train Loss: 0.7202 || mIoU: 0.3801 || Cost Time: 0:04:04 || Estimated Time: 1:02:24\n",
            "Epochs: 2/20 || Iters: 530/8500 || Lr: 0.009500 || Train Loss: 0.7036 || mIoU: 0.3810 || Cost Time: 0:04:08 || Estimated Time: 1:02:15\n",
            "Epochs: 2/20 || Iters: 540/8500 || Lr: 0.009500 || Train Loss: 0.5974 || mIoU: 0.3817 || Cost Time: 0:04:12 || Estimated Time: 1:01:57\n",
            "Epochs: 2/20 || Iters: 550/8500 || Lr: 0.009500 || Train Loss: 1.0651 || mIoU: 0.3820 || Cost Time: 0:04:16 || Estimated Time: 1:01:52\n",
            "Epochs: 2/20 || Iters: 560/8500 || Lr: 0.009500 || Train Loss: 0.7030 || mIoU: 0.3822 || Cost Time: 0:04:20 || Estimated Time: 1:01:33\n",
            "Epochs: 2/20 || Iters: 570/8500 || Lr: 0.009500 || Train Loss: 1.2227 || mIoU: 0.3814 || Cost Time: 0:04:25 || Estimated Time: 1:01:27\n",
            "Epochs: 2/20 || Iters: 580/8500 || Lr: 0.009500 || Train Loss: 0.6513 || mIoU: 0.3823 || Cost Time: 0:04:28 || Estimated Time: 1:01:11\n",
            "Epochs: 2/20 || Iters: 590/8500 || Lr: 0.009500 || Train Loss: 0.5652 || mIoU: 0.3840 || Cost Time: 0:04:33 || Estimated Time: 1:01:01\n",
            "Epochs: 2/20 || Iters: 600/8500 || Lr: 0.009500 || Train Loss: 0.6293 || mIoU: 0.3850 || Cost Time: 0:04:36 || Estimated Time: 1:00:43\n",
            "Epochs: 2/20 || Iters: 610/8500 || Lr: 0.009500 || Train Loss: 0.6586 || mIoU: 0.3850 || Cost Time: 0:04:40 || Estimated Time: 1:00:33\n",
            "Epochs: 2/20 || Iters: 620/8500 || Lr: 0.009500 || Train Loss: 0.5815 || mIoU: 0.3869 || Cost Time: 0:04:44 || Estimated Time: 1:00:16\n",
            "Epochs: 2/20 || Iters: 630/8500 || Lr: 0.009500 || Train Loss: 0.6593 || mIoU: 0.3861 || Cost Time: 0:04:49 || Estimated Time: 1:00:12\n",
            "Epochs: 2/20 || Iters: 640/8500 || Lr: 0.009500 || Train Loss: 0.5942 || mIoU: 0.3857 || Cost Time: 0:04:52 || Estimated Time: 0:59:55\n",
            "Epochs: 2/20 || Iters: 650/8500 || Lr: 0.009500 || Train Loss: 0.7207 || mIoU: 0.3857 || Cost Time: 0:04:57 || Estimated Time: 0:59:47\n",
            "Epochs: 2/20 || Iters: 660/8500 || Lr: 0.009500 || Train Loss: 0.9447 || mIoU: 0.3841 || Cost Time: 0:05:00 || Estimated Time: 0:59:32\n",
            "Epochs: 2/20 || Iters: 670/8500 || Lr: 0.009500 || Train Loss: 0.5230 || mIoU: 0.3846 || Cost Time: 0:05:05 || Estimated Time: 0:59:25\n",
            "Epochs: 2/20 || Iters: 680/8500 || Lr: 0.009500 || Train Loss: 1.4492 || mIoU: 0.3841 || Cost Time: 0:05:08 || Estimated Time: 0:59:08\n",
            "Epochs: 2/20 || Iters: 690/8500 || Lr: 0.009500 || Train Loss: 0.6888 || mIoU: 0.3838 || Cost Time: 0:05:12 || Estimated Time: 0:59:00\n",
            "Epochs: 2/20 || Iters: 700/8500 || Lr: 0.009500 || Train Loss: 0.6065 || mIoU: 0.3839 || Cost Time: 0:05:16 || Estimated Time: 0:58:45\n",
            "Epochs: 2/20 || Iters: 710/8500 || Lr: 0.009500 || Train Loss: 0.6113 || mIoU: 0.3849 || Cost Time: 0:05:20 || Estimated Time: 0:58:37\n",
            "Epochs: 2/20 || Iters: 720/8500 || Lr: 0.009500 || Train Loss: 0.7423 || mIoU: 0.3848 || Cost Time: 0:05:24 || Estimated Time: 0:58:27\n",
            "Epochs: 2/20 || Iters: 730/8500 || Lr: 0.009500 || Train Loss: 0.5380 || mIoU: 0.3849 || Cost Time: 0:05:28 || Estimated Time: 0:58:19\n",
            "Epochs: 2/20 || Iters: 740/8500 || Lr: 0.009500 || Train Loss: 0.5579 || mIoU: 0.3854 || Cost Time: 0:05:32 || Estimated Time: 0:58:10\n",
            "Epochs: 2/20 || Iters: 750/8500 || Lr: 0.009500 || Train Loss: 0.6223 || mIoU: 0.3860 || Cost Time: 0:05:37 || Estimated Time: 0:58:02\n",
            "Epochs: 2/20 || Iters: 760/8500 || Lr: 0.009500 || Train Loss: 0.5981 || mIoU: 0.3861 || Cost Time: 0:05:41 || Estimated Time: 0:57:53\n",
            "Epochs: 2/20 || Iters: 770/8500 || Lr: 0.009500 || Train Loss: 0.4902 || mIoU: 0.3866 || Cost Time: 0:05:45 || Estimated Time: 0:57:47\n",
            "Epochs: 2/20 || Iters: 780/8500 || Lr: 0.009500 || Train Loss: 1.1534 || mIoU: 0.3877 || Cost Time: 0:05:49 || Estimated Time: 0:57:35\n",
            "Epochs: 2/20 || Iters: 790/8500 || Lr: 0.009500 || Train Loss: 0.7152 || mIoU: 0.3885 || Cost Time: 0:05:53 || Estimated Time: 0:57:29\n",
            "Epochs: 2/20 || Iters: 800/8500 || Lr: 0.009500 || Train Loss: 0.7915 || mIoU: 0.3886 || Cost Time: 0:05:56 || Estimated Time: 0:57:15\n",
            "Epochs: 2/20 || Iters: 810/8500 || Lr: 0.009500 || Train Loss: 0.8898 || mIoU: 0.3888 || Cost Time: 0:06:01 || Estimated Time: 0:57:10\n",
            "Epochs: 2/20 || Iters: 820/8500 || Lr: 0.009500 || Train Loss: 0.6770 || mIoU: 0.3889 || Cost Time: 0:06:04 || Estimated Time: 0:56:57\n",
            "Epochs: 2/20 || Iters: 830/8500 || Lr: 0.009500 || Train Loss: 0.6119 || mIoU: 0.3890 || Cost Time: 0:06:09 || Estimated Time: 0:56:52\n",
            "Epochs: 2/20 || Iters: 840/8500 || Lr: 0.009500 || Train Loss: 0.8266 || mIoU: 0.3886 || Cost Time: 0:06:13 || Estimated Time: 0:56:41\n",
            "Epochs: 2/20 || Iters: 850/8500 || Lr: 0.009500 || Train Loss: 0.6581 || mIoU: 0.3886 || Cost Time: 0:06:17 || Estimated Time: 0:56:34\n",
            "Epochs: 2/20, Average loss: 0.745, Average mIoU: 0.382, Average pixAcc: 0.886\n",
            "Validation: Average loss: 0.836, Average mIoU: 0.352, Average pixAcc: 0.870\n",
            "Epochs: 3/20 || Iters: 860/8500 || Lr: 0.009025 || Train Loss: 0.6798 || mIoU: 0.3540 || Cost Time: 0:06:52 || Estimated Time: 1:01:08\n",
            "Epochs: 3/20 || Iters: 870/8500 || Lr: 0.009025 || Train Loss: 0.7507 || mIoU: 0.3559 || Cost Time: 0:06:56 || Estimated Time: 1:00:56\n",
            "Epochs: 3/20 || Iters: 880/8500 || Lr: 0.009025 || Train Loss: 0.7262 || mIoU: 0.3631 || Cost Time: 0:07:01 || Estimated Time: 1:00:47\n",
            "Epochs: 3/20 || Iters: 890/8500 || Lr: 0.009025 || Train Loss: 0.7642 || mIoU: 0.3680 || Cost Time: 0:07:04 || Estimated Time: 1:00:33\n",
            "Epochs: 3/20 || Iters: 900/8500 || Lr: 0.009025 || Train Loss: 0.5628 || mIoU: 0.3747 || Cost Time: 0:07:09 || Estimated Time: 1:00:26\n",
            "Epochs: 3/20 || Iters: 910/8500 || Lr: 0.009025 || Train Loss: 0.5849 || mIoU: 0.3780 || Cost Time: 0:07:13 || Estimated Time: 1:00:12\n",
            "Epochs: 3/20 || Iters: 920/8500 || Lr: 0.009025 || Train Loss: 0.7202 || mIoU: 0.3824 || Cost Time: 0:07:17 || Estimated Time: 1:00:07\n",
            "Epochs: 3/20 || Iters: 930/8500 || Lr: 0.009025 || Train Loss: 0.6384 || mIoU: 0.3873 || Cost Time: 0:07:21 || Estimated Time: 0:59:52\n",
            "Epochs: 3/20 || Iters: 940/8500 || Lr: 0.009025 || Train Loss: 0.8872 || mIoU: 0.3926 || Cost Time: 0:07:26 || Estimated Time: 0:59:49\n",
            "Epochs: 3/20 || Iters: 950/8500 || Lr: 0.009025 || Train Loss: 0.5505 || mIoU: 0.3945 || Cost Time: 0:07:29 || Estimated Time: 0:59:35\n",
            "Epochs: 3/20 || Iters: 960/8500 || Lr: 0.009025 || Train Loss: 0.4861 || mIoU: 0.3954 || Cost Time: 0:07:34 || Estimated Time: 0:59:29\n",
            "Epochs: 3/20 || Iters: 970/8500 || Lr: 0.009025 || Train Loss: 1.2786 || mIoU: 0.3939 || Cost Time: 0:07:38 || Estimated Time: 0:59:15\n",
            "Epochs: 3/20 || Iters: 980/8500 || Lr: 0.009025 || Train Loss: 0.7344 || mIoU: 0.3931 || Cost Time: 0:07:42 || Estimated Time: 0:59:08\n",
            "Epochs: 3/20 || Iters: 990/8500 || Lr: 0.009025 || Train Loss: 0.6893 || mIoU: 0.3948 || Cost Time: 0:07:45 || Estimated Time: 0:58:52\n",
            "Epochs: 3/20 || Iters: 1000/8500 || Lr: 0.009025 || Train Loss: 0.6778 || mIoU: 0.3954 || Cost Time: 0:07:50 || Estimated Time: 0:58:47\n",
            "Epochs: 3/20 || Iters: 1010/8500 || Lr: 0.009025 || Train Loss: 0.9344 || mIoU: 0.3952 || Cost Time: 0:07:53 || Estimated Time: 0:58:34\n",
            "Epochs: 3/20 || Iters: 1020/8500 || Lr: 0.009025 || Train Loss: 0.6446 || mIoU: 0.3963 || Cost Time: 0:07:58 || Estimated Time: 0:58:27\n",
            "Epochs: 3/20 || Iters: 1030/8500 || Lr: 0.009025 || Train Loss: 0.8164 || mIoU: 0.3963 || Cost Time: 0:08:01 || Estimated Time: 0:58:13\n",
            "Epochs: 3/20 || Iters: 1040/8500 || Lr: 0.009025 || Train Loss: 0.7374 || mIoU: 0.3966 || Cost Time: 0:08:06 || Estimated Time: 0:58:07\n",
            "Epochs: 3/20 || Iters: 1050/8500 || Lr: 0.009025 || Train Loss: 0.5489 || mIoU: 0.3963 || Cost Time: 0:08:09 || Estimated Time: 0:57:54\n",
            "Epochs: 3/20 || Iters: 1060/8500 || Lr: 0.009025 || Train Loss: 0.8453 || mIoU: 0.3968 || Cost Time: 0:08:14 || Estimated Time: 0:57:48\n",
            "Epochs: 3/20 || Iters: 1070/8500 || Lr: 0.009025 || Train Loss: 0.8285 || mIoU: 0.3969 || Cost Time: 0:08:17 || Estimated Time: 0:57:34\n",
            "Epochs: 3/20 || Iters: 1080/8500 || Lr: 0.009025 || Train Loss: 0.8635 || mIoU: 0.3967 || Cost Time: 0:08:22 || Estimated Time: 0:57:29\n",
            "Epochs: 3/20 || Iters: 1090/8500 || Lr: 0.009025 || Train Loss: 0.6222 || mIoU: 0.3971 || Cost Time: 0:08:25 || Estimated Time: 0:57:18\n",
            "Epochs: 3/20 || Iters: 1100/8500 || Lr: 0.009025 || Train Loss: 0.7419 || mIoU: 0.3967 || Cost Time: 0:08:30 || Estimated Time: 0:57:12\n",
            "Epochs: 3/20 || Iters: 1110/8500 || Lr: 0.009025 || Train Loss: 0.7675 || mIoU: 0.3978 || Cost Time: 0:08:34 || Estimated Time: 0:57:06\n",
            "Epochs: 3/20 || Iters: 1120/8500 || Lr: 0.009025 || Train Loss: 1.2590 || mIoU: 0.3986 || Cost Time: 0:08:38 || Estimated Time: 0:56:55\n",
            "Epochs: 3/20 || Iters: 1130/8500 || Lr: 0.009025 || Train Loss: 1.1003 || mIoU: 0.3991 || Cost Time: 0:08:42 || Estimated Time: 0:56:45\n",
            "Epochs: 3/20 || Iters: 1140/8500 || Lr: 0.009025 || Train Loss: 0.6472 || mIoU: 0.3993 || Cost Time: 0:08:46 || Estimated Time: 0:56:37\n",
            "Epochs: 3/20 || Iters: 1150/8500 || Lr: 0.009025 || Train Loss: 0.6655 || mIoU: 0.4009 || Cost Time: 0:08:50 || Estimated Time: 0:56:28\n",
            "Epochs: 3/20 || Iters: 1160/8500 || Lr: 0.009025 || Train Loss: 0.7571 || mIoU: 0.4015 || Cost Time: 0:08:54 || Estimated Time: 0:56:22\n",
            "Epochs: 3/20 || Iters: 1170/8500 || Lr: 0.009025 || Train Loss: 0.5978 || mIoU: 0.4016 || Cost Time: 0:08:58 || Estimated Time: 0:56:12\n",
            "Epochs: 3/20 || Iters: 1180/8500 || Lr: 0.009025 || Train Loss: 0.8064 || mIoU: 0.4014 || Cost Time: 0:09:02 || Estimated Time: 0:56:07\n",
            "Epochs: 3/20 || Iters: 1190/8500 || Lr: 0.009025 || Train Loss: 0.7026 || mIoU: 0.4026 || Cost Time: 0:09:06 || Estimated Time: 0:55:56\n",
            "Epochs: 3/20 || Iters: 1200/8500 || Lr: 0.009025 || Train Loss: 1.2229 || mIoU: 0.4024 || Cost Time: 0:09:10 || Estimated Time: 0:55:51\n",
            "Epochs: 3/20 || Iters: 1210/8500 || Lr: 0.009025 || Train Loss: 0.6418 || mIoU: 0.4029 || Cost Time: 0:09:14 || Estimated Time: 0:55:41\n",
            "Epochs: 3/20 || Iters: 1220/8500 || Lr: 0.009025 || Train Loss: 0.5698 || mIoU: 0.4025 || Cost Time: 0:09:18 || Estimated Time: 0:55:34\n",
            "Epochs: 3/20 || Iters: 1230/8500 || Lr: 0.009025 || Train Loss: 0.5655 || mIoU: 0.4027 || Cost Time: 0:09:22 || Estimated Time: 0:55:24\n",
            "Epochs: 3/20 || Iters: 1240/8500 || Lr: 0.009025 || Train Loss: 0.6974 || mIoU: 0.4032 || Cost Time: 0:09:26 || Estimated Time: 0:55:17\n",
            "Epochs: 3/20 || Iters: 1250/8500 || Lr: 0.009025 || Train Loss: 0.5493 || mIoU: 0.4027 || Cost Time: 0:09:30 || Estimated Time: 0:55:07\n",
            "Epochs: 3/20 || Iters: 1260/8500 || Lr: 0.009025 || Train Loss: 0.6682 || mIoU: 0.4026 || Cost Time: 0:09:35 || Estimated Time: 0:55:06\n",
            "Epochs: 3/20 || Iters: 1270/8500 || Lr: 0.009025 || Train Loss: 0.6652 || mIoU: 0.4020 || Cost Time: 0:09:38 || Estimated Time: 0:54:53\n",
            "Epochs: 3/20, Average loss: 0.720, Average mIoU: 0.393, Average pixAcc: 0.892\n",
            "Validation: Average loss: 0.857, Average mIoU: 0.368, Average pixAcc: 0.870\n",
            "Epochs: 4/20 || Iters: 1280/8500 || Lr: 0.008574 || Train Loss: 0.7064 || mIoU: 0.3453 || Cost Time: 0:10:15 || Estimated Time: 0:57:51\n",
            "Epochs: 4/20 || Iters: 1290/8500 || Lr: 0.008574 || Train Loss: 0.6170 || mIoU: 0.3858 || Cost Time: 0:10:19 || Estimated Time: 0:57:39\n",
            "Epochs: 4/20 || Iters: 1300/8500 || Lr: 0.008574 || Train Loss: 0.7815 || mIoU: 0.3812 || Cost Time: 0:10:23 || Estimated Time: 0:57:33\n",
            "Epochs: 4/20 || Iters: 1310/8500 || Lr: 0.008574 || Train Loss: 0.6310 || mIoU: 0.4054 || Cost Time: 0:10:27 || Estimated Time: 0:57:21\n",
            "Epochs: 4/20 || Iters: 1320/8500 || Lr: 0.008574 || Train Loss: 0.5297 || mIoU: 0.4012 || Cost Time: 0:10:31 || Estimated Time: 0:57:15\n",
            "Epochs: 4/20 || Iters: 1330/8500 || Lr: 0.008574 || Train Loss: 0.6254 || mIoU: 0.3976 || Cost Time: 0:10:35 || Estimated Time: 0:57:04\n",
            "Epochs: 4/20 || Iters: 1340/8500 || Lr: 0.008574 || Train Loss: 0.8907 || mIoU: 0.4039 || Cost Time: 0:10:39 || Estimated Time: 0:56:59\n",
            "Epochs: 4/20 || Iters: 1350/8500 || Lr: 0.008574 || Train Loss: 0.6320 || mIoU: 0.4024 || Cost Time: 0:10:43 || Estimated Time: 0:56:46\n",
            "Epochs: 4/20 || Iters: 1360/8500 || Lr: 0.008574 || Train Loss: 0.6069 || mIoU: 0.4009 || Cost Time: 0:10:48 || Estimated Time: 0:56:41\n",
            "Epochs: 4/20 || Iters: 1370/8500 || Lr: 0.008574 || Train Loss: 0.6154 || mIoU: 0.4029 || Cost Time: 0:10:51 || Estimated Time: 0:56:30\n",
            "Epochs: 4/20 || Iters: 1380/8500 || Lr: 0.008574 || Train Loss: 0.8443 || mIoU: 0.4045 || Cost Time: 0:10:55 || Estimated Time: 0:56:23\n",
            "Epochs: 4/20 || Iters: 1390/8500 || Lr: 0.008574 || Train Loss: 0.7094 || mIoU: 0.4010 || Cost Time: 0:10:59 || Estimated Time: 0:56:14\n",
            "Epochs: 4/20 || Iters: 1400/8500 || Lr: 0.008574 || Train Loss: 0.7083 || mIoU: 0.4026 || Cost Time: 0:11:04 || Estimated Time: 0:56:08\n",
            "Epochs: 4/20 || Iters: 1410/8500 || Lr: 0.008574 || Train Loss: 0.6607 || mIoU: 0.4006 || Cost Time: 0:11:07 || Estimated Time: 0:55:57\n",
            "Epochs: 4/20 || Iters: 1420/8500 || Lr: 0.008574 || Train Loss: 0.7724 || mIoU: 0.4030 || Cost Time: 0:11:12 || Estimated Time: 0:55:52\n",
            "Epochs: 4/20 || Iters: 1430/8500 || Lr: 0.008574 || Train Loss: 0.6378 || mIoU: 0.4017 || Cost Time: 0:11:15 || Estimated Time: 0:55:41\n",
            "Epochs: 4/20 || Iters: 1440/8500 || Lr: 0.008574 || Train Loss: 0.9265 || mIoU: 0.4018 || Cost Time: 0:11:20 || Estimated Time: 0:55:34\n",
            "Epochs: 4/20 || Iters: 1450/8500 || Lr: 0.008574 || Train Loss: 0.6261 || mIoU: 0.3997 || Cost Time: 0:11:23 || Estimated Time: 0:55:24\n",
            "Epochs: 4/20 || Iters: 1460/8500 || Lr: 0.008574 || Train Loss: 0.7136 || mIoU: 0.4007 || Cost Time: 0:11:28 || Estimated Time: 0:55:19\n",
            "Epochs: 4/20 || Iters: 1470/8500 || Lr: 0.008574 || Train Loss: 0.5408 || mIoU: 0.4001 || Cost Time: 0:11:32 || Estimated Time: 0:55:10\n",
            "Epochs: 4/20 || Iters: 1480/8500 || Lr: 0.008574 || Train Loss: 0.6130 || mIoU: 0.4006 || Cost Time: 0:11:36 || Estimated Time: 0:55:04\n",
            "Epochs: 4/20 || Iters: 1490/8500 || Lr: 0.008574 || Train Loss: 0.8090 || mIoU: 0.3997 || Cost Time: 0:11:40 || Estimated Time: 0:54:53\n",
            "Epochs: 4/20 || Iters: 1500/8500 || Lr: 0.008574 || Train Loss: 0.5440 || mIoU: 0.4007 || Cost Time: 0:11:44 || Estimated Time: 0:54:47\n",
            "Epochs: 4/20 || Iters: 1510/8500 || Lr: 0.008574 || Train Loss: 0.8613 || mIoU: 0.3999 || Cost Time: 0:11:48 || Estimated Time: 0:54:40\n",
            "Epochs: 4/20 || Iters: 1520/8500 || Lr: 0.008574 || Train Loss: 0.9385 || mIoU: 0.3988 || Cost Time: 0:11:52 || Estimated Time: 0:54:29\n",
            "Epochs: 4/20 || Iters: 1530/8500 || Lr: 0.008574 || Train Loss: 0.7660 || mIoU: 0.3968 || Cost Time: 0:11:55 || Estimated Time: 0:54:19\n",
            "Epochs: 4/20 || Iters: 1540/8500 || Lr: 0.008574 || Train Loss: 0.7758 || mIoU: 0.3967 || Cost Time: 0:11:59 || Estimated Time: 0:54:13\n",
            "Epochs: 4/20 || Iters: 1550/8500 || Lr: 0.008574 || Train Loss: 1.0701 || mIoU: 0.3961 || Cost Time: 0:12:03 || Estimated Time: 0:54:03\n",
            "Epochs: 4/20 || Iters: 1560/8500 || Lr: 0.008574 || Train Loss: 0.6514 || mIoU: 0.3972 || Cost Time: 0:12:07 || Estimated Time: 0:53:57\n",
            "Epochs: 4/20 || Iters: 1570/8500 || Lr: 0.008574 || Train Loss: 0.5779 || mIoU: 0.3973 || Cost Time: 0:12:11 || Estimated Time: 0:53:48\n",
            "Epochs: 4/20 || Iters: 1580/8500 || Lr: 0.008574 || Train Loss: 0.4758 || mIoU: 0.3973 || Cost Time: 0:12:15 || Estimated Time: 0:53:42\n",
            "Epochs: 4/20 || Iters: 1590/8500 || Lr: 0.008574 || Train Loss: 0.6793 || mIoU: 0.3977 || Cost Time: 0:12:19 || Estimated Time: 0:53:32\n",
            "Epochs: 4/20 || Iters: 1600/8500 || Lr: 0.008574 || Train Loss: 1.0638 || mIoU: 0.3975 || Cost Time: 0:12:23 || Estimated Time: 0:53:28\n",
            "Epochs: 4/20 || Iters: 1610/8500 || Lr: 0.008574 || Train Loss: 0.6530 || mIoU: 0.3980 || Cost Time: 0:12:27 || Estimated Time: 0:53:19\n",
            "Epochs: 4/20 || Iters: 1620/8500 || Lr: 0.008574 || Train Loss: 0.7956 || mIoU: 0.3983 || Cost Time: 0:12:31 || Estimated Time: 0:53:13\n",
            "Epochs: 4/20 || Iters: 1630/8500 || Lr: 0.008574 || Train Loss: 1.1451 || mIoU: 0.3994 || Cost Time: 0:12:35 || Estimated Time: 0:53:05\n",
            "Epochs: 4/20 || Iters: 1640/8500 || Lr: 0.008574 || Train Loss: 0.8233 || mIoU: 0.3993 || Cost Time: 0:12:40 || Estimated Time: 0:52:59\n",
            "Epochs: 4/20 || Iters: 1650/8500 || Lr: 0.008574 || Train Loss: 0.5411 || mIoU: 0.3989 || Cost Time: 0:12:43 || Estimated Time: 0:52:50\n",
            "Epochs: 4/20 || Iters: 1660/8500 || Lr: 0.008574 || Train Loss: 0.7702 || mIoU: 0.3995 || Cost Time: 0:12:48 || Estimated Time: 0:52:44\n",
            "Epochs: 4/20 || Iters: 1670/8500 || Lr: 0.008574 || Train Loss: 0.8767 || mIoU: 0.4003 || Cost Time: 0:12:51 || Estimated Time: 0:52:36\n",
            "Epochs: 4/20 || Iters: 1680/8500 || Lr: 0.008574 || Train Loss: 0.6089 || mIoU: 0.3999 || Cost Time: 0:12:56 || Estimated Time: 0:52:30\n",
            "Epochs: 4/20 || Iters: 1690/8500 || Lr: 0.008574 || Train Loss: 0.6768 || mIoU: 0.3988 || Cost Time: 0:13:00 || Estimated Time: 0:52:24\n",
            "Epochs: 4/20 || Iters: 1700/8500 || Lr: 0.008574 || Train Loss: 0.6352 || mIoU: 0.3989 || Cost Time: 0:13:04 || Estimated Time: 0:52:17\n",
            "Epochs: 4/20, Average loss: 0.717, Average mIoU: 0.398, Average pixAcc: 0.893\n",
            "Validation: Average loss: 0.863, Average mIoU: 0.371, Average pixAcc: 0.866\n",
            "Epochs: 5/20 || Iters: 1710/8500 || Lr: 0.008145 || Train Loss: 0.5121 || mIoU: 0.3819 || Cost Time: 0:13:41 || Estimated Time: 0:54:21\n",
            "Epochs: 5/20 || Iters: 1720/8500 || Lr: 0.008145 || Train Loss: 0.6094 || mIoU: 0.3998 || Cost Time: 0:13:44 || Estimated Time: 0:54:11\n",
            "Epochs: 5/20 || Iters: 1730/8500 || Lr: 0.008145 || Train Loss: 0.5717 || mIoU: 0.3993 || Cost Time: 0:13:49 || Estimated Time: 0:54:05\n",
            "Epochs: 5/20 || Iters: 1740/8500 || Lr: 0.008145 || Train Loss: 0.6953 || mIoU: 0.4078 || Cost Time: 0:13:52 || Estimated Time: 0:53:55\n",
            "Epochs: 5/20 || Iters: 1750/8500 || Lr: 0.008145 || Train Loss: 0.4877 || mIoU: 0.4072 || Cost Time: 0:13:57 || Estimated Time: 0:53:49\n",
            "Epochs: 5/20 || Iters: 1760/8500 || Lr: 0.008145 || Train Loss: 1.5418 || mIoU: 0.4102 || Cost Time: 0:14:00 || Estimated Time: 0:53:39\n",
            "Epochs: 5/20 || Iters: 1770/8500 || Lr: 0.008145 || Train Loss: 0.7511 || mIoU: 0.4108 || Cost Time: 0:14:06 || Estimated Time: 0:53:36\n",
            "Epochs: 5/20 || Iters: 1780/8500 || Lr: 0.008145 || Train Loss: 0.6018 || mIoU: 0.4082 || Cost Time: 0:14:09 || Estimated Time: 0:53:27\n",
            "Epochs: 5/20 || Iters: 1790/8500 || Lr: 0.008145 || Train Loss: 1.0548 || mIoU: 0.4083 || Cost Time: 0:14:13 || Estimated Time: 0:53:20\n",
            "Epochs: 5/20 || Iters: 1800/8500 || Lr: 0.008145 || Train Loss: 0.6589 || mIoU: 0.4061 || Cost Time: 0:14:17 || Estimated Time: 0:53:11\n",
            "Epochs: 5/20 || Iters: 1810/8500 || Lr: 0.008145 || Train Loss: 0.6801 || mIoU: 0.4063 || Cost Time: 0:14:21 || Estimated Time: 0:53:05\n",
            "Epochs: 5/20 || Iters: 1820/8500 || Lr: 0.008145 || Train Loss: 0.7243 || mIoU: 0.4042 || Cost Time: 0:14:25 || Estimated Time: 0:52:56\n",
            "Epochs: 5/20 || Iters: 1830/8500 || Lr: 0.008145 || Train Loss: 0.7866 || mIoU: 0.4049 || Cost Time: 0:14:31 || Estimated Time: 0:52:54\n",
            "Epochs: 5/20 || Iters: 1840/8500 || Lr: 0.008145 || Train Loss: 0.9676 || mIoU: 0.4042 || Cost Time: 0:14:34 || Estimated Time: 0:52:45\n",
            "Epochs: 5/20 || Iters: 1850/8500 || Lr: 0.008145 || Train Loss: 0.6227 || mIoU: 0.4054 || Cost Time: 0:14:38 || Estimated Time: 0:52:39\n",
            "Epochs: 5/20 || Iters: 1860/8500 || Lr: 0.008145 || Train Loss: 0.7743 || mIoU: 0.4039 || Cost Time: 0:14:43 || Estimated Time: 0:52:32\n",
            "Epochs: 5/20 || Iters: 1870/8500 || Lr: 0.008145 || Train Loss: 0.7264 || mIoU: 0.4029 || Cost Time: 0:14:48 || Estimated Time: 0:52:28\n",
            "Epochs: 5/20 || Iters: 1880/8500 || Lr: 0.008145 || Train Loss: 0.8532 || mIoU: 0.4040 || Cost Time: 0:14:51 || Estimated Time: 0:52:18\n",
            "Epochs: 5/20 || Iters: 1890/8500 || Lr: 0.008145 || Train Loss: 0.6473 || mIoU: 0.4044 || Cost Time: 0:14:55 || Estimated Time: 0:52:12\n",
            "Epochs: 5/20 || Iters: 1900/8500 || Lr: 0.008145 || Train Loss: 0.8429 || mIoU: 0.4061 || Cost Time: 0:14:59 || Estimated Time: 0:52:04\n",
            "Epochs: 5/20 || Iters: 1910/8500 || Lr: 0.008145 || Train Loss: 0.5897 || mIoU: 0.4068 || Cost Time: 0:15:04 || Estimated Time: 0:51:59\n",
            "Epochs: 5/20 || Iters: 1920/8500 || Lr: 0.008145 || Train Loss: 0.7363 || mIoU: 0.4061 || Cost Time: 0:15:07 || Estimated Time: 0:51:51\n",
            "Epochs: 5/20 || Iters: 1930/8500 || Lr: 0.008145 || Train Loss: 0.4858 || mIoU: 0.4039 || Cost Time: 0:15:12 || Estimated Time: 0:51:46\n",
            "Epochs: 5/20 || Iters: 1940/8500 || Lr: 0.008145 || Train Loss: 0.6236 || mIoU: 0.4047 || Cost Time: 0:15:16 || Estimated Time: 0:51:38\n",
            "Epochs: 5/20 || Iters: 1950/8500 || Lr: 0.008145 || Train Loss: 0.5263 || mIoU: 0.4040 || Cost Time: 0:15:20 || Estimated Time: 0:51:33\n",
            "Epochs: 5/20 || Iters: 1960/8500 || Lr: 0.008145 || Train Loss: 0.7025 || mIoU: 0.4042 || Cost Time: 0:15:24 || Estimated Time: 0:51:25\n",
            "Epochs: 5/20 || Iters: 1970/8500 || Lr: 0.008145 || Train Loss: 0.6934 || mIoU: 0.4044 || Cost Time: 0:15:29 || Estimated Time: 0:51:19\n",
            "Epochs: 5/20 || Iters: 1980/8500 || Lr: 0.008145 || Train Loss: 0.5956 || mIoU: 0.4046 || Cost Time: 0:15:34 || Estimated Time: 0:51:16\n",
            "Epochs: 5/20 || Iters: 1990/8500 || Lr: 0.008145 || Train Loss: 1.1011 || mIoU: 0.4049 || Cost Time: 0:15:37 || Estimated Time: 0:51:07\n",
            "Epochs: 5/20 || Iters: 2000/8500 || Lr: 0.008145 || Train Loss: 0.7462 || mIoU: 0.4048 || Cost Time: 0:15:42 || Estimated Time: 0:51:02\n",
            "Epochs: 5/20 || Iters: 2010/8500 || Lr: 0.008145 || Train Loss: 0.5696 || mIoU: 0.4064 || Cost Time: 0:15:46 || Estimated Time: 0:50:54\n",
            "Epochs: 5/20 || Iters: 2020/8500 || Lr: 0.008145 || Train Loss: 0.8088 || mIoU: 0.4072 || Cost Time: 0:15:50 || Estimated Time: 0:50:48\n",
            "Epochs: 5/20 || Iters: 2030/8500 || Lr: 0.008145 || Train Loss: 0.7241 || mIoU: 0.4068 || Cost Time: 0:15:53 || Estimated Time: 0:50:40\n",
            "Epochs: 5/20 || Iters: 2040/8500 || Lr: 0.008145 || Train Loss: 0.8953 || mIoU: 0.4079 || Cost Time: 0:15:58 || Estimated Time: 0:50:33\n",
            "Epochs: 5/20 || Iters: 2050/8500 || Lr: 0.008145 || Train Loss: 0.6461 || mIoU: 0.4069 || Cost Time: 0:16:02 || Estimated Time: 0:50:27\n",
            "Epochs: 5/20 || Iters: 2060/8500 || Lr: 0.008145 || Train Loss: 1.0044 || mIoU: 0.4074 || Cost Time: 0:16:06 || Estimated Time: 0:50:20\n",
            "Epochs: 5/20 || Iters: 2070/8500 || Lr: 0.008145 || Train Loss: 0.5682 || mIoU: 0.4088 || Cost Time: 0:16:10 || Estimated Time: 0:50:13\n",
            "Epochs: 5/20 || Iters: 2080/8500 || Lr: 0.008145 || Train Loss: 0.5888 || mIoU: 0.4090 || Cost Time: 0:16:13 || Estimated Time: 0:50:05\n",
            "Epochs: 5/20 || Iters: 2090/8500 || Lr: 0.008145 || Train Loss: 0.6244 || mIoU: 0.4097 || Cost Time: 0:16:18 || Estimated Time: 0:49:59\n",
            "Epochs: 5/20 || Iters: 2100/8500 || Lr: 0.008145 || Train Loss: 0.7580 || mIoU: 0.4100 || Cost Time: 0:16:22 || Estimated Time: 0:49:53\n",
            "Epochs: 5/20 || Iters: 2110/8500 || Lr: 0.008145 || Train Loss: 0.6548 || mIoU: 0.4100 || Cost Time: 0:16:26 || Estimated Time: 0:49:46\n",
            "Epochs: 5/20 || Iters: 2120/8500 || Lr: 0.008145 || Train Loss: 1.0915 || mIoU: 0.4093 || Cost Time: 0:16:29 || Estimated Time: 0:49:38\n",
            "Epochs: 5/20, Average loss: 0.699, Average mIoU: 0.405, Average pixAcc: 0.897\n",
            "Validation: Average loss: 0.823, Average mIoU: 0.378, Average pixAcc: 0.872\n",
            "Epochs: 6/20 || Iters: 2130/8500 || Lr: 0.007738 || Train Loss: 0.5868 || mIoU: 0.4140 || Cost Time: 0:17:06 || Estimated Time: 0:51:08\n",
            "Epochs: 6/20 || Iters: 2140/8500 || Lr: 0.007738 || Train Loss: 1.1304 || mIoU: 0.4029 || Cost Time: 0:17:09 || Estimated Time: 0:51:00\n",
            "Epochs: 6/20 || Iters: 2150/8500 || Lr: 0.007738 || Train Loss: 0.8710 || mIoU: 0.4044 || Cost Time: 0:17:14 || Estimated Time: 0:50:54\n",
            "Epochs: 6/20 || Iters: 2160/8500 || Lr: 0.007738 || Train Loss: 0.6782 || mIoU: 0.4174 || Cost Time: 0:17:18 || Estimated Time: 0:50:47\n",
            "Epochs: 6/20 || Iters: 2170/8500 || Lr: 0.007738 || Train Loss: 0.5525 || mIoU: 0.4160 || Cost Time: 0:17:22 || Estimated Time: 0:50:39\n",
            "Epochs: 6/20 || Iters: 2180/8500 || Lr: 0.007738 || Train Loss: 0.8489 || mIoU: 0.4140 || Cost Time: 0:17:26 || Estimated Time: 0:50:32\n",
            "Epochs: 6/20 || Iters: 2190/8500 || Lr: 0.007738 || Train Loss: 0.6605 || mIoU: 0.4161 || Cost Time: 0:17:30 || Estimated Time: 0:50:25\n",
            "Epochs: 6/20 || Iters: 2200/8500 || Lr: 0.007738 || Train Loss: 0.5840 || mIoU: 0.4138 || Cost Time: 0:17:34 || Estimated Time: 0:50:19\n",
            "Epochs: 6/20 || Iters: 2210/8500 || Lr: 0.007738 || Train Loss: 0.5826 || mIoU: 0.4112 || Cost Time: 0:17:38 || Estimated Time: 0:50:11\n",
            "Epochs: 6/20 || Iters: 2220/8500 || Lr: 0.007738 || Train Loss: 0.6789 || mIoU: 0.4159 || Cost Time: 0:17:42 || Estimated Time: 0:50:04\n",
            "Epochs: 6/20 || Iters: 2230/8500 || Lr: 0.007738 || Train Loss: 0.8573 || mIoU: 0.4115 || Cost Time: 0:17:46 || Estimated Time: 0:49:58\n",
            "Epochs: 6/20 || Iters: 2240/8500 || Lr: 0.007738 || Train Loss: 0.5928 || mIoU: 0.4153 || Cost Time: 0:17:50 || Estimated Time: 0:49:50\n",
            "Epochs: 6/20 || Iters: 2250/8500 || Lr: 0.007738 || Train Loss: 0.5299 || mIoU: 0.4167 || Cost Time: 0:17:54 || Estimated Time: 0:49:43\n",
            "Epochs: 6/20 || Iters: 2260/8500 || Lr: 0.007738 || Train Loss: 0.7600 || mIoU: 0.4178 || Cost Time: 0:17:58 || Estimated Time: 0:49:37\n",
            "Epochs: 6/20 || Iters: 2270/8500 || Lr: 0.007738 || Train Loss: 0.5072 || mIoU: 0.4171 || Cost Time: 0:18:02 || Estimated Time: 0:49:30\n",
            "Epochs: 6/20 || Iters: 2280/8500 || Lr: 0.007738 || Train Loss: 0.6570 || mIoU: 0.4181 || Cost Time: 0:18:06 || Estimated Time: 0:49:23\n",
            "Epochs: 6/20 || Iters: 2290/8500 || Lr: 0.007738 || Train Loss: 0.5524 || mIoU: 0.4164 || Cost Time: 0:18:10 || Estimated Time: 0:49:17\n",
            "Epochs: 6/20 || Iters: 2300/8500 || Lr: 0.007738 || Train Loss: 0.6702 || mIoU: 0.4183 || Cost Time: 0:18:14 || Estimated Time: 0:49:10\n",
            "Epochs: 6/20 || Iters: 2310/8500 || Lr: 0.007738 || Train Loss: 0.6883 || mIoU: 0.4201 || Cost Time: 0:18:18 || Estimated Time: 0:49:04\n",
            "Epochs: 6/20 || Iters: 2320/8500 || Lr: 0.007738 || Train Loss: 0.7782 || mIoU: 0.4183 || Cost Time: 0:18:22 || Estimated Time: 0:48:57\n",
            "Epochs: 6/20 || Iters: 2330/8500 || Lr: 0.007738 || Train Loss: 0.4310 || mIoU: 0.4174 || Cost Time: 0:18:26 || Estimated Time: 0:48:51\n",
            "Epochs: 6/20 || Iters: 2340/8500 || Lr: 0.007738 || Train Loss: 1.1097 || mIoU: 0.4178 || Cost Time: 0:18:30 || Estimated Time: 0:48:44\n",
            "Epochs: 6/20 || Iters: 2350/8500 || Lr: 0.007738 || Train Loss: 0.5560 || mIoU: 0.4174 || Cost Time: 0:18:35 || Estimated Time: 0:48:38\n",
            "Epochs: 6/20 || Iters: 2360/8500 || Lr: 0.007738 || Train Loss: 0.6101 || mIoU: 0.4186 || Cost Time: 0:18:38 || Estimated Time: 0:48:31\n",
            "Epochs: 6/20 || Iters: 2370/8500 || Lr: 0.007738 || Train Loss: 0.7317 || mIoU: 0.4186 || Cost Time: 0:18:43 || Estimated Time: 0:48:25\n",
            "Epochs: 6/20 || Iters: 2380/8500 || Lr: 0.007738 || Train Loss: 0.6893 || mIoU: 0.4185 || Cost Time: 0:18:47 || Estimated Time: 0:48:18\n",
            "Epochs: 6/20 || Iters: 2390/8500 || Lr: 0.007738 || Train Loss: 0.9267 || mIoU: 0.4191 || Cost Time: 0:18:51 || Estimated Time: 0:48:11\n",
            "Epochs: 6/20 || Iters: 2400/8500 || Lr: 0.007738 || Train Loss: 1.2820 || mIoU: 0.4180 || Cost Time: 0:18:55 || Estimated Time: 0:48:05\n",
            "Epochs: 6/20 || Iters: 2410/8500 || Lr: 0.007738 || Train Loss: 0.5782 || mIoU: 0.4174 || Cost Time: 0:18:59 || Estimated Time: 0:47:58\n",
            "Epochs: 6/20 || Iters: 2420/8500 || Lr: 0.007738 || Train Loss: 0.6604 || mIoU: 0.4173 || Cost Time: 0:19:03 || Estimated Time: 0:47:53\n",
            "Epochs: 6/20 || Iters: 2430/8500 || Lr: 0.007738 || Train Loss: 0.6246 || mIoU: 0.4179 || Cost Time: 0:19:07 || Estimated Time: 0:47:45\n",
            "Epochs: 6/20 || Iters: 2440/8500 || Lr: 0.007738 || Train Loss: 0.9295 || mIoU: 0.4171 || Cost Time: 0:19:11 || Estimated Time: 0:47:40\n",
            "Epochs: 6/20 || Iters: 2450/8500 || Lr: 0.007738 || Train Loss: 0.7391 || mIoU: 0.4164 || Cost Time: 0:19:15 || Estimated Time: 0:47:32\n",
            "Epochs: 6/20 || Iters: 2460/8500 || Lr: 0.007738 || Train Loss: 0.5974 || mIoU: 0.4168 || Cost Time: 0:19:19 || Estimated Time: 0:47:28\n",
            "Epochs: 6/20 || Iters: 2470/8500 || Lr: 0.007738 || Train Loss: 0.9221 || mIoU: 0.4175 || Cost Time: 0:19:23 || Estimated Time: 0:47:20\n",
            "Epochs: 6/20 || Iters: 2480/8500 || Lr: 0.007738 || Train Loss: 0.5812 || mIoU: 0.4179 || Cost Time: 0:19:27 || Estimated Time: 0:47:14\n",
            "Epochs: 6/20 || Iters: 2490/8500 || Lr: 0.007738 || Train Loss: 0.6632 || mIoU: 0.4181 || Cost Time: 0:19:31 || Estimated Time: 0:47:07\n",
            "Epochs: 6/20 || Iters: 2500/8500 || Lr: 0.007738 || Train Loss: 0.7574 || mIoU: 0.4183 || Cost Time: 0:19:35 || Estimated Time: 0:47:01\n",
            "Epochs: 6/20 || Iters: 2510/8500 || Lr: 0.007738 || Train Loss: 0.6291 || mIoU: 0.4190 || Cost Time: 0:19:39 || Estimated Time: 0:46:54\n",
            "Epochs: 6/20 || Iters: 2520/8500 || Lr: 0.007738 || Train Loss: 0.3724 || mIoU: 0.4186 || Cost Time: 0:19:43 || Estimated Time: 0:46:49\n",
            "Epochs: 6/20 || Iters: 2530/8500 || Lr: 0.007738 || Train Loss: 0.8935 || mIoU: 0.4185 || Cost Time: 0:19:47 || Estimated Time: 0:46:41\n",
            "Epochs: 6/20 || Iters: 2540/8500 || Lr: 0.007738 || Train Loss: 0.6444 || mIoU: 0.4171 || Cost Time: 0:19:51 || Estimated Time: 0:46:36\n",
            "Epochs: 6/20 || Iters: 2550/8500 || Lr: 0.007738 || Train Loss: 0.6032 || mIoU: 0.4175 || Cost Time: 0:19:55 || Estimated Time: 0:46:29\n",
            "Epochs: 6/20, Average loss: 0.704, Average mIoU: 0.416, Average pixAcc: 0.892\n",
            "Validation: Average loss: 0.824, Average mIoU: 0.381, Average pixAcc: 0.875\n",
            "Epochs: 7/20 || Iters: 2560/8500 || Lr: 0.007351 || Train Loss: 0.5940 || mIoU: 0.4148 || Cost Time: 0:20:31 || Estimated Time: 0:47:37\n",
            "Epochs: 7/20 || Iters: 2570/8500 || Lr: 0.007351 || Train Loss: 0.7221 || mIoU: 0.4228 || Cost Time: 0:20:34 || Estimated Time: 0:47:29\n",
            "Epochs: 7/20 || Iters: 2580/8500 || Lr: 0.007351 || Train Loss: 0.7439 || mIoU: 0.4360 || Cost Time: 0:20:39 || Estimated Time: 0:47:23\n",
            "Epochs: 7/20 || Iters: 2590/8500 || Lr: 0.007351 || Train Loss: 1.0455 || mIoU: 0.4326 || Cost Time: 0:20:42 || Estimated Time: 0:47:16\n",
            "Epochs: 7/20 || Iters: 2600/8500 || Lr: 0.007351 || Train Loss: 0.7312 || mIoU: 0.4308 || Cost Time: 0:20:47 || Estimated Time: 0:47:11\n",
            "Epochs: 7/20 || Iters: 2610/8500 || Lr: 0.007351 || Train Loss: 0.5909 || mIoU: 0.4245 || Cost Time: 0:20:51 || Estimated Time: 0:47:03\n",
            "Epochs: 7/20 || Iters: 2620/8500 || Lr: 0.007351 || Train Loss: 0.5134 || mIoU: 0.4221 || Cost Time: 0:20:55 || Estimated Time: 0:46:58\n",
            "Epochs: 7/20 || Iters: 2630/8500 || Lr: 0.007351 || Train Loss: 0.7347 || mIoU: 0.4206 || Cost Time: 0:20:59 || Estimated Time: 0:46:51\n",
            "Epochs: 7/20 || Iters: 2640/8500 || Lr: 0.007351 || Train Loss: 0.5627 || mIoU: 0.4263 || Cost Time: 0:21:04 || Estimated Time: 0:46:46\n",
            "Epochs: 7/20 || Iters: 2650/8500 || Lr: 0.007351 || Train Loss: 0.5578 || mIoU: 0.4295 || Cost Time: 0:21:07 || Estimated Time: 0:46:38\n",
            "Epochs: 7/20 || Iters: 2660/8500 || Lr: 0.007351 || Train Loss: 0.6228 || mIoU: 0.4276 || Cost Time: 0:21:12 || Estimated Time: 0:46:33\n",
            "Epochs: 7/20 || Iters: 2670/8500 || Lr: 0.007351 || Train Loss: 0.5927 || mIoU: 0.4250 || Cost Time: 0:21:15 || Estimated Time: 0:46:26\n",
            "Epochs: 7/20 || Iters: 2680/8500 || Lr: 0.007351 || Train Loss: 0.4948 || mIoU: 0.4236 || Cost Time: 0:21:20 || Estimated Time: 0:46:20\n",
            "Epochs: 7/20 || Iters: 2690/8500 || Lr: 0.007351 || Train Loss: 1.0047 || mIoU: 0.4240 || Cost Time: 0:21:23 || Estimated Time: 0:46:12\n",
            "Epochs: 7/20 || Iters: 2700/8500 || Lr: 0.007351 || Train Loss: 0.5856 || mIoU: 0.4287 || Cost Time: 0:21:28 || Estimated Time: 0:46:07\n",
            "Epochs: 7/20 || Iters: 2710/8500 || Lr: 0.007351 || Train Loss: 0.8121 || mIoU: 0.4275 || Cost Time: 0:21:31 || Estimated Time: 0:46:00\n",
            "Epochs: 7/20 || Iters: 2720/8500 || Lr: 0.007351 || Train Loss: 0.5675 || mIoU: 0.4254 || Cost Time: 0:21:36 || Estimated Time: 0:45:54\n",
            "Epochs: 7/20 || Iters: 2730/8500 || Lr: 0.007351 || Train Loss: 0.5940 || mIoU: 0.4236 || Cost Time: 0:21:39 || Estimated Time: 0:45:46\n",
            "Epochs: 7/20 || Iters: 2740/8500 || Lr: 0.007351 || Train Loss: 0.7796 || mIoU: 0.4242 || Cost Time: 0:21:44 || Estimated Time: 0:45:42\n",
            "Epochs: 7/20 || Iters: 2750/8500 || Lr: 0.007351 || Train Loss: 0.4802 || mIoU: 0.4230 || Cost Time: 0:21:47 || Estimated Time: 0:45:34\n",
            "Epochs: 7/20 || Iters: 2760/8500 || Lr: 0.007351 || Train Loss: 0.6848 || mIoU: 0.4252 || Cost Time: 0:21:52 || Estimated Time: 0:45:29\n",
            "Epochs: 7/20 || Iters: 2770/8500 || Lr: 0.007351 || Train Loss: 0.9209 || mIoU: 0.4250 || Cost Time: 0:21:56 || Estimated Time: 0:45:22\n",
            "Epochs: 7/20 || Iters: 2780/8500 || Lr: 0.007351 || Train Loss: 0.5449 || mIoU: 0.4252 || Cost Time: 0:22:00 || Estimated Time: 0:45:16\n",
            "Epochs: 7/20 || Iters: 2790/8500 || Lr: 0.007351 || Train Loss: 0.5261 || mIoU: 0.4264 || Cost Time: 0:22:03 || Estimated Time: 0:45:09\n",
            "Epochs: 7/20 || Iters: 2800/8500 || Lr: 0.007351 || Train Loss: 0.7221 || mIoU: 0.4265 || Cost Time: 0:22:08 || Estimated Time: 0:45:04\n",
            "Epochs: 7/20 || Iters: 2810/8500 || Lr: 0.007351 || Train Loss: 0.7675 || mIoU: 0.4255 || Cost Time: 0:22:11 || Estimated Time: 0:44:56\n",
            "Epochs: 7/20 || Iters: 2820/8500 || Lr: 0.007351 || Train Loss: 0.6728 || mIoU: 0.4259 || Cost Time: 0:22:16 || Estimated Time: 0:44:51\n",
            "Epochs: 7/20 || Iters: 2830/8500 || Lr: 0.007351 || Train Loss: 0.7883 || mIoU: 0.4256 || Cost Time: 0:22:20 || Estimated Time: 0:44:44\n",
            "Epochs: 7/20 || Iters: 2840/8500 || Lr: 0.007351 || Train Loss: 1.0675 || mIoU: 0.4256 || Cost Time: 0:22:24 || Estimated Time: 0:44:39\n",
            "Epochs: 7/20 || Iters: 2850/8500 || Lr: 0.007351 || Train Loss: 0.8501 || mIoU: 0.4246 || Cost Time: 0:22:27 || Estimated Time: 0:44:32\n",
            "Epochs: 7/20 || Iters: 2860/8500 || Lr: 0.007351 || Train Loss: 0.6595 || mIoU: 0.4255 || Cost Time: 0:22:32 || Estimated Time: 0:44:26\n",
            "Epochs: 7/20 || Iters: 2870/8500 || Lr: 0.007351 || Train Loss: 0.7044 || mIoU: 0.4262 || Cost Time: 0:22:36 || Estimated Time: 0:44:20\n",
            "Epochs: 7/20 || Iters: 2880/8500 || Lr: 0.007351 || Train Loss: 0.6261 || mIoU: 0.4262 || Cost Time: 0:22:40 || Estimated Time: 0:44:15\n",
            "Epochs: 7/20 || Iters: 2890/8500 || Lr: 0.007351 || Train Loss: 0.7000 || mIoU: 0.4265 || Cost Time: 0:22:44 || Estimated Time: 0:44:08\n",
            "Epochs: 7/20 || Iters: 2900/8500 || Lr: 0.007351 || Train Loss: 0.4567 || mIoU: 0.4269 || Cost Time: 0:22:48 || Estimated Time: 0:44:02\n",
            "Epochs: 7/20 || Iters: 2910/8500 || Lr: 0.007351 || Train Loss: 0.5797 || mIoU: 0.4271 || Cost Time: 0:22:51 || Estimated Time: 0:43:55\n",
            "Epochs: 7/20 || Iters: 2920/8500 || Lr: 0.007351 || Train Loss: 0.8533 || mIoU: 0.4266 || Cost Time: 0:22:56 || Estimated Time: 0:43:50\n",
            "Epochs: 7/20 || Iters: 2930/8500 || Lr: 0.007351 || Train Loss: 0.6172 || mIoU: 0.4275 || Cost Time: 0:23:00 || Estimated Time: 0:43:43\n",
            "Epochs: 7/20 || Iters: 2940/8500 || Lr: 0.007351 || Train Loss: 1.0100 || mIoU: 0.4268 || Cost Time: 0:23:04 || Estimated Time: 0:43:38\n",
            "Epochs: 7/20 || Iters: 2950/8500 || Lr: 0.007351 || Train Loss: 0.7330 || mIoU: 0.4264 || Cost Time: 0:23:08 || Estimated Time: 0:43:31\n",
            "Epochs: 7/20 || Iters: 2960/8500 || Lr: 0.007351 || Train Loss: 0.8968 || mIoU: 0.4265 || Cost Time: 0:23:12 || Estimated Time: 0:43:25\n",
            "Epochs: 7/20 || Iters: 2970/8500 || Lr: 0.007351 || Train Loss: 0.6553 || mIoU: 0.4271 || Cost Time: 0:23:16 || Estimated Time: 0:43:19\n",
            "Epochs: 7/20, Average loss: 0.695, Average mIoU: 0.425, Average pixAcc: 0.897\n",
            "Validation: Average loss: 0.819, Average mIoU: 0.368, Average pixAcc: 0.873\n",
            "Epochs: 8/20 || Iters: 2980/8500 || Lr: 0.006983 || Train Loss: 0.4227 || mIoU: 0.3830 || Cost Time: 0:23:52 || Estimated Time: 0:44:13\n",
            "Epochs: 8/20 || Iters: 2990/8500 || Lr: 0.006983 || Train Loss: 0.9420 || mIoU: 0.4054 || Cost Time: 0:23:56 || Estimated Time: 0:44:06\n",
            "Epochs: 8/20 || Iters: 3000/8500 || Lr: 0.006983 || Train Loss: 0.7958 || mIoU: 0.3992 || Cost Time: 0:24:01 || Estimated Time: 0:44:01\n",
            "Epochs: 8/20 || Iters: 3010/8500 || Lr: 0.006983 || Train Loss: 0.8926 || mIoU: 0.4250 || Cost Time: 0:24:04 || Estimated Time: 0:43:54\n",
            "Epochs: 8/20 || Iters: 3020/8500 || Lr: 0.006983 || Train Loss: 0.6103 || mIoU: 0.4183 || Cost Time: 0:24:09 || Estimated Time: 0:43:49\n",
            "Epochs: 8/20 || Iters: 3030/8500 || Lr: 0.006983 || Train Loss: 0.7245 || mIoU: 0.4261 || Cost Time: 0:24:12 || Estimated Time: 0:43:42\n",
            "Epochs: 8/20 || Iters: 3040/8500 || Lr: 0.006983 || Train Loss: 0.7052 || mIoU: 0.4222 || Cost Time: 0:24:18 || Estimated Time: 0:43:39\n",
            "Epochs: 8/20 || Iters: 3050/8500 || Lr: 0.006983 || Train Loss: 0.7038 || mIoU: 0.4217 || Cost Time: 0:24:23 || Estimated Time: 0:43:34\n",
            "Epochs: 8/20 || Iters: 3060/8500 || Lr: 0.006983 || Train Loss: 0.5282 || mIoU: 0.4221 || Cost Time: 0:24:26 || Estimated Time: 0:43:27\n",
            "Epochs: 8/20 || Iters: 3070/8500 || Lr: 0.006983 || Train Loss: 0.7136 || mIoU: 0.4250 || Cost Time: 0:24:31 || Estimated Time: 0:43:22\n",
            "Epochs: 8/20 || Iters: 3080/8500 || Lr: 0.006983 || Train Loss: 0.7025 || mIoU: 0.4221 || Cost Time: 0:24:34 || Estimated Time: 0:43:15\n",
            "Epochs: 8/20 || Iters: 3090/8500 || Lr: 0.006983 || Train Loss: 0.5391 || mIoU: 0.4240 || Cost Time: 0:24:39 || Estimated Time: 0:43:10\n",
            "Epochs: 8/20 || Iters: 3100/8500 || Lr: 0.006983 || Train Loss: 0.5212 || mIoU: 0.4222 || Cost Time: 0:24:42 || Estimated Time: 0:43:02\n",
            "Epochs: 8/20 || Iters: 3110/8500 || Lr: 0.006983 || Train Loss: 0.6256 || mIoU: 0.4218 || Cost Time: 0:24:47 || Estimated Time: 0:42:57\n",
            "Epochs: 8/20 || Iters: 3120/8500 || Lr: 0.006983 || Train Loss: 0.8819 || mIoU: 0.4237 || Cost Time: 0:24:50 || Estimated Time: 0:42:50\n",
            "Epochs: 8/20 || Iters: 3130/8500 || Lr: 0.006983 || Train Loss: 0.6247 || mIoU: 0.4247 || Cost Time: 0:24:55 || Estimated Time: 0:42:44\n",
            "Epochs: 8/20 || Iters: 3140/8500 || Lr: 0.006983 || Train Loss: 0.8713 || mIoU: 0.4261 || Cost Time: 0:24:58 || Estimated Time: 0:42:37\n",
            "Epochs: 8/20 || Iters: 3150/8500 || Lr: 0.006983 || Train Loss: 0.5609 || mIoU: 0.4259 || Cost Time: 0:25:03 || Estimated Time: 0:42:32\n",
            "Epochs: 8/20 || Iters: 3160/8500 || Lr: 0.006983 || Train Loss: 0.4926 || mIoU: 0.4270 || Cost Time: 0:25:06 || Estimated Time: 0:42:26\n",
            "Epochs: 8/20 || Iters: 3170/8500 || Lr: 0.006983 || Train Loss: 0.5533 || mIoU: 0.4260 || Cost Time: 0:25:11 || Estimated Time: 0:42:20\n",
            "Epochs: 8/20 || Iters: 3180/8500 || Lr: 0.006983 || Train Loss: 0.6798 || mIoU: 0.4247 || Cost Time: 0:25:14 || Estimated Time: 0:42:14\n",
            "Epochs: 8/20 || Iters: 3190/8500 || Lr: 0.006983 || Train Loss: 0.6428 || mIoU: 0.4247 || Cost Time: 0:25:19 || Estimated Time: 0:42:09\n",
            "Epochs: 8/20 || Iters: 3200/8500 || Lr: 0.006983 || Train Loss: 0.6385 || mIoU: 0.4253 || Cost Time: 0:25:22 || Estimated Time: 0:42:02\n",
            "Epochs: 8/20 || Iters: 3210/8500 || Lr: 0.006983 || Train Loss: 0.6650 || mIoU: 0.4250 || Cost Time: 0:25:28 || Estimated Time: 0:41:58\n",
            "Epochs: 8/20 || Iters: 3220/8500 || Lr: 0.006983 || Train Loss: 0.8543 || mIoU: 0.4251 || Cost Time: 0:25:32 || Estimated Time: 0:41:52\n",
            "Epochs: 8/20 || Iters: 3230/8500 || Lr: 0.006983 || Train Loss: 0.5980 || mIoU: 0.4244 || Cost Time: 0:25:36 || Estimated Time: 0:41:47\n",
            "Epochs: 8/20 || Iters: 3240/8500 || Lr: 0.006983 || Train Loss: 0.5913 || mIoU: 0.4242 || Cost Time: 0:25:40 || Estimated Time: 0:41:40\n",
            "Epochs: 8/20 || Iters: 3250/8500 || Lr: 0.006983 || Train Loss: 0.5739 || mIoU: 0.4241 || Cost Time: 0:25:44 || Estimated Time: 0:41:34\n",
            "Epochs: 8/20 || Iters: 3260/8500 || Lr: 0.006983 || Train Loss: 0.6879 || mIoU: 0.4249 || Cost Time: 0:25:48 || Estimated Time: 0:41:29\n",
            "Epochs: 8/20 || Iters: 3270/8500 || Lr: 0.006983 || Train Loss: 0.6408 || mIoU: 0.4243 || Cost Time: 0:25:52 || Estimated Time: 0:41:22\n",
            "Epochs: 8/20 || Iters: 3280/8500 || Lr: 0.006983 || Train Loss: 0.6756 || mIoU: 0.4248 || Cost Time: 0:25:56 || Estimated Time: 0:41:17\n",
            "Epochs: 8/20 || Iters: 3290/8500 || Lr: 0.006983 || Train Loss: 0.7828 || mIoU: 0.4249 || Cost Time: 0:26:00 || Estimated Time: 0:41:11\n",
            "Epochs: 8/20 || Iters: 3300/8500 || Lr: 0.006983 || Train Loss: 0.6867 || mIoU: 0.4249 || Cost Time: 0:26:05 || Estimated Time: 0:41:06\n",
            "Epochs: 8/20 || Iters: 3310/8500 || Lr: 0.006983 || Train Loss: 0.4494 || mIoU: 0.4249 || Cost Time: 0:26:09 || Estimated Time: 0:41:00\n",
            "Epochs: 8/20 || Iters: 3320/8500 || Lr: 0.006983 || Train Loss: 0.3874 || mIoU: 0.4244 || Cost Time: 0:26:13 || Estimated Time: 0:40:55\n",
            "Epochs: 8/20 || Iters: 3330/8500 || Lr: 0.006983 || Train Loss: 0.7298 || mIoU: 0.4256 || Cost Time: 0:26:17 || Estimated Time: 0:40:48\n",
            "Epochs: 8/20 || Iters: 3340/8500 || Lr: 0.006983 || Train Loss: 0.4752 || mIoU: 0.4261 || Cost Time: 0:26:21 || Estimated Time: 0:40:43\n",
            "Epochs: 8/20 || Iters: 3350/8500 || Lr: 0.006983 || Train Loss: 0.7116 || mIoU: 0.4260 || Cost Time: 0:26:24 || Estimated Time: 0:40:36\n",
            "Epochs: 8/20 || Iters: 3360/8500 || Lr: 0.006983 || Train Loss: 0.6473 || mIoU: 0.4269 || Cost Time: 0:26:29 || Estimated Time: 0:40:31\n",
            "Epochs: 8/20 || Iters: 3370/8500 || Lr: 0.006983 || Train Loss: 0.6209 || mIoU: 0.4267 || Cost Time: 0:26:32 || Estimated Time: 0:40:24\n",
            "Epochs: 8/20 || Iters: 3380/8500 || Lr: 0.006983 || Train Loss: 0.5236 || mIoU: 0.4273 || Cost Time: 0:26:37 || Estimated Time: 0:40:19\n",
            "Epochs: 8/20 || Iters: 3390/8500 || Lr: 0.006983 || Train Loss: 0.6929 || mIoU: 0.4275 || Cost Time: 0:26:40 || Estimated Time: 0:40:12\n",
            "Epochs: 8/20 || Iters: 3400/8500 || Lr: 0.006983 || Train Loss: 0.7085 || mIoU: 0.4271 || Cost Time: 0:26:45 || Estimated Time: 0:40:07\n",
            "Epochs: 8/20, Average loss: 0.679, Average mIoU: 0.422, Average pixAcc: 0.900\n",
            "Validation: Average loss: 0.827, Average mIoU: 0.382, Average pixAcc: 0.873\n",
            "Epochs: 9/20 || Iters: 3410/8500 || Lr: 0.006634 || Train Loss: 0.7565 || mIoU: 0.4361 || Cost Time: 0:27:20 || Estimated Time: 0:40:48\n",
            "Epochs: 9/20 || Iters: 3420/8500 || Lr: 0.006634 || Train Loss: 0.6232 || mIoU: 0.4267 || Cost Time: 0:27:24 || Estimated Time: 0:40:43\n",
            "Epochs: 9/20 || Iters: 3430/8500 || Lr: 0.006634 || Train Loss: 0.8086 || mIoU: 0.4397 || Cost Time: 0:27:29 || Estimated Time: 0:40:38\n",
            "Epochs: 9/20 || Iters: 3440/8500 || Lr: 0.006634 || Train Loss: 0.8130 || mIoU: 0.4395 || Cost Time: 0:27:33 || Estimated Time: 0:40:32\n",
            "Epochs: 9/20 || Iters: 3450/8500 || Lr: 0.006634 || Train Loss: 0.8856 || mIoU: 0.4357 || Cost Time: 0:27:37 || Estimated Time: 0:40:26\n",
            "Epochs: 9/20 || Iters: 3460/8500 || Lr: 0.006634 || Train Loss: 0.5512 || mIoU: 0.4300 || Cost Time: 0:27:41 || Estimated Time: 0:40:20\n",
            "Epochs: 9/20 || Iters: 3470/8500 || Lr: 0.006634 || Train Loss: 0.5714 || mIoU: 0.4328 || Cost Time: 0:27:45 || Estimated Time: 0:40:14\n",
            "Epochs: 9/20 || Iters: 3480/8500 || Lr: 0.006634 || Train Loss: 0.5101 || mIoU: 0.4335 || Cost Time: 0:27:49 || Estimated Time: 0:40:08\n",
            "Epochs: 9/20 || Iters: 3490/8500 || Lr: 0.006634 || Train Loss: 0.4785 || mIoU: 0.4334 || Cost Time: 0:27:53 || Estimated Time: 0:40:02\n",
            "Epochs: 9/20 || Iters: 3500/8500 || Lr: 0.006634 || Train Loss: 0.7775 || mIoU: 0.4325 || Cost Time: 0:27:57 || Estimated Time: 0:39:56\n",
            "Epochs: 9/20 || Iters: 3510/8500 || Lr: 0.006634 || Train Loss: 0.5631 || mIoU: 0.4315 || Cost Time: 0:28:01 || Estimated Time: 0:39:50\n",
            "Epochs: 9/20 || Iters: 3520/8500 || Lr: 0.006634 || Train Loss: 0.7890 || mIoU: 0.4258 || Cost Time: 0:28:06 || Estimated Time: 0:39:45\n",
            "Epochs: 9/20 || Iters: 3530/8500 || Lr: 0.006634 || Train Loss: 0.6787 || mIoU: 0.4280 || Cost Time: 0:28:09 || Estimated Time: 0:39:39\n",
            "Epochs: 9/20 || Iters: 3540/8500 || Lr: 0.006634 || Train Loss: 0.6542 || mIoU: 0.4322 || Cost Time: 0:28:15 || Estimated Time: 0:39:35\n",
            "Epochs: 9/20 || Iters: 3550/8500 || Lr: 0.006634 || Train Loss: 0.9538 || mIoU: 0.4304 || Cost Time: 0:28:19 || Estimated Time: 0:39:29\n",
            "Epochs: 9/20 || Iters: 3560/8500 || Lr: 0.006634 || Train Loss: 0.5357 || mIoU: 0.4326 || Cost Time: 0:28:23 || Estimated Time: 0:39:24\n",
            "Epochs: 9/20 || Iters: 3570/8500 || Lr: 0.006634 || Train Loss: 0.9341 || mIoU: 0.4330 || Cost Time: 0:28:28 || Estimated Time: 0:39:19\n",
            "Epochs: 9/20 || Iters: 3580/8500 || Lr: 0.006634 || Train Loss: 0.5670 || mIoU: 0.4329 || Cost Time: 0:28:31 || Estimated Time: 0:39:12\n",
            "Epochs: 9/20 || Iters: 3590/8500 || Lr: 0.006634 || Train Loss: 0.5910 || mIoU: 0.4320 || Cost Time: 0:28:36 || Estimated Time: 0:39:07\n",
            "Epochs: 9/20 || Iters: 3600/8500 || Lr: 0.006634 || Train Loss: 0.8363 || mIoU: 0.4291 || Cost Time: 0:28:40 || Estimated Time: 0:39:01\n",
            "Epochs: 9/20 || Iters: 3610/8500 || Lr: 0.006634 || Train Loss: 0.4159 || mIoU: 0.4280 || Cost Time: 0:28:44 || Estimated Time: 0:38:56\n",
            "Epochs: 9/20 || Iters: 3620/8500 || Lr: 0.006634 || Train Loss: 0.7274 || mIoU: 0.4295 || Cost Time: 0:28:49 || Estimated Time: 0:38:50\n",
            "Epochs: 9/20 || Iters: 3630/8500 || Lr: 0.006634 || Train Loss: 0.7297 || mIoU: 0.4297 || Cost Time: 0:28:52 || Estimated Time: 0:38:44\n",
            "Epochs: 9/20 || Iters: 3640/8500 || Lr: 0.006634 || Train Loss: 0.6599 || mIoU: 0.4298 || Cost Time: 0:28:57 || Estimated Time: 0:38:39\n",
            "Epochs: 9/20 || Iters: 3650/8500 || Lr: 0.006634 || Train Loss: 0.7509 || mIoU: 0.4303 || Cost Time: 0:29:01 || Estimated Time: 0:38:34\n",
            "Epochs: 9/20 || Iters: 3660/8500 || Lr: 0.006634 || Train Loss: 0.7568 || mIoU: 0.4294 || Cost Time: 0:29:06 || Estimated Time: 0:38:29\n",
            "Epochs: 9/20 || Iters: 3670/8500 || Lr: 0.006634 || Train Loss: 0.5014 || mIoU: 0.4296 || Cost Time: 0:29:10 || Estimated Time: 0:38:23\n",
            "Epochs: 9/20 || Iters: 3680/8500 || Lr: 0.006634 || Train Loss: 0.7518 || mIoU: 0.4292 || Cost Time: 0:29:14 || Estimated Time: 0:38:17\n",
            "Epochs: 9/20 || Iters: 3690/8500 || Lr: 0.006634 || Train Loss: 0.5875 || mIoU: 0.4315 || Cost Time: 0:29:20 || Estimated Time: 0:38:14\n",
            "Epochs: 9/20 || Iters: 3700/8500 || Lr: 0.006634 || Train Loss: 0.5484 || mIoU: 0.4307 || Cost Time: 0:29:23 || Estimated Time: 0:38:08\n",
            "Epochs: 9/20 || Iters: 3710/8500 || Lr: 0.006634 || Train Loss: 0.6294 || mIoU: 0.4302 || Cost Time: 0:29:28 || Estimated Time: 0:38:03\n",
            "Epochs: 9/20 || Iters: 3720/8500 || Lr: 0.006634 || Train Loss: 0.9791 || mIoU: 0.4300 || Cost Time: 0:29:32 || Estimated Time: 0:37:57\n",
            "Epochs: 9/20 || Iters: 3730/8500 || Lr: 0.006634 || Train Loss: 0.5735 || mIoU: 0.4311 || Cost Time: 0:29:36 || Estimated Time: 0:37:52\n",
            "Epochs: 9/20 || Iters: 3740/8500 || Lr: 0.006634 || Train Loss: 0.4215 || mIoU: 0.4314 || Cost Time: 0:29:40 || Estimated Time: 0:37:46\n",
            "Epochs: 9/20 || Iters: 3750/8500 || Lr: 0.006634 || Train Loss: 0.8449 || mIoU: 0.4308 || Cost Time: 0:29:45 || Estimated Time: 0:37:41\n",
            "Epochs: 9/20 || Iters: 3760/8500 || Lr: 0.006634 || Train Loss: 0.5712 || mIoU: 0.4329 || Cost Time: 0:29:49 || Estimated Time: 0:37:35\n",
            "Epochs: 9/20 || Iters: 3770/8500 || Lr: 0.006634 || Train Loss: 0.8134 || mIoU: 0.4328 || Cost Time: 0:29:53 || Estimated Time: 0:37:29\n",
            "Epochs: 9/20 || Iters: 3780/8500 || Lr: 0.006634 || Train Loss: 0.5061 || mIoU: 0.4326 || Cost Time: 0:29:57 || Estimated Time: 0:37:24\n",
            "Epochs: 9/20 || Iters: 3790/8500 || Lr: 0.006634 || Train Loss: 0.9941 || mIoU: 0.4321 || Cost Time: 0:30:01 || Estimated Time: 0:37:18\n",
            "Epochs: 9/20 || Iters: 3800/8500 || Lr: 0.006634 || Train Loss: 0.5861 || mIoU: 0.4333 || Cost Time: 0:30:05 || Estimated Time: 0:37:13\n",
            "Epochs: 9/20 || Iters: 3810/8500 || Lr: 0.006634 || Train Loss: 0.6797 || mIoU: 0.4346 || Cost Time: 0:30:09 || Estimated Time: 0:37:07\n",
            "Epochs: 9/20 || Iters: 3820/8500 || Lr: 0.006634 || Train Loss: 0.5544 || mIoU: 0.4336 || Cost Time: 0:30:13 || Estimated Time: 0:37:01\n",
            "Epochs: 9/20, Average loss: 0.680, Average mIoU: 0.431, Average pixAcc: 0.899\n",
            "Validation: Average loss: 0.864, Average mIoU: 0.375, Average pixAcc: 0.859\n",
            "Epochs: 10/20 || Iters: 3830/8500 || Lr: 0.006302 || Train Loss: 0.3844 || mIoU: 0.3888 || Cost Time: 0:30:49 || Estimated Time: 0:37:35\n",
            "Epochs: 10/20 || Iters: 3840/8500 || Lr: 0.006302 || Train Loss: 0.6195 || mIoU: 0.4207 || Cost Time: 0:30:53 || Estimated Time: 0:37:29\n",
            "Epochs: 10/20 || Iters: 3850/8500 || Lr: 0.006302 || Train Loss: 0.7391 || mIoU: 0.4212 || Cost Time: 0:30:57 || Estimated Time: 0:37:23\n",
            "Epochs: 10/20 || Iters: 3860/8500 || Lr: 0.006302 || Train Loss: 0.7783 || mIoU: 0.4322 || Cost Time: 0:31:01 || Estimated Time: 0:37:17\n",
            "Epochs: 10/20 || Iters: 3870/8500 || Lr: 0.006302 || Train Loss: 1.1147 || mIoU: 0.4272 || Cost Time: 0:31:05 || Estimated Time: 0:37:12\n",
            "Epochs: 10/20 || Iters: 3880/8500 || Lr: 0.006302 || Train Loss: 0.4849 || mIoU: 0.4232 || Cost Time: 0:31:09 || Estimated Time: 0:37:05\n",
            "Epochs: 10/20 || Iters: 3890/8500 || Lr: 0.006302 || Train Loss: 0.6783 || mIoU: 0.4212 || Cost Time: 0:31:13 || Estimated Time: 0:37:00\n",
            "Epochs: 10/20 || Iters: 3900/8500 || Lr: 0.006302 || Train Loss: 0.8162 || mIoU: 0.4175 || Cost Time: 0:31:18 || Estimated Time: 0:36:55\n",
            "Epochs: 10/20 || Iters: 3910/8500 || Lr: 0.006302 || Train Loss: 0.6497 || mIoU: 0.4168 || Cost Time: 0:31:21 || Estimated Time: 0:36:49\n",
            "Epochs: 10/20 || Iters: 3920/8500 || Lr: 0.006302 || Train Loss: 0.6963 || mIoU: 0.4212 || Cost Time: 0:31:26 || Estimated Time: 0:36:43\n",
            "Epochs: 10/20 || Iters: 3930/8500 || Lr: 0.006302 || Train Loss: 0.7498 || mIoU: 0.4217 || Cost Time: 0:31:29 || Estimated Time: 0:36:37\n",
            "Epochs: 10/20 || Iters: 3940/8500 || Lr: 0.006302 || Train Loss: 0.6651 || mIoU: 0.4274 || Cost Time: 0:31:34 || Estimated Time: 0:36:32\n",
            "Epochs: 10/20 || Iters: 3950/8500 || Lr: 0.006302 || Train Loss: 0.5876 || mIoU: 0.4295 || Cost Time: 0:31:37 || Estimated Time: 0:36:25\n",
            "Epochs: 10/20 || Iters: 3960/8500 || Lr: 0.006302 || Train Loss: 1.1484 || mIoU: 0.4274 || Cost Time: 0:31:42 || Estimated Time: 0:36:20\n",
            "Epochs: 10/20 || Iters: 3970/8500 || Lr: 0.006302 || Train Loss: 0.4831 || mIoU: 0.4280 || Cost Time: 0:31:45 || Estimated Time: 0:36:14\n",
            "Epochs: 10/20 || Iters: 3980/8500 || Lr: 0.006302 || Train Loss: 0.6645 || mIoU: 0.4279 || Cost Time: 0:31:50 || Estimated Time: 0:36:09\n",
            "Epochs: 10/20 || Iters: 3990/8500 || Lr: 0.006302 || Train Loss: 0.5361 || mIoU: 0.4294 || Cost Time: 0:31:53 || Estimated Time: 0:36:02\n",
            "Epochs: 10/20 || Iters: 4000/8500 || Lr: 0.006302 || Train Loss: 0.9077 || mIoU: 0.4280 || Cost Time: 0:31:57 || Estimated Time: 0:35:57\n",
            "Epochs: 10/20 || Iters: 4010/8500 || Lr: 0.006302 || Train Loss: 0.7465 || mIoU: 0.4314 || Cost Time: 0:32:01 || Estimated Time: 0:35:51\n",
            "Epochs: 10/20 || Iters: 4020/8500 || Lr: 0.006302 || Train Loss: 0.8242 || mIoU: 0.4269 || Cost Time: 0:32:06 || Estimated Time: 0:35:46\n",
            "Epochs: 10/20 || Iters: 4030/8500 || Lr: 0.006302 || Train Loss: 0.9727 || mIoU: 0.4273 || Cost Time: 0:32:09 || Estimated Time: 0:35:40\n",
            "Epochs: 10/20 || Iters: 4040/8500 || Lr: 0.006302 || Train Loss: 0.6644 || mIoU: 0.4256 || Cost Time: 0:32:14 || Estimated Time: 0:35:35\n",
            "Epochs: 10/20 || Iters: 4050/8500 || Lr: 0.006302 || Train Loss: 0.9003 || mIoU: 0.4255 || Cost Time: 0:32:17 || Estimated Time: 0:35:29\n",
            "Epochs: 10/20 || Iters: 4060/8500 || Lr: 0.006302 || Train Loss: 0.5982 || mIoU: 0.4253 || Cost Time: 0:32:24 || Estimated Time: 0:35:26\n",
            "Epochs: 10/20 || Iters: 4070/8500 || Lr: 0.006302 || Train Loss: 0.4834 || mIoU: 0.4244 || Cost Time: 0:32:27 || Estimated Time: 0:35:20\n",
            "Epochs: 10/20 || Iters: 4080/8500 || Lr: 0.006302 || Train Loss: 0.5404 || mIoU: 0.4245 || Cost Time: 0:32:32 || Estimated Time: 0:35:15\n",
            "Epochs: 10/20 || Iters: 4090/8500 || Lr: 0.006302 || Train Loss: 0.8403 || mIoU: 0.4240 || Cost Time: 0:32:36 || Estimated Time: 0:35:09\n",
            "Epochs: 10/20 || Iters: 4100/8500 || Lr: 0.006302 || Train Loss: 0.4885 || mIoU: 0.4238 || Cost Time: 0:32:40 || Estimated Time: 0:35:03\n",
            "Epochs: 10/20 || Iters: 4110/8500 || Lr: 0.006302 || Train Loss: 0.5916 || mIoU: 0.4236 || Cost Time: 0:32:44 || Estimated Time: 0:34:58\n",
            "Epochs: 10/20 || Iters: 4120/8500 || Lr: 0.006302 || Train Loss: 0.5274 || mIoU: 0.4229 || Cost Time: 0:32:48 || Estimated Time: 0:34:52\n",
            "Epochs: 10/20 || Iters: 4130/8500 || Lr: 0.006302 || Train Loss: 0.4952 || mIoU: 0.4227 || Cost Time: 0:32:52 || Estimated Time: 0:34:47\n",
            "Epochs: 10/20 || Iters: 4140/8500 || Lr: 0.006302 || Train Loss: 0.6466 || mIoU: 0.4251 || Cost Time: 0:32:57 || Estimated Time: 0:34:42\n",
            "Epochs: 10/20 || Iters: 4150/8500 || Lr: 0.006302 || Train Loss: 0.5704 || mIoU: 0.4262 || Cost Time: 0:33:01 || Estimated Time: 0:34:36\n",
            "Epochs: 10/20 || Iters: 4160/8500 || Lr: 0.006302 || Train Loss: 0.4496 || mIoU: 0.4275 || Cost Time: 0:33:05 || Estimated Time: 0:34:31\n",
            "Epochs: 10/20 || Iters: 4170/8500 || Lr: 0.006302 || Train Loss: 0.5408 || mIoU: 0.4287 || Cost Time: 0:33:09 || Estimated Time: 0:34:25\n",
            "Epochs: 10/20 || Iters: 4180/8500 || Lr: 0.006302 || Train Loss: 0.5867 || mIoU: 0.4292 || Cost Time: 0:33:14 || Estimated Time: 0:34:20\n",
            "Epochs: 10/20 || Iters: 4190/8500 || Lr: 0.006302 || Train Loss: 0.8232 || mIoU: 0.4288 || Cost Time: 0:33:17 || Estimated Time: 0:34:14\n",
            "Epochs: 10/20 || Iters: 4200/8500 || Lr: 0.006302 || Train Loss: 0.6288 || mIoU: 0.4284 || Cost Time: 0:33:21 || Estimated Time: 0:34:09\n",
            "Epochs: 10/20 || Iters: 4210/8500 || Lr: 0.006302 || Train Loss: 0.5510 || mIoU: 0.4291 || Cost Time: 0:33:25 || Estimated Time: 0:34:03\n",
            "Epochs: 10/20 || Iters: 4220/8500 || Lr: 0.006302 || Train Loss: 0.6415 || mIoU: 0.4292 || Cost Time: 0:33:29 || Estimated Time: 0:33:58\n",
            "Epochs: 10/20 || Iters: 4230/8500 || Lr: 0.006302 || Train Loss: 0.5792 || mIoU: 0.4285 || Cost Time: 0:33:33 || Estimated Time: 0:33:52\n",
            "Epochs: 10/20 || Iters: 4240/8500 || Lr: 0.006302 || Train Loss: 0.7246 || mIoU: 0.4280 || Cost Time: 0:33:37 || Estimated Time: 0:33:47\n",
            "Epochs: 10/20 || Iters: 4250/8500 || Lr: 0.006302 || Train Loss: 0.6541 || mIoU: 0.4283 || Cost Time: 0:33:41 || Estimated Time: 0:33:41\n",
            "Epochs: 10/20, Average loss: 0.680, Average mIoU: 0.425, Average pixAcc: 0.899\n",
            "Validation: Average loss: 0.829, Average mIoU: 0.382, Average pixAcc: 0.871\n",
            "Epochs: 11/20 || Iters: 4260/8500 || Lr: 0.005987 || Train Loss: 0.4609 || mIoU: 0.3965 || Cost Time: 0:34:17 || Estimated Time: 0:34:07\n",
            "Epochs: 11/20 || Iters: 4270/8500 || Lr: 0.005987 || Train Loss: 0.7074 || mIoU: 0.4016 || Cost Time: 0:34:21 || Estimated Time: 0:34:01\n",
            "Epochs: 11/20 || Iters: 4280/8500 || Lr: 0.005987 || Train Loss: 0.7677 || mIoU: 0.3985 || Cost Time: 0:34:25 || Estimated Time: 0:33:56\n",
            "Epochs: 11/20 || Iters: 4290/8500 || Lr: 0.005987 || Train Loss: 0.6474 || mIoU: 0.4348 || Cost Time: 0:34:29 || Estimated Time: 0:33:50\n",
            "Epochs: 11/20 || Iters: 4300/8500 || Lr: 0.005987 || Train Loss: 0.5232 || mIoU: 0.4347 || Cost Time: 0:34:33 || Estimated Time: 0:33:45\n",
            "Epochs: 11/20 || Iters: 4310/8500 || Lr: 0.005987 || Train Loss: 0.5510 || mIoU: 0.4352 || Cost Time: 0:34:37 || Estimated Time: 0:33:39\n",
            "Epochs: 11/20 || Iters: 4320/8500 || Lr: 0.005987 || Train Loss: 0.6422 || mIoU: 0.4319 || Cost Time: 0:34:42 || Estimated Time: 0:33:34\n",
            "Epochs: 11/20 || Iters: 4330/8500 || Lr: 0.005987 || Train Loss: 0.5754 || mIoU: 0.4311 || Cost Time: 0:34:46 || Estimated Time: 0:33:29\n",
            "Epochs: 11/20 || Iters: 4340/8500 || Lr: 0.005987 || Train Loss: 0.5086 || mIoU: 0.4319 || Cost Time: 0:34:50 || Estimated Time: 0:33:23\n",
            "Epochs: 11/20 || Iters: 4350/8500 || Lr: 0.005987 || Train Loss: 0.7782 || mIoU: 0.4308 || Cost Time: 0:34:54 || Estimated Time: 0:33:18\n",
            "Epochs: 11/20 || Iters: 4360/8500 || Lr: 0.005987 || Train Loss: 0.7459 || mIoU: 0.4295 || Cost Time: 0:34:59 || Estimated Time: 0:33:13\n",
            "Epochs: 11/20 || Iters: 4370/8500 || Lr: 0.005987 || Train Loss: 0.7203 || mIoU: 0.4309 || Cost Time: 0:35:03 || Estimated Time: 0:33:07\n",
            "Epochs: 11/20 || Iters: 4380/8500 || Lr: 0.005987 || Train Loss: 0.5039 || mIoU: 0.4313 || Cost Time: 0:35:07 || Estimated Time: 0:33:02\n",
            "Epochs: 11/20 || Iters: 4390/8500 || Lr: 0.005987 || Train Loss: 0.4944 || mIoU: 0.4307 || Cost Time: 0:35:11 || Estimated Time: 0:32:56\n",
            "Epochs: 11/20 || Iters: 4400/8500 || Lr: 0.005987 || Train Loss: 0.5124 || mIoU: 0.4310 || Cost Time: 0:35:15 || Estimated Time: 0:32:51\n",
            "Epochs: 11/20 || Iters: 4410/8500 || Lr: 0.005987 || Train Loss: 0.6668 || mIoU: 0.4322 || Cost Time: 0:35:19 || Estimated Time: 0:32:45\n",
            "Epochs: 11/20 || Iters: 4420/8500 || Lr: 0.005987 || Train Loss: 0.6224 || mIoU: 0.4325 || Cost Time: 0:35:23 || Estimated Time: 0:32:40\n",
            "Epochs: 11/20 || Iters: 4430/8500 || Lr: 0.005987 || Train Loss: 0.6142 || mIoU: 0.4323 || Cost Time: 0:35:27 || Estimated Time: 0:32:34\n",
            "Epochs: 11/20 || Iters: 4440/8500 || Lr: 0.005987 || Train Loss: 0.8153 || mIoU: 0.4328 || Cost Time: 0:35:32 || Estimated Time: 0:32:29\n",
            "Epochs: 11/20 || Iters: 4450/8500 || Lr: 0.005987 || Train Loss: 1.0227 || mIoU: 0.4323 || Cost Time: 0:35:35 || Estimated Time: 0:32:23\n",
            "Epochs: 11/20 || Iters: 4460/8500 || Lr: 0.005987 || Train Loss: 0.7080 || mIoU: 0.4311 || Cost Time: 0:35:40 || Estimated Time: 0:32:18\n",
            "Epochs: 11/20 || Iters: 4470/8500 || Lr: 0.005987 || Train Loss: 0.6538 || mIoU: 0.4316 || Cost Time: 0:35:43 || Estimated Time: 0:32:12\n",
            "Epochs: 11/20 || Iters: 4480/8500 || Lr: 0.005987 || Train Loss: 0.7739 || mIoU: 0.4332 || Cost Time: 0:35:49 || Estimated Time: 0:32:08\n",
            "Epochs: 11/20 || Iters: 4490/8500 || Lr: 0.005987 || Train Loss: 0.4570 || mIoU: 0.4345 || Cost Time: 0:35:52 || Estimated Time: 0:32:02\n",
            "Epochs: 11/20 || Iters: 4500/8500 || Lr: 0.005987 || Train Loss: 0.7315 || mIoU: 0.4338 || Cost Time: 0:35:57 || Estimated Time: 0:31:57\n",
            "Epochs: 11/20 || Iters: 4510/8500 || Lr: 0.005987 || Train Loss: 0.7704 || mIoU: 0.4343 || Cost Time: 0:36:00 || Estimated Time: 0:31:51\n",
            "Epochs: 11/20 || Iters: 4520/8500 || Lr: 0.005987 || Train Loss: 0.5483 || mIoU: 0.4347 || Cost Time: 0:36:05 || Estimated Time: 0:31:46\n",
            "Epochs: 11/20 || Iters: 4530/8500 || Lr: 0.005987 || Train Loss: 0.7319 || mIoU: 0.4343 || Cost Time: 0:36:08 || Estimated Time: 0:31:40\n",
            "Epochs: 11/20 || Iters: 4540/8500 || Lr: 0.005987 || Train Loss: 0.6716 || mIoU: 0.4341 || Cost Time: 0:36:13 || Estimated Time: 0:31:35\n",
            "Epochs: 11/20 || Iters: 4550/8500 || Lr: 0.005987 || Train Loss: 0.6106 || mIoU: 0.4346 || Cost Time: 0:36:16 || Estimated Time: 0:31:29\n",
            "Epochs: 11/20 || Iters: 4560/8500 || Lr: 0.005987 || Train Loss: 0.6257 || mIoU: 0.4349 || Cost Time: 0:36:21 || Estimated Time: 0:31:24\n",
            "Epochs: 11/20 || Iters: 4570/8500 || Lr: 0.005987 || Train Loss: 0.7056 || mIoU: 0.4365 || Cost Time: 0:36:25 || Estimated Time: 0:31:19\n",
            "Epochs: 11/20 || Iters: 4580/8500 || Lr: 0.005987 || Train Loss: 1.3799 || mIoU: 0.4361 || Cost Time: 0:36:29 || Estimated Time: 0:31:13\n",
            "Epochs: 11/20 || Iters: 4590/8500 || Lr: 0.005987 || Train Loss: 0.6678 || mIoU: 0.4354 || Cost Time: 0:36:32 || Estimated Time: 0:31:07\n",
            "Epochs: 11/20 || Iters: 4600/8500 || Lr: 0.005987 || Train Loss: 0.8667 || mIoU: 0.4360 || Cost Time: 0:36:37 || Estimated Time: 0:31:02\n",
            "Epochs: 11/20 || Iters: 4610/8500 || Lr: 0.005987 || Train Loss: 0.7786 || mIoU: 0.4367 || Cost Time: 0:36:40 || Estimated Time: 0:30:57\n",
            "Epochs: 11/20 || Iters: 4620/8500 || Lr: 0.005987 || Train Loss: 0.5725 || mIoU: 0.4364 || Cost Time: 0:36:45 || Estimated Time: 0:30:52\n",
            "Epochs: 11/20 || Iters: 4630/8500 || Lr: 0.005987 || Train Loss: 0.5288 || mIoU: 0.4364 || Cost Time: 0:36:48 || Estimated Time: 0:30:46\n",
            "Epochs: 11/20 || Iters: 4640/8500 || Lr: 0.005987 || Train Loss: 0.6990 || mIoU: 0.4356 || Cost Time: 0:36:53 || Estimated Time: 0:30:41\n",
            "Epochs: 11/20 || Iters: 4650/8500 || Lr: 0.005987 || Train Loss: 0.5220 || mIoU: 0.4360 || Cost Time: 0:36:56 || Estimated Time: 0:30:35\n",
            "Epochs: 11/20 || Iters: 4660/8500 || Lr: 0.005987 || Train Loss: 0.7231 || mIoU: 0.4362 || Cost Time: 0:37:01 || Estimated Time: 0:30:30\n",
            "Epochs: 11/20 || Iters: 4670/8500 || Lr: 0.005987 || Train Loss: 0.6095 || mIoU: 0.4359 || Cost Time: 0:37:05 || Estimated Time: 0:30:24\n",
            "Epochs: 11/20, Average loss: 0.675, Average mIoU: 0.430, Average pixAcc: 0.899\n",
            "Validation: Average loss: 0.816, Average mIoU: 0.394, Average pixAcc: 0.874\n",
            "Epochs: 12/20 || Iters: 4680/8500 || Lr: 0.005688 || Train Loss: 0.4713 || mIoU: 0.4485 || Cost Time: 0:37:41 || Estimated Time: 0:30:45\n",
            "Epochs: 12/20 || Iters: 4690/8500 || Lr: 0.005688 || Train Loss: 0.6998 || mIoU: 0.4596 || Cost Time: 0:37:44 || Estimated Time: 0:30:39\n",
            "Epochs: 12/20 || Iters: 4700/8500 || Lr: 0.005688 || Train Loss: 0.5998 || mIoU: 0.4441 || Cost Time: 0:37:49 || Estimated Time: 0:30:34\n",
            "Epochs: 12/20 || Iters: 4710/8500 || Lr: 0.005688 || Train Loss: 0.7629 || mIoU: 0.4401 || Cost Time: 0:37:53 || Estimated Time: 0:30:29\n",
            "Epochs: 12/20 || Iters: 4720/8500 || Lr: 0.005688 || Train Loss: 1.0335 || mIoU: 0.4417 || Cost Time: 0:37:57 || Estimated Time: 0:30:23\n",
            "Epochs: 12/20 || Iters: 4730/8500 || Lr: 0.005688 || Train Loss: 0.5151 || mIoU: 0.4497 || Cost Time: 0:38:01 || Estimated Time: 0:30:18\n",
            "Epochs: 12/20 || Iters: 4740/8500 || Lr: 0.005688 || Train Loss: 0.6722 || mIoU: 0.4468 || Cost Time: 0:38:05 || Estimated Time: 0:30:12\n",
            "Epochs: 12/20 || Iters: 4750/8500 || Lr: 0.005688 || Train Loss: 0.5378 || mIoU: 0.4483 || Cost Time: 0:38:09 || Estimated Time: 0:30:07\n",
            "Epochs: 12/20 || Iters: 4760/8500 || Lr: 0.005688 || Train Loss: 0.6347 || mIoU: 0.4505 || Cost Time: 0:38:14 || Estimated Time: 0:30:02\n",
            "Epochs: 12/20 || Iters: 4770/8500 || Lr: 0.005688 || Train Loss: 0.7787 || mIoU: 0.4480 || Cost Time: 0:38:17 || Estimated Time: 0:29:56\n",
            "Epochs: 12/20 || Iters: 4780/8500 || Lr: 0.005688 || Train Loss: 0.7552 || mIoU: 0.4423 || Cost Time: 0:38:22 || Estimated Time: 0:29:51\n",
            "Epochs: 12/20 || Iters: 4790/8500 || Lr: 0.005688 || Train Loss: 0.4738 || mIoU: 0.4385 || Cost Time: 0:38:25 || Estimated Time: 0:29:45\n",
            "Epochs: 12/20 || Iters: 4800/8500 || Lr: 0.005688 || Train Loss: 1.1157 || mIoU: 0.4360 || Cost Time: 0:38:30 || Estimated Time: 0:29:40\n",
            "Epochs: 12/20 || Iters: 4810/8500 || Lr: 0.005688 || Train Loss: 0.4523 || mIoU: 0.4349 || Cost Time: 0:38:34 || Estimated Time: 0:29:35\n",
            "Epochs: 12/20 || Iters: 4820/8500 || Lr: 0.005688 || Train Loss: 0.7901 || mIoU: 0.4344 || Cost Time: 0:38:38 || Estimated Time: 0:29:30\n",
            "Epochs: 12/20 || Iters: 4830/8500 || Lr: 0.005688 || Train Loss: 0.5236 || mIoU: 0.4340 || Cost Time: 0:38:41 || Estimated Time: 0:29:24\n",
            "Epochs: 12/20 || Iters: 4840/8500 || Lr: 0.005688 || Train Loss: 0.4735 || mIoU: 0.4327 || Cost Time: 0:38:46 || Estimated Time: 0:29:19\n",
            "Epochs: 12/20 || Iters: 4850/8500 || Lr: 0.005688 || Train Loss: 0.7257 || mIoU: 0.4327 || Cost Time: 0:38:50 || Estimated Time: 0:29:13\n",
            "Epochs: 12/20 || Iters: 4860/8500 || Lr: 0.005688 || Train Loss: 0.4245 || mIoU: 0.4317 || Cost Time: 0:38:54 || Estimated Time: 0:29:08\n",
            "Epochs: 12/20 || Iters: 4870/8500 || Lr: 0.005688 || Train Loss: 0.4921 || mIoU: 0.4298 || Cost Time: 0:38:58 || Estimated Time: 0:29:02\n",
            "Epochs: 12/20 || Iters: 4880/8500 || Lr: 0.005688 || Train Loss: 0.6700 || mIoU: 0.4299 || Cost Time: 0:39:02 || Estimated Time: 0:28:57\n",
            "Epochs: 12/20 || Iters: 4890/8500 || Lr: 0.005688 || Train Loss: 0.4780 || mIoU: 0.4304 || Cost Time: 0:39:06 || Estimated Time: 0:28:51\n",
            "Epochs: 12/20 || Iters: 4900/8500 || Lr: 0.005688 || Train Loss: 0.6447 || mIoU: 0.4304 || Cost Time: 0:39:10 || Estimated Time: 0:28:46\n",
            "Epochs: 12/20 || Iters: 4910/8500 || Lr: 0.005688 || Train Loss: 0.5202 || mIoU: 0.4314 || Cost Time: 0:39:14 || Estimated Time: 0:28:41\n",
            "Epochs: 12/20 || Iters: 4920/8500 || Lr: 0.005688 || Train Loss: 0.5605 || mIoU: 0.4313 || Cost Time: 0:39:18 || Estimated Time: 0:28:36\n",
            "Epochs: 12/20 || Iters: 4930/8500 || Lr: 0.005688 || Train Loss: 0.5155 || mIoU: 0.4320 || Cost Time: 0:39:21 || Estimated Time: 0:28:30\n",
            "Epochs: 12/20 || Iters: 4940/8500 || Lr: 0.005688 || Train Loss: 0.6213 || mIoU: 0.4313 || Cost Time: 0:39:26 || Estimated Time: 0:28:25\n",
            "Epochs: 12/20 || Iters: 4950/8500 || Lr: 0.005688 || Train Loss: 0.5174 || mIoU: 0.4310 || Cost Time: 0:39:29 || Estimated Time: 0:28:19\n",
            "Epochs: 12/20 || Iters: 4960/8500 || Lr: 0.005688 || Train Loss: 0.6578 || mIoU: 0.4310 || Cost Time: 0:39:34 || Estimated Time: 0:28:14\n",
            "Epochs: 12/20 || Iters: 4970/8500 || Lr: 0.005688 || Train Loss: 1.0081 || mIoU: 0.4309 || Cost Time: 0:39:38 || Estimated Time: 0:28:09\n",
            "Epochs: 12/20 || Iters: 4980/8500 || Lr: 0.005688 || Train Loss: 0.5687 || mIoU: 0.4298 || Cost Time: 0:39:42 || Estimated Time: 0:28:04\n",
            "Epochs: 12/20 || Iters: 4990/8500 || Lr: 0.005688 || Train Loss: 1.0158 || mIoU: 0.4306 || Cost Time: 0:39:46 || Estimated Time: 0:27:58\n",
            "Epochs: 12/20 || Iters: 5000/8500 || Lr: 0.005688 || Train Loss: 0.7415 || mIoU: 0.4310 || Cost Time: 0:39:50 || Estimated Time: 0:27:53\n",
            "Epochs: 12/20 || Iters: 5010/8500 || Lr: 0.005688 || Train Loss: 0.7425 || mIoU: 0.4307 || Cost Time: 0:39:54 || Estimated Time: 0:27:48\n",
            "Epochs: 12/20 || Iters: 5020/8500 || Lr: 0.005688 || Train Loss: 0.6571 || mIoU: 0.4312 || Cost Time: 0:39:59 || Estimated Time: 0:27:43\n",
            "Epochs: 12/20 || Iters: 5030/8500 || Lr: 0.005688 || Train Loss: 0.5831 || mIoU: 0.4302 || Cost Time: 0:40:02 || Estimated Time: 0:27:37\n",
            "Epochs: 12/20 || Iters: 5040/8500 || Lr: 0.005688 || Train Loss: 0.6846 || mIoU: 0.4305 || Cost Time: 0:40:06 || Estimated Time: 0:27:32\n",
            "Epochs: 12/20 || Iters: 5050/8500 || Lr: 0.005688 || Train Loss: 0.7465 || mIoU: 0.4308 || Cost Time: 0:40:10 || Estimated Time: 0:27:26\n",
            "Epochs: 12/20 || Iters: 5060/8500 || Lr: 0.005688 || Train Loss: 0.4743 || mIoU: 0.4317 || Cost Time: 0:40:16 || Estimated Time: 0:27:22\n",
            "Epochs: 12/20 || Iters: 5070/8500 || Lr: 0.005688 || Train Loss: 0.5124 || mIoU: 0.4324 || Cost Time: 0:40:19 || Estimated Time: 0:27:16\n",
            "Epochs: 12/20 || Iters: 5080/8500 || Lr: 0.005688 || Train Loss: 0.7148 || mIoU: 0.4331 || Cost Time: 0:40:24 || Estimated Time: 0:27:12\n",
            "Epochs: 12/20 || Iters: 5090/8500 || Lr: 0.005688 || Train Loss: 0.6016 || mIoU: 0.4338 || Cost Time: 0:40:27 || Estimated Time: 0:27:06\n",
            "Epochs: 12/20 || Iters: 5100/8500 || Lr: 0.005688 || Train Loss: 0.6175 || mIoU: 0.4342 || Cost Time: 0:40:31 || Estimated Time: 0:27:01\n",
            "Epochs: 12/20, Average loss: 0.677, Average mIoU: 0.436, Average pixAcc: 0.902\n",
            "Validation: Average loss: 0.801, Average mIoU: 0.394, Average pixAcc: 0.877\n",
            "Epochs: 13/20 || Iters: 5110/8500 || Lr: 0.005404 || Train Loss: 0.7837 || mIoU: 0.4039 || Cost Time: 0:41:08 || Estimated Time: 0:27:17\n",
            "Epochs: 13/20 || Iters: 5120/8500 || Lr: 0.005404 || Train Loss: 0.4688 || mIoU: 0.3943 || Cost Time: 0:41:12 || Estimated Time: 0:27:12\n",
            "Epochs: 13/20 || Iters: 5130/8500 || Lr: 0.005404 || Train Loss: 0.5220 || mIoU: 0.4223 || Cost Time: 0:41:16 || Estimated Time: 0:27:07\n",
            "Epochs: 13/20 || Iters: 5140/8500 || Lr: 0.005404 || Train Loss: 0.8366 || mIoU: 0.4218 || Cost Time: 0:41:20 || Estimated Time: 0:27:01\n",
            "Epochs: 13/20 || Iters: 5150/8500 || Lr: 0.005404 || Train Loss: 0.6539 || mIoU: 0.4248 || Cost Time: 0:41:24 || Estimated Time: 0:26:56\n",
            "Epochs: 13/20 || Iters: 5160/8500 || Lr: 0.005404 || Train Loss: 0.6012 || mIoU: 0.4277 || Cost Time: 0:41:28 || Estimated Time: 0:26:50\n",
            "Epochs: 13/20 || Iters: 5170/8500 || Lr: 0.005404 || Train Loss: 0.6382 || mIoU: 0.4265 || Cost Time: 0:41:33 || Estimated Time: 0:26:45\n",
            "Epochs: 13/20 || Iters: 5180/8500 || Lr: 0.005404 || Train Loss: 0.5213 || mIoU: 0.4278 || Cost Time: 0:41:36 || Estimated Time: 0:26:40\n",
            "Epochs: 13/20 || Iters: 5190/8500 || Lr: 0.005404 || Train Loss: 0.5268 || mIoU: 0.4352 || Cost Time: 0:41:41 || Estimated Time: 0:26:35\n",
            "Epochs: 13/20 || Iters: 5200/8500 || Lr: 0.005404 || Train Loss: 0.4804 || mIoU: 0.4339 || Cost Time: 0:41:44 || Estimated Time: 0:26:29\n",
            "Epochs: 13/20 || Iters: 5210/8500 || Lr: 0.005404 || Train Loss: 0.5119 || mIoU: 0.4331 || Cost Time: 0:41:48 || Estimated Time: 0:26:24\n",
            "Epochs: 13/20 || Iters: 5220/8500 || Lr: 0.005404 || Train Loss: 0.5156 || mIoU: 0.4364 || Cost Time: 0:41:52 || Estimated Time: 0:26:18\n",
            "Epochs: 13/20 || Iters: 5230/8500 || Lr: 0.005404 || Train Loss: 0.8266 || mIoU: 0.4378 || Cost Time: 0:41:57 || Estimated Time: 0:26:13\n",
            "Epochs: 13/20 || Iters: 5240/8500 || Lr: 0.005404 || Train Loss: 0.4664 || mIoU: 0.4362 || Cost Time: 0:42:00 || Estimated Time: 0:26:08\n",
            "Epochs: 13/20 || Iters: 5250/8500 || Lr: 0.005404 || Train Loss: 0.6726 || mIoU: 0.4383 || Cost Time: 0:42:05 || Estimated Time: 0:26:03\n",
            "Epochs: 13/20 || Iters: 5260/8500 || Lr: 0.005404 || Train Loss: 0.7669 || mIoU: 0.4384 || Cost Time: 0:42:09 || Estimated Time: 0:25:58\n",
            "Epochs: 13/20 || Iters: 5270/8500 || Lr: 0.005404 || Train Loss: 0.5589 || mIoU: 0.4373 || Cost Time: 0:42:13 || Estimated Time: 0:25:52\n",
            "Epochs: 13/20 || Iters: 5280/8500 || Lr: 0.005404 || Train Loss: 0.7804 || mIoU: 0.4363 || Cost Time: 0:42:17 || Estimated Time: 0:25:47\n",
            "Epochs: 13/20 || Iters: 5290/8500 || Lr: 0.005404 || Train Loss: 0.8997 || mIoU: 0.4378 || Cost Time: 0:42:21 || Estimated Time: 0:25:42\n",
            "Epochs: 13/20 || Iters: 5300/8500 || Lr: 0.005404 || Train Loss: 0.7971 || mIoU: 0.4370 || Cost Time: 0:42:24 || Estimated Time: 0:25:36\n",
            "Epochs: 13/20 || Iters: 5310/8500 || Lr: 0.005404 || Train Loss: 0.7029 || mIoU: 0.4380 || Cost Time: 0:42:29 || Estimated Time: 0:25:31\n",
            "Epochs: 13/20 || Iters: 5320/8500 || Lr: 0.005404 || Train Loss: 0.6215 || mIoU: 0.4393 || Cost Time: 0:42:32 || Estimated Time: 0:25:25\n",
            "Epochs: 13/20 || Iters: 5330/8500 || Lr: 0.005404 || Train Loss: 0.4365 || mIoU: 0.4405 || Cost Time: 0:42:37 || Estimated Time: 0:25:21\n",
            "Epochs: 13/20 || Iters: 5340/8500 || Lr: 0.005404 || Train Loss: 0.5828 || mIoU: 0.4412 || Cost Time: 0:42:40 || Estimated Time: 0:25:15\n",
            "Epochs: 13/20 || Iters: 5350/8500 || Lr: 0.005404 || Train Loss: 0.5310 || mIoU: 0.4403 || Cost Time: 0:42:46 || Estimated Time: 0:25:10\n",
            "Epochs: 13/20 || Iters: 5360/8500 || Lr: 0.005404 || Train Loss: 0.5157 || mIoU: 0.4403 || Cost Time: 0:42:49 || Estimated Time: 0:25:05\n",
            "Epochs: 13/20 || Iters: 5370/8500 || Lr: 0.005404 || Train Loss: 0.6962 || mIoU: 0.4396 || Cost Time: 0:42:54 || Estimated Time: 0:25:00\n",
            "Epochs: 13/20 || Iters: 5380/8500 || Lr: 0.005404 || Train Loss: 0.4795 || mIoU: 0.4393 || Cost Time: 0:42:57 || Estimated Time: 0:24:54\n",
            "Epochs: 13/20 || Iters: 5390/8500 || Lr: 0.005404 || Train Loss: 0.4836 || mIoU: 0.4397 || Cost Time: 0:43:02 || Estimated Time: 0:24:50\n",
            "Epochs: 13/20 || Iters: 5400/8500 || Lr: 0.005404 || Train Loss: 0.9279 || mIoU: 0.4396 || Cost Time: 0:43:06 || Estimated Time: 0:24:44\n",
            "Epochs: 13/20 || Iters: 5410/8500 || Lr: 0.005404 || Train Loss: 0.6721 || mIoU: 0.4422 || Cost Time: 0:43:10 || Estimated Time: 0:24:39\n",
            "Epochs: 13/20 || Iters: 5420/8500 || Lr: 0.005404 || Train Loss: 0.5666 || mIoU: 0.4410 || Cost Time: 0:43:14 || Estimated Time: 0:24:34\n",
            "Epochs: 13/20 || Iters: 5430/8500 || Lr: 0.005404 || Train Loss: 0.6912 || mIoU: 0.4415 || Cost Time: 0:43:19 || Estimated Time: 0:24:29\n",
            "Epochs: 13/20 || Iters: 5440/8500 || Lr: 0.005404 || Train Loss: 0.4472 || mIoU: 0.4404 || Cost Time: 0:43:22 || Estimated Time: 0:24:24\n",
            "Epochs: 13/20 || Iters: 5450/8500 || Lr: 0.005404 || Train Loss: 0.6463 || mIoU: 0.4399 || Cost Time: 0:43:27 || Estimated Time: 0:24:19\n",
            "Epochs: 13/20 || Iters: 5460/8500 || Lr: 0.005404 || Train Loss: 0.4644 || mIoU: 0.4391 || Cost Time: 0:43:31 || Estimated Time: 0:24:13\n",
            "Epochs: 13/20 || Iters: 5470/8500 || Lr: 0.005404 || Train Loss: 0.6122 || mIoU: 0.4394 || Cost Time: 0:43:36 || Estimated Time: 0:24:09\n",
            "Epochs: 13/20 || Iters: 5480/8500 || Lr: 0.005404 || Train Loss: 0.8245 || mIoU: 0.4399 || Cost Time: 0:43:39 || Estimated Time: 0:24:03\n",
            "Epochs: 13/20 || Iters: 5490/8500 || Lr: 0.005404 || Train Loss: 1.0464 || mIoU: 0.4403 || Cost Time: 0:43:43 || Estimated Time: 0:23:58\n",
            "Epochs: 13/20 || Iters: 5500/8500 || Lr: 0.005404 || Train Loss: 0.6605 || mIoU: 0.4400 || Cost Time: 0:43:47 || Estimated Time: 0:23:53\n",
            "Epochs: 13/20 || Iters: 5510/8500 || Lr: 0.005404 || Train Loss: 0.8348 || mIoU: 0.4393 || Cost Time: 0:43:52 || Estimated Time: 0:23:48\n",
            "Epochs: 13/20 || Iters: 5520/8500 || Lr: 0.005404 || Train Loss: 0.4890 || mIoU: 0.4399 || Cost Time: 0:43:55 || Estimated Time: 0:23:42\n",
            "Epochs: 13/20, Average loss: 0.674, Average mIoU: 0.434, Average pixAcc: 0.898\n",
            "Validation: Average loss: 0.809, Average mIoU: 0.403, Average pixAcc: 0.878\n",
            "Epochs: 14/20 || Iters: 5530/8500 || Lr: 0.005133 || Train Loss: 0.6656 || mIoU: 0.4084 || Cost Time: 0:44:32 || Estimated Time: 0:23:55\n",
            "Epochs: 14/20 || Iters: 5540/8500 || Lr: 0.005133 || Train Loss: 0.6664 || mIoU: 0.4267 || Cost Time: 0:44:35 || Estimated Time: 0:23:49\n",
            "Epochs: 14/20 || Iters: 5550/8500 || Lr: 0.005133 || Train Loss: 0.7297 || mIoU: 0.4340 || Cost Time: 0:44:40 || Estimated Time: 0:23:44\n",
            "Epochs: 14/20 || Iters: 5560/8500 || Lr: 0.005133 || Train Loss: 0.5546 || mIoU: 0.4371 || Cost Time: 0:44:44 || Estimated Time: 0:23:39\n",
            "Epochs: 14/20 || Iters: 5570/8500 || Lr: 0.005133 || Train Loss: 0.5388 || mIoU: 0.4405 || Cost Time: 0:44:48 || Estimated Time: 0:23:34\n",
            "Epochs: 14/20 || Iters: 5580/8500 || Lr: 0.005133 || Train Loss: 0.7899 || mIoU: 0.4473 || Cost Time: 0:44:52 || Estimated Time: 0:23:29\n",
            "Epochs: 14/20 || Iters: 5590/8500 || Lr: 0.005133 || Train Loss: 0.7128 || mIoU: 0.4530 || Cost Time: 0:44:57 || Estimated Time: 0:23:24\n",
            "Epochs: 14/20 || Iters: 5600/8500 || Lr: 0.005133 || Train Loss: 0.5043 || mIoU: 0.4596 || Cost Time: 0:45:02 || Estimated Time: 0:23:19\n",
            "Epochs: 14/20 || Iters: 5610/8500 || Lr: 0.005133 || Train Loss: 1.1944 || mIoU: 0.4551 || Cost Time: 0:45:05 || Estimated Time: 0:23:13\n",
            "Epochs: 14/20 || Iters: 5620/8500 || Lr: 0.005133 || Train Loss: 0.5826 || mIoU: 0.4519 || Cost Time: 0:45:10 || Estimated Time: 0:23:08\n",
            "Epochs: 14/20 || Iters: 5630/8500 || Lr: 0.005133 || Train Loss: 0.6521 || mIoU: 0.4502 || Cost Time: 0:45:14 || Estimated Time: 0:23:03\n",
            "Epochs: 14/20 || Iters: 5640/8500 || Lr: 0.005133 || Train Loss: 0.8184 || mIoU: 0.4508 || Cost Time: 0:45:18 || Estimated Time: 0:22:58\n",
            "Epochs: 14/20 || Iters: 5650/8500 || Lr: 0.005133 || Train Loss: 1.2769 || mIoU: 0.4501 || Cost Time: 0:45:22 || Estimated Time: 0:22:53\n",
            "Epochs: 14/20 || Iters: 5660/8500 || Lr: 0.005133 || Train Loss: 0.7498 || mIoU: 0.4488 || Cost Time: 0:45:27 || Estimated Time: 0:22:48\n",
            "Epochs: 14/20 || Iters: 5670/8500 || Lr: 0.005133 || Train Loss: 0.6256 || mIoU: 0.4479 || Cost Time: 0:45:30 || Estimated Time: 0:22:42\n",
            "Epochs: 14/20 || Iters: 5680/8500 || Lr: 0.005133 || Train Loss: 0.6597 || mIoU: 0.4490 || Cost Time: 0:45:35 || Estimated Time: 0:22:38\n",
            "Epochs: 14/20 || Iters: 5690/8500 || Lr: 0.005133 || Train Loss: 0.7100 || mIoU: 0.4447 || Cost Time: 0:45:38 || Estimated Time: 0:22:32\n",
            "Epochs: 14/20 || Iters: 5700/8500 || Lr: 0.005133 || Train Loss: 0.7865 || mIoU: 0.4450 || Cost Time: 0:45:43 || Estimated Time: 0:22:27\n",
            "Epochs: 14/20 || Iters: 5710/8500 || Lr: 0.005133 || Train Loss: 0.5413 || mIoU: 0.4458 || Cost Time: 0:45:47 || Estimated Time: 0:22:22\n",
            "Epochs: 14/20 || Iters: 5720/8500 || Lr: 0.005133 || Train Loss: 0.5837 || mIoU: 0.4469 || Cost Time: 0:45:52 || Estimated Time: 0:22:17\n",
            "Epochs: 14/20 || Iters: 5730/8500 || Lr: 0.005133 || Train Loss: 0.9790 || mIoU: 0.4463 || Cost Time: 0:45:55 || Estimated Time: 0:22:12\n",
            "Epochs: 14/20 || Iters: 5740/8500 || Lr: 0.005133 || Train Loss: 0.4896 || mIoU: 0.4454 || Cost Time: 0:46:00 || Estimated Time: 0:22:07\n",
            "Epochs: 14/20 || Iters: 5750/8500 || Lr: 0.005133 || Train Loss: 0.8529 || mIoU: 0.4435 || Cost Time: 0:46:03 || Estimated Time: 0:22:01\n",
            "Epochs: 14/20 || Iters: 5760/8500 || Lr: 0.005133 || Train Loss: 0.5081 || mIoU: 0.4399 || Cost Time: 0:46:08 || Estimated Time: 0:21:56\n",
            "Epochs: 14/20 || Iters: 5770/8500 || Lr: 0.005133 || Train Loss: 1.0357 || mIoU: 0.4406 || Cost Time: 0:46:11 || Estimated Time: 0:21:51\n",
            "Epochs: 14/20 || Iters: 5780/8500 || Lr: 0.005133 || Train Loss: 0.7884 || mIoU: 0.4409 || Cost Time: 0:46:16 || Estimated Time: 0:21:46\n",
            "Epochs: 14/20 || Iters: 5790/8500 || Lr: 0.005133 || Train Loss: 0.5634 || mIoU: 0.4419 || Cost Time: 0:46:19 || Estimated Time: 0:21:40\n",
            "Epochs: 14/20 || Iters: 5800/8500 || Lr: 0.005133 || Train Loss: 0.6092 || mIoU: 0.4407 || Cost Time: 0:46:24 || Estimated Time: 0:21:36\n",
            "Epochs: 14/20 || Iters: 5810/8500 || Lr: 0.005133 || Train Loss: 0.6225 || mIoU: 0.4402 || Cost Time: 0:46:27 || Estimated Time: 0:21:30\n",
            "Epochs: 14/20 || Iters: 5820/8500 || Lr: 0.005133 || Train Loss: 0.6302 || mIoU: 0.4401 || Cost Time: 0:46:32 || Estimated Time: 0:21:25\n",
            "Epochs: 14/20 || Iters: 5830/8500 || Lr: 0.005133 || Train Loss: 0.4946 || mIoU: 0.4395 || Cost Time: 0:46:36 || Estimated Time: 0:21:20\n",
            "Epochs: 14/20 || Iters: 5840/8500 || Lr: 0.005133 || Train Loss: 0.7126 || mIoU: 0.4410 || Cost Time: 0:46:40 || Estimated Time: 0:21:15\n",
            "Epochs: 14/20 || Iters: 5850/8500 || Lr: 0.005133 || Train Loss: 0.6500 || mIoU: 0.4400 || Cost Time: 0:46:44 || Estimated Time: 0:21:10\n",
            "Epochs: 14/20 || Iters: 5860/8500 || Lr: 0.005133 || Train Loss: 0.4390 || mIoU: 0.4416 || Cost Time: 0:46:49 || Estimated Time: 0:21:05\n",
            "Epochs: 14/20 || Iters: 5870/8500 || Lr: 0.005133 || Train Loss: 0.5826 || mIoU: 0.4414 || Cost Time: 0:46:53 || Estimated Time: 0:21:00\n",
            "Epochs: 14/20 || Iters: 5880/8500 || Lr: 0.005133 || Train Loss: 1.1517 || mIoU: 0.4405 || Cost Time: 0:46:57 || Estimated Time: 0:20:55\n",
            "Epochs: 14/20 || Iters: 5890/8500 || Lr: 0.005133 || Train Loss: 0.7083 || mIoU: 0.4418 || Cost Time: 0:47:01 || Estimated Time: 0:20:50\n",
            "Epochs: 14/20 || Iters: 5900/8500 || Lr: 0.005133 || Train Loss: 0.6027 || mIoU: 0.4412 || Cost Time: 0:47:05 || Estimated Time: 0:20:45\n",
            "Epochs: 14/20 || Iters: 5910/8500 || Lr: 0.005133 || Train Loss: 0.8131 || mIoU: 0.4397 || Cost Time: 0:47:11 || Estimated Time: 0:20:40\n",
            "Epochs: 14/20 || Iters: 5920/8500 || Lr: 0.005133 || Train Loss: 0.4663 || mIoU: 0.4408 || Cost Time: 0:47:15 || Estimated Time: 0:20:35\n",
            "Epochs: 14/20 || Iters: 5930/8500 || Lr: 0.005133 || Train Loss: 0.7335 || mIoU: 0.4408 || Cost Time: 0:47:20 || Estimated Time: 0:20:31\n",
            "Epochs: 14/20 || Iters: 5940/8500 || Lr: 0.005133 || Train Loss: 0.6134 || mIoU: 0.4407 || Cost Time: 0:47:23 || Estimated Time: 0:20:25\n",
            "Epochs: 14/20 || Iters: 5950/8500 || Lr: 0.005133 || Train Loss: 0.5766 || mIoU: 0.4402 || Cost Time: 0:47:28 || Estimated Time: 0:20:20\n",
            "Epochs: 14/20, Average loss: 0.677, Average mIoU: 0.443, Average pixAcc: 0.901\n",
            "Validation: Average loss: 0.806, Average mIoU: 0.397, Average pixAcc: 0.879\n",
            "Epochs: 15/20 || Iters: 5960/8500 || Lr: 0.004877 || Train Loss: 0.7310 || mIoU: 0.4351 || Cost Time: 0:48:04 || Estimated Time: 0:20:29\n",
            "Epochs: 15/20 || Iters: 5970/8500 || Lr: 0.004877 || Train Loss: 0.7009 || mIoU: 0.4415 || Cost Time: 0:48:08 || Estimated Time: 0:20:24\n",
            "Epochs: 15/20 || Iters: 5980/8500 || Lr: 0.004877 || Train Loss: 0.5351 || mIoU: 0.4298 || Cost Time: 0:48:12 || Estimated Time: 0:20:19\n",
            "Epochs: 15/20 || Iters: 5990/8500 || Lr: 0.004877 || Train Loss: 0.5603 || mIoU: 0.4289 || Cost Time: 0:48:16 || Estimated Time: 0:20:13\n",
            "Epochs: 15/20 || Iters: 6000/8500 || Lr: 0.004877 || Train Loss: 0.8407 || mIoU: 0.4297 || Cost Time: 0:48:21 || Estimated Time: 0:20:08\n",
            "Epochs: 15/20 || Iters: 6010/8500 || Lr: 0.004877 || Train Loss: 0.5784 || mIoU: 0.4417 || Cost Time: 0:48:24 || Estimated Time: 0:20:03\n",
            "Epochs: 15/20 || Iters: 6020/8500 || Lr: 0.004877 || Train Loss: 0.6104 || mIoU: 0.4431 || Cost Time: 0:48:29 || Estimated Time: 0:19:58\n",
            "Epochs: 15/20 || Iters: 6030/8500 || Lr: 0.004877 || Train Loss: 0.7219 || mIoU: 0.4449 || Cost Time: 0:48:32 || Estimated Time: 0:19:53\n",
            "Epochs: 15/20 || Iters: 6040/8500 || Lr: 0.004877 || Train Loss: 0.7553 || mIoU: 0.4467 || Cost Time: 0:48:37 || Estimated Time: 0:19:48\n",
            "Epochs: 15/20 || Iters: 6050/8500 || Lr: 0.004877 || Train Loss: 0.4929 || mIoU: 0.4437 || Cost Time: 0:48:41 || Estimated Time: 0:19:42\n",
            "Epochs: 15/20 || Iters: 6060/8500 || Lr: 0.004877 || Train Loss: 0.8431 || mIoU: 0.4409 || Cost Time: 0:48:45 || Estimated Time: 0:19:37\n",
            "Epochs: 15/20 || Iters: 6070/8500 || Lr: 0.004877 || Train Loss: 0.4655 || mIoU: 0.4413 || Cost Time: 0:48:49 || Estimated Time: 0:19:32\n",
            "Epochs: 15/20 || Iters: 6080/8500 || Lr: 0.004877 || Train Loss: 0.7771 || mIoU: 0.4403 || Cost Time: 0:48:53 || Estimated Time: 0:19:27\n",
            "Epochs: 15/20 || Iters: 6090/8500 || Lr: 0.004877 || Train Loss: 0.8002 || mIoU: 0.4389 || Cost Time: 0:48:57 || Estimated Time: 0:19:22\n",
            "Epochs: 15/20 || Iters: 6100/8500 || Lr: 0.004877 || Train Loss: 0.4830 || mIoU: 0.4395 || Cost Time: 0:49:01 || Estimated Time: 0:19:17\n",
            "Epochs: 15/20 || Iters: 6110/8500 || Lr: 0.004877 || Train Loss: 0.4545 || mIoU: 0.4400 || Cost Time: 0:49:05 || Estimated Time: 0:19:12\n",
            "Epochs: 15/20 || Iters: 6120/8500 || Lr: 0.004877 || Train Loss: 0.9305 || mIoU: 0.4391 || Cost Time: 0:49:09 || Estimated Time: 0:19:07\n",
            "Epochs: 15/20 || Iters: 6130/8500 || Lr: 0.004877 || Train Loss: 0.4206 || mIoU: 0.4389 || Cost Time: 0:49:13 || Estimated Time: 0:19:01\n",
            "Epochs: 15/20 || Iters: 6140/8500 || Lr: 0.004877 || Train Loss: 0.5951 || mIoU: 0.4368 || Cost Time: 0:49:18 || Estimated Time: 0:18:57\n",
            "Epochs: 15/20 || Iters: 6150/8500 || Lr: 0.004877 || Train Loss: 0.5950 || mIoU: 0.4357 || Cost Time: 0:49:21 || Estimated Time: 0:18:51\n",
            "Epochs: 15/20 || Iters: 6160/8500 || Lr: 0.004877 || Train Loss: 0.4645 || mIoU: 0.4391 || Cost Time: 0:49:26 || Estimated Time: 0:18:46\n",
            "Epochs: 15/20 || Iters: 6170/8500 || Lr: 0.004877 || Train Loss: 0.5543 || mIoU: 0.4408 || Cost Time: 0:49:29 || Estimated Time: 0:18:41\n",
            "Epochs: 15/20 || Iters: 6180/8500 || Lr: 0.004877 || Train Loss: 0.5390 || mIoU: 0.4406 || Cost Time: 0:49:33 || Estimated Time: 0:18:36\n",
            "Epochs: 15/20 || Iters: 6190/8500 || Lr: 0.004877 || Train Loss: 0.8199 || mIoU: 0.4401 || Cost Time: 0:49:37 || Estimated Time: 0:18:31\n",
            "Epochs: 15/20 || Iters: 6200/8500 || Lr: 0.004877 || Train Loss: 0.6528 || mIoU: 0.4408 || Cost Time: 0:49:42 || Estimated Time: 0:18:26\n",
            "Epochs: 15/20 || Iters: 6210/8500 || Lr: 0.004877 || Train Loss: 0.5053 || mIoU: 0.4409 || Cost Time: 0:49:45 || Estimated Time: 0:18:20\n",
            "Epochs: 15/20 || Iters: 6220/8500 || Lr: 0.004877 || Train Loss: 0.7404 || mIoU: 0.4399 || Cost Time: 0:49:50 || Estimated Time: 0:18:16\n",
            "Epochs: 15/20 || Iters: 6230/8500 || Lr: 0.004877 || Train Loss: 0.5350 || mIoU: 0.4395 || Cost Time: 0:49:53 || Estimated Time: 0:18:10\n",
            "Epochs: 15/20 || Iters: 6240/8500 || Lr: 0.004877 || Train Loss: 0.7400 || mIoU: 0.4407 || Cost Time: 0:49:58 || Estimated Time: 0:18:05\n",
            "Epochs: 15/20 || Iters: 6250/8500 || Lr: 0.004877 || Train Loss: 0.4996 || mIoU: 0.4398 || Cost Time: 0:50:01 || Estimated Time: 0:18:00\n",
            "Epochs: 15/20 || Iters: 6260/8500 || Lr: 0.004877 || Train Loss: 0.5957 || mIoU: 0.4399 || Cost Time: 0:50:06 || Estimated Time: 0:17:55\n",
            "Epochs: 15/20 || Iters: 6270/8500 || Lr: 0.004877 || Train Loss: 0.6175 || mIoU: 0.4392 || Cost Time: 0:50:09 || Estimated Time: 0:17:50\n",
            "Epochs: 15/20 || Iters: 6280/8500 || Lr: 0.004877 || Train Loss: 0.6517 || mIoU: 0.4396 || Cost Time: 0:50:14 || Estimated Time: 0:17:45\n",
            "Epochs: 15/20 || Iters: 6290/8500 || Lr: 0.004877 || Train Loss: 0.6241 || mIoU: 0.4373 || Cost Time: 0:50:18 || Estimated Time: 0:17:40\n",
            "Epochs: 15/20 || Iters: 6300/8500 || Lr: 0.004877 || Train Loss: 0.7828 || mIoU: 0.4364 || Cost Time: 0:50:22 || Estimated Time: 0:17:35\n",
            "Epochs: 15/20 || Iters: 6310/8500 || Lr: 0.004877 || Train Loss: 0.7391 || mIoU: 0.4356 || Cost Time: 0:50:26 || Estimated Time: 0:17:30\n",
            "Epochs: 15/20 || Iters: 6320/8500 || Lr: 0.004877 || Train Loss: 0.7179 || mIoU: 0.4354 || Cost Time: 0:50:31 || Estimated Time: 0:17:25\n",
            "Epochs: 15/20 || Iters: 6330/8500 || Lr: 0.004877 || Train Loss: 0.4907 || mIoU: 0.4350 || Cost Time: 0:50:34 || Estimated Time: 0:17:20\n",
            "Epochs: 15/20 || Iters: 6340/8500 || Lr: 0.004877 || Train Loss: 0.7127 || mIoU: 0.4353 || Cost Time: 0:50:38 || Estimated Time: 0:17:15\n",
            "Epochs: 15/20 || Iters: 6350/8500 || Lr: 0.004877 || Train Loss: 0.6829 || mIoU: 0.4351 || Cost Time: 0:50:42 || Estimated Time: 0:17:10\n",
            "Epochs: 15/20 || Iters: 6360/8500 || Lr: 0.004877 || Train Loss: 0.8679 || mIoU: 0.4363 || Cost Time: 0:50:47 || Estimated Time: 0:17:05\n",
            "Epochs: 15/20 || Iters: 6370/8500 || Lr: 0.004877 || Train Loss: 0.3693 || mIoU: 0.4362 || Cost Time: 0:50:50 || Estimated Time: 0:16:59\n",
            "Epochs: 15/20, Average loss: 0.669, Average mIoU: 0.439, Average pixAcc: 0.901\n",
            "Validation: Average loss: 0.797, Average mIoU: 0.396, Average pixAcc: 0.878\n",
            "Epochs: 16/20 || Iters: 6380/8500 || Lr: 0.004633 || Train Loss: 0.5248 || mIoU: 0.4295 || Cost Time: 0:51:26 || Estimated Time: 0:17:05\n",
            "Epochs: 16/20 || Iters: 6390/8500 || Lr: 0.004633 || Train Loss: 1.0338 || mIoU: 0.4269 || Cost Time: 0:51:30 || Estimated Time: 0:17:00\n",
            "Epochs: 16/20 || Iters: 6400/8500 || Lr: 0.004633 || Train Loss: 0.6412 || mIoU: 0.4410 || Cost Time: 0:51:35 || Estimated Time: 0:16:55\n",
            "Epochs: 16/20 || Iters: 6410/8500 || Lr: 0.004633 || Train Loss: 0.5273 || mIoU: 0.4342 || Cost Time: 0:51:38 || Estimated Time: 0:16:50\n",
            "Epochs: 16/20 || Iters: 6420/8500 || Lr: 0.004633 || Train Loss: 0.4827 || mIoU: 0.4418 || Cost Time: 0:51:43 || Estimated Time: 0:16:45\n",
            "Epochs: 16/20 || Iters: 6430/8500 || Lr: 0.004633 || Train Loss: 0.8317 || mIoU: 0.4423 || Cost Time: 0:51:46 || Estimated Time: 0:16:40\n",
            "Epochs: 16/20 || Iters: 6440/8500 || Lr: 0.004633 || Train Loss: 1.0973 || mIoU: 0.4407 || Cost Time: 0:51:51 || Estimated Time: 0:16:35\n",
            "Epochs: 16/20 || Iters: 6450/8500 || Lr: 0.004633 || Train Loss: 0.7628 || mIoU: 0.4375 || Cost Time: 0:51:54 || Estimated Time: 0:16:30\n",
            "Epochs: 16/20 || Iters: 6460/8500 || Lr: 0.004633 || Train Loss: 0.5107 || mIoU: 0.4400 || Cost Time: 0:51:59 || Estimated Time: 0:16:25\n",
            "Epochs: 16/20 || Iters: 6470/8500 || Lr: 0.004633 || Train Loss: 0.5137 || mIoU: 0.4438 || Cost Time: 0:52:02 || Estimated Time: 0:16:19\n",
            "Epochs: 16/20 || Iters: 6480/8500 || Lr: 0.004633 || Train Loss: 0.7231 || mIoU: 0.4461 || Cost Time: 0:52:07 || Estimated Time: 0:16:14\n",
            "Epochs: 16/20 || Iters: 6490/8500 || Lr: 0.004633 || Train Loss: 0.5483 || mIoU: 0.4460 || Cost Time: 0:52:10 || Estimated Time: 0:16:09\n",
            "Epochs: 16/20 || Iters: 6500/8500 || Lr: 0.004633 || Train Loss: 0.4635 || mIoU: 0.4453 || Cost Time: 0:52:15 || Estimated Time: 0:16:04\n",
            "Epochs: 16/20 || Iters: 6510/8500 || Lr: 0.004633 || Train Loss: 0.7711 || mIoU: 0.4458 || Cost Time: 0:52:18 || Estimated Time: 0:15:59\n",
            "Epochs: 16/20 || Iters: 6520/8500 || Lr: 0.004633 || Train Loss: 0.6288 || mIoU: 0.4444 || Cost Time: 0:52:23 || Estimated Time: 0:15:54\n",
            "Epochs: 16/20 || Iters: 6530/8500 || Lr: 0.004633 || Train Loss: 0.7782 || mIoU: 0.4456 || Cost Time: 0:52:27 || Estimated Time: 0:15:49\n",
            "Epochs: 16/20 || Iters: 6540/8500 || Lr: 0.004633 || Train Loss: 0.6379 || mIoU: 0.4442 || Cost Time: 0:52:31 || Estimated Time: 0:15:44\n",
            "Epochs: 16/20 || Iters: 6550/8500 || Lr: 0.004633 || Train Loss: 0.5997 || mIoU: 0.4447 || Cost Time: 0:52:35 || Estimated Time: 0:15:39\n",
            "Epochs: 16/20 || Iters: 6560/8500 || Lr: 0.004633 || Train Loss: 0.5643 || mIoU: 0.4471 || Cost Time: 0:52:39 || Estimated Time: 0:15:34\n",
            "Epochs: 16/20 || Iters: 6570/8500 || Lr: 0.004633 || Train Loss: 0.4045 || mIoU: 0.4477 || Cost Time: 0:52:43 || Estimated Time: 0:15:29\n",
            "Epochs: 16/20 || Iters: 6580/8500 || Lr: 0.004633 || Train Loss: 0.5337 || mIoU: 0.4479 || Cost Time: 0:52:47 || Estimated Time: 0:15:24\n",
            "Epochs: 16/20 || Iters: 6590/8500 || Lr: 0.004633 || Train Loss: 0.6831 || mIoU: 0.4505 || Cost Time: 0:52:51 || Estimated Time: 0:15:19\n",
            "Epochs: 16/20 || Iters: 6600/8500 || Lr: 0.004633 || Train Loss: 0.7698 || mIoU: 0.4515 || Cost Time: 0:52:54 || Estimated Time: 0:15:13\n",
            "Epochs: 16/20 || Iters: 6610/8500 || Lr: 0.004633 || Train Loss: 0.5884 || mIoU: 0.4531 || Cost Time: 0:52:59 || Estimated Time: 0:15:09\n",
            "Epochs: 16/20 || Iters: 6620/8500 || Lr: 0.004633 || Train Loss: 0.5875 || mIoU: 0.4519 || Cost Time: 0:53:03 || Estimated Time: 0:15:04\n",
            "Epochs: 16/20 || Iters: 6630/8500 || Lr: 0.004633 || Train Loss: 0.7909 || mIoU: 0.4524 || Cost Time: 0:53:07 || Estimated Time: 0:14:59\n",
            "Epochs: 16/20 || Iters: 6640/8500 || Lr: 0.004633 || Train Loss: 0.6122 || mIoU: 0.4528 || Cost Time: 0:53:11 || Estimated Time: 0:14:53\n",
            "Epochs: 16/20 || Iters: 6650/8500 || Lr: 0.004633 || Train Loss: 0.6933 || mIoU: 0.4521 || Cost Time: 0:53:16 || Estimated Time: 0:14:49\n",
            "Epochs: 16/20 || Iters: 6660/8500 || Lr: 0.004633 || Train Loss: 0.5284 || mIoU: 0.4518 || Cost Time: 0:53:19 || Estimated Time: 0:14:44\n",
            "Epochs: 16/20 || Iters: 6670/8500 || Lr: 0.004633 || Train Loss: 0.7027 || mIoU: 0.4532 || Cost Time: 0:53:24 || Estimated Time: 0:14:39\n",
            "Epochs: 16/20 || Iters: 6680/8500 || Lr: 0.004633 || Train Loss: 0.5334 || mIoU: 0.4545 || Cost Time: 0:53:27 || Estimated Time: 0:14:34\n",
            "Epochs: 16/20 || Iters: 6690/8500 || Lr: 0.004633 || Train Loss: 0.5673 || mIoU: 0.4560 || Cost Time: 0:53:32 || Estimated Time: 0:14:29\n",
            "Epochs: 16/20 || Iters: 6700/8500 || Lr: 0.004633 || Train Loss: 0.7353 || mIoU: 0.4536 || Cost Time: 0:53:36 || Estimated Time: 0:14:24\n",
            "Epochs: 16/20 || Iters: 6710/8500 || Lr: 0.004633 || Train Loss: 0.6290 || mIoU: 0.4544 || Cost Time: 0:53:40 || Estimated Time: 0:14:19\n",
            "Epochs: 16/20 || Iters: 6720/8500 || Lr: 0.004633 || Train Loss: 0.7603 || mIoU: 0.4537 || Cost Time: 0:53:43 || Estimated Time: 0:14:13\n",
            "Epochs: 16/20 || Iters: 6730/8500 || Lr: 0.004633 || Train Loss: 0.5173 || mIoU: 0.4546 || Cost Time: 0:53:48 || Estimated Time: 0:14:09\n",
            "Epochs: 16/20 || Iters: 6740/8500 || Lr: 0.004633 || Train Loss: 0.5465 || mIoU: 0.4544 || Cost Time: 0:53:51 || Estimated Time: 0:14:03\n",
            "Epochs: 16/20 || Iters: 6750/8500 || Lr: 0.004633 || Train Loss: 0.5538 || mIoU: 0.4530 || Cost Time: 0:53:56 || Estimated Time: 0:13:59\n",
            "Epochs: 16/20 || Iters: 6760/8500 || Lr: 0.004633 || Train Loss: 0.5023 || mIoU: 0.4521 || Cost Time: 0:54:00 || Estimated Time: 0:13:54\n",
            "Epochs: 16/20 || Iters: 6770/8500 || Lr: 0.004633 || Train Loss: 0.6404 || mIoU: 0.4514 || Cost Time: 0:54:04 || Estimated Time: 0:13:49\n",
            "Epochs: 16/20 || Iters: 6780/8500 || Lr: 0.004633 || Train Loss: 0.7029 || mIoU: 0.4516 || Cost Time: 0:54:08 || Estimated Time: 0:13:44\n",
            "Epochs: 16/20 || Iters: 6790/8500 || Lr: 0.004633 || Train Loss: 0.6601 || mIoU: 0.4509 || Cost Time: 0:54:13 || Estimated Time: 0:13:39\n",
            "Epochs: 16/20 || Iters: 6800/8500 || Lr: 0.004633 || Train Loss: 0.8170 || mIoU: 0.4500 || Cost Time: 0:54:16 || Estimated Time: 0:13:34\n",
            "Epochs: 16/20, Average loss: 0.649, Average mIoU: 0.447, Average pixAcc: 0.901\n",
            "Validation: Average loss: 0.806, Average mIoU: 0.396, Average pixAcc: 0.877\n",
            "Epochs: 17/20 || Iters: 6810/8500 || Lr: 0.004401 || Train Loss: 0.5256 || mIoU: 0.4133 || Cost Time: 0:54:52 || Estimated Time: 0:13:37\n",
            "Epochs: 17/20 || Iters: 6820/8500 || Lr: 0.004401 || Train Loss: 0.5282 || mIoU: 0.4367 || Cost Time: 0:54:56 || Estimated Time: 0:13:32\n",
            "Epochs: 17/20 || Iters: 6830/8500 || Lr: 0.004401 || Train Loss: 0.7013 || mIoU: 0.4285 || Cost Time: 0:55:01 || Estimated Time: 0:13:27\n",
            "Epochs: 17/20 || Iters: 6840/8500 || Lr: 0.004401 || Train Loss: 0.4479 || mIoU: 0.4331 || Cost Time: 0:55:05 || Estimated Time: 0:13:22\n",
            "Epochs: 17/20 || Iters: 6850/8500 || Lr: 0.004401 || Train Loss: 0.5190 || mIoU: 0.4376 || Cost Time: 0:55:09 || Estimated Time: 0:13:17\n",
            "Epochs: 17/20 || Iters: 6860/8500 || Lr: 0.004401 || Train Loss: 0.6417 || mIoU: 0.4314 || Cost Time: 0:55:13 || Estimated Time: 0:13:12\n",
            "Epochs: 17/20 || Iters: 6870/8500 || Lr: 0.004401 || Train Loss: 0.5334 || mIoU: 0.4395 || Cost Time: 0:55:17 || Estimated Time: 0:13:07\n",
            "Epochs: 17/20 || Iters: 6880/8500 || Lr: 0.004401 || Train Loss: 0.5512 || mIoU: 0.4396 || Cost Time: 0:55:21 || Estimated Time: 0:13:02\n",
            "Epochs: 17/20 || Iters: 6890/8500 || Lr: 0.004401 || Train Loss: 0.8500 || mIoU: 0.4370 || Cost Time: 0:55:25 || Estimated Time: 0:12:57\n",
            "Epochs: 17/20 || Iters: 6900/8500 || Lr: 0.004401 || Train Loss: 0.7943 || mIoU: 0.4365 || Cost Time: 0:55:29 || Estimated Time: 0:12:52\n",
            "Epochs: 17/20 || Iters: 6910/8500 || Lr: 0.004401 || Train Loss: 0.5453 || mIoU: 0.4395 || Cost Time: 0:55:33 || Estimated Time: 0:12:47\n",
            "Epochs: 17/20 || Iters: 6920/8500 || Lr: 0.004401 || Train Loss: 0.8201 || mIoU: 0.4396 || Cost Time: 0:55:37 || Estimated Time: 0:12:42\n",
            "Epochs: 17/20 || Iters: 6930/8500 || Lr: 0.004401 || Train Loss: 0.5629 || mIoU: 0.4381 || Cost Time: 0:55:41 || Estimated Time: 0:12:36\n",
            "Epochs: 17/20 || Iters: 6940/8500 || Lr: 0.004401 || Train Loss: 0.5958 || mIoU: 0.4359 || Cost Time: 0:55:46 || Estimated Time: 0:12:32\n",
            "Epochs: 17/20 || Iters: 6950/8500 || Lr: 0.004401 || Train Loss: 0.4285 || mIoU: 0.4364 || Cost Time: 0:55:50 || Estimated Time: 0:12:27\n",
            "Epochs: 17/20 || Iters: 6960/8500 || Lr: 0.004401 || Train Loss: 0.5712 || mIoU: 0.4348 || Cost Time: 0:55:54 || Estimated Time: 0:12:22\n",
            "Epochs: 17/20 || Iters: 6970/8500 || Lr: 0.004401 || Train Loss: 0.5580 || mIoU: 0.4386 || Cost Time: 0:55:58 || Estimated Time: 0:12:17\n",
            "Epochs: 17/20 || Iters: 6980/8500 || Lr: 0.004401 || Train Loss: 0.4397 || mIoU: 0.4394 || Cost Time: 0:56:02 || Estimated Time: 0:12:12\n",
            "Epochs: 17/20 || Iters: 6990/8500 || Lr: 0.004401 || Train Loss: 0.5612 || mIoU: 0.4411 || Cost Time: 0:56:06 || Estimated Time: 0:12:07\n",
            "Epochs: 17/20 || Iters: 7000/8500 || Lr: 0.004401 || Train Loss: 0.6337 || mIoU: 0.4412 || Cost Time: 0:56:10 || Estimated Time: 0:12:02\n",
            "Epochs: 17/20 || Iters: 7010/8500 || Lr: 0.004401 || Train Loss: 0.6798 || mIoU: 0.4418 || Cost Time: 0:56:14 || Estimated Time: 0:11:57\n",
            "Epochs: 17/20 || Iters: 7020/8500 || Lr: 0.004401 || Train Loss: 0.6296 || mIoU: 0.4427 || Cost Time: 0:56:19 || Estimated Time: 0:11:52\n",
            "Epochs: 17/20 || Iters: 7030/8500 || Lr: 0.004401 || Train Loss: 0.4580 || mIoU: 0.4434 || Cost Time: 0:56:22 || Estimated Time: 0:11:47\n",
            "Epochs: 17/20 || Iters: 7040/8500 || Lr: 0.004401 || Train Loss: 0.5463 || mIoU: 0.4448 || Cost Time: 0:56:27 || Estimated Time: 0:11:42\n",
            "Epochs: 17/20 || Iters: 7050/8500 || Lr: 0.004401 || Train Loss: 0.5120 || mIoU: 0.4447 || Cost Time: 0:56:31 || Estimated Time: 0:11:37\n",
            "Epochs: 17/20 || Iters: 7060/8500 || Lr: 0.004401 || Train Loss: 0.6267 || mIoU: 0.4442 || Cost Time: 0:56:35 || Estimated Time: 0:11:32\n",
            "Epochs: 17/20 || Iters: 7070/8500 || Lr: 0.004401 || Train Loss: 0.6702 || mIoU: 0.4441 || Cost Time: 0:56:39 || Estimated Time: 0:11:27\n",
            "Epochs: 17/20 || Iters: 7080/8500 || Lr: 0.004401 || Train Loss: 0.7126 || mIoU: 0.4441 || Cost Time: 0:56:43 || Estimated Time: 0:11:22\n",
            "Epochs: 17/20 || Iters: 7090/8500 || Lr: 0.004401 || Train Loss: 0.5806 || mIoU: 0.4442 || Cost Time: 0:56:47 || Estimated Time: 0:11:17\n",
            "Epochs: 17/20 || Iters: 7100/8500 || Lr: 0.004401 || Train Loss: 0.5257 || mIoU: 0.4441 || Cost Time: 0:56:51 || Estimated Time: 0:11:12\n",
            "Epochs: 17/20 || Iters: 7110/8500 || Lr: 0.004401 || Train Loss: 0.7016 || mIoU: 0.4436 || Cost Time: 0:56:55 || Estimated Time: 0:11:07\n",
            "Epochs: 17/20 || Iters: 7120/8500 || Lr: 0.004401 || Train Loss: 0.4590 || mIoU: 0.4440 || Cost Time: 0:56:59 || Estimated Time: 0:11:02\n",
            "Epochs: 17/20 || Iters: 7130/8500 || Lr: 0.004401 || Train Loss: 0.7222 || mIoU: 0.4436 || Cost Time: 0:57:03 || Estimated Time: 0:10:57\n",
            "Epochs: 17/20 || Iters: 7140/8500 || Lr: 0.004401 || Train Loss: 0.6318 || mIoU: 0.4429 || Cost Time: 0:57:07 || Estimated Time: 0:10:52\n",
            "Epochs: 17/20 || Iters: 7150/8500 || Lr: 0.004401 || Train Loss: 0.7127 || mIoU: 0.4424 || Cost Time: 0:57:11 || Estimated Time: 0:10:47\n",
            "Epochs: 17/20 || Iters: 7160/8500 || Lr: 0.004401 || Train Loss: 0.7402 || mIoU: 0.4432 || Cost Time: 0:57:16 || Estimated Time: 0:10:43\n",
            "Epochs: 17/20 || Iters: 7170/8500 || Lr: 0.004401 || Train Loss: 0.5492 || mIoU: 0.4444 || Cost Time: 0:57:20 || Estimated Time: 0:10:38\n",
            "Epochs: 17/20 || Iters: 7180/8500 || Lr: 0.004401 || Train Loss: 0.8302 || mIoU: 0.4447 || Cost Time: 0:57:24 || Estimated Time: 0:10:33\n",
            "Epochs: 17/20 || Iters: 7190/8500 || Lr: 0.004401 || Train Loss: 0.6528 || mIoU: 0.4450 || Cost Time: 0:57:28 || Estimated Time: 0:10:28\n",
            "Epochs: 17/20 || Iters: 7200/8500 || Lr: 0.004401 || Train Loss: 0.8274 || mIoU: 0.4445 || Cost Time: 0:57:33 || Estimated Time: 0:10:23\n",
            "Epochs: 17/20 || Iters: 7210/8500 || Lr: 0.004401 || Train Loss: 0.6525 || mIoU: 0.4437 || Cost Time: 0:57:36 || Estimated Time: 0:10:18\n",
            "Epochs: 17/20 || Iters: 7220/8500 || Lr: 0.004401 || Train Loss: 0.7379 || mIoU: 0.4446 || Cost Time: 0:57:40 || Estimated Time: 0:10:13\n",
            "Epochs: 17/20, Average loss: 0.656, Average mIoU: 0.439, Average pixAcc: 0.902\n",
            "Validation: Average loss: 0.806, Average mIoU: 0.395, Average pixAcc: 0.878\n",
            "Epochs: 18/20 || Iters: 7230/8500 || Lr: 0.004181 || Train Loss: 0.6236 || mIoU: 0.4181 || Cost Time: 0:58:16 || Estimated Time: 0:10:14\n",
            "Epochs: 18/20 || Iters: 7240/8500 || Lr: 0.004181 || Train Loss: 0.7709 || mIoU: 0.4394 || Cost Time: 0:58:19 || Estimated Time: 0:10:09\n",
            "Epochs: 18/20 || Iters: 7250/8500 || Lr: 0.004181 || Train Loss: 0.9803 || mIoU: 0.4333 || Cost Time: 0:58:24 || Estimated Time: 0:10:04\n",
            "Epochs: 18/20 || Iters: 7260/8500 || Lr: 0.004181 || Train Loss: 0.6676 || mIoU: 0.4287 || Cost Time: 0:58:27 || Estimated Time: 0:09:59\n",
            "Epochs: 18/20 || Iters: 7270/8500 || Lr: 0.004181 || Train Loss: 0.8395 || mIoU: 0.4409 || Cost Time: 0:58:32 || Estimated Time: 0:09:54\n",
            "Epochs: 18/20 || Iters: 7280/8500 || Lr: 0.004181 || Train Loss: 0.6150 || mIoU: 0.4444 || Cost Time: 0:58:36 || Estimated Time: 0:09:49\n",
            "Epochs: 18/20 || Iters: 7290/8500 || Lr: 0.004181 || Train Loss: 0.5159 || mIoU: 0.4486 || Cost Time: 0:58:40 || Estimated Time: 0:09:44\n",
            "Epochs: 18/20 || Iters: 7300/8500 || Lr: 0.004181 || Train Loss: 0.7582 || mIoU: 0.4471 || Cost Time: 0:58:44 || Estimated Time: 0:09:39\n",
            "Epochs: 18/20 || Iters: 7310/8500 || Lr: 0.004181 || Train Loss: 0.7697 || mIoU: 0.4451 || Cost Time: 0:58:48 || Estimated Time: 0:09:34\n",
            "Epochs: 18/20 || Iters: 7320/8500 || Lr: 0.004181 || Train Loss: 0.5991 || mIoU: 0.4455 || Cost Time: 0:58:52 || Estimated Time: 0:09:29\n",
            "Epochs: 18/20 || Iters: 7330/8500 || Lr: 0.004181 || Train Loss: 0.8179 || mIoU: 0.4404 || Cost Time: 0:58:56 || Estimated Time: 0:09:24\n",
            "Epochs: 18/20 || Iters: 7340/8500 || Lr: 0.004181 || Train Loss: 0.5609 || mIoU: 0.4384 || Cost Time: 0:59:00 || Estimated Time: 0:09:19\n",
            "Epochs: 18/20 || Iters: 7350/8500 || Lr: 0.004181 || Train Loss: 0.9141 || mIoU: 0.4402 || Cost Time: 0:59:04 || Estimated Time: 0:09:14\n",
            "Epochs: 18/20 || Iters: 7360/8500 || Lr: 0.004181 || Train Loss: 0.5379 || mIoU: 0.4409 || Cost Time: 0:59:08 || Estimated Time: 0:09:09\n",
            "Epochs: 18/20 || Iters: 7370/8500 || Lr: 0.004181 || Train Loss: 0.4998 || mIoU: 0.4415 || Cost Time: 0:59:12 || Estimated Time: 0:09:04\n",
            "Epochs: 18/20 || Iters: 7380/8500 || Lr: 0.004181 || Train Loss: 0.6413 || mIoU: 0.4436 || Cost Time: 0:59:16 || Estimated Time: 0:08:59\n",
            "Epochs: 18/20 || Iters: 7390/8500 || Lr: 0.004181 || Train Loss: 0.7731 || mIoU: 0.4424 || Cost Time: 0:59:20 || Estimated Time: 0:08:54\n",
            "Epochs: 18/20 || Iters: 7400/8500 || Lr: 0.004181 || Train Loss: 0.7902 || mIoU: 0.4420 || Cost Time: 0:59:24 || Estimated Time: 0:08:49\n",
            "Epochs: 18/20 || Iters: 7410/8500 || Lr: 0.004181 || Train Loss: 0.6647 || mIoU: 0.4426 || Cost Time: 0:59:28 || Estimated Time: 0:08:44\n",
            "Epochs: 18/20 || Iters: 7420/8500 || Lr: 0.004181 || Train Loss: 0.8679 || mIoU: 0.4426 || Cost Time: 0:59:32 || Estimated Time: 0:08:40\n",
            "Epochs: 18/20 || Iters: 7430/8500 || Lr: 0.004181 || Train Loss: 0.7556 || mIoU: 0.4442 || Cost Time: 0:59:37 || Estimated Time: 0:08:35\n",
            "Epochs: 18/20 || Iters: 7440/8500 || Lr: 0.004181 || Train Loss: 0.4419 || mIoU: 0.4475 || Cost Time: 0:59:40 || Estimated Time: 0:08:30\n",
            "Epochs: 18/20 || Iters: 7450/8500 || Lr: 0.004181 || Train Loss: 0.6376 || mIoU: 0.4477 || Cost Time: 0:59:45 || Estimated Time: 0:08:25\n",
            "Epochs: 18/20 || Iters: 7460/8500 || Lr: 0.004181 || Train Loss: 0.8845 || mIoU: 0.4469 || Cost Time: 0:59:49 || Estimated Time: 0:08:20\n",
            "Epochs: 18/20 || Iters: 7470/8500 || Lr: 0.004181 || Train Loss: 0.6986 || mIoU: 0.4464 || Cost Time: 0:59:53 || Estimated Time: 0:08:15\n",
            "Epochs: 18/20 || Iters: 7480/8500 || Lr: 0.004181 || Train Loss: 0.8027 || mIoU: 0.4464 || Cost Time: 0:59:57 || Estimated Time: 0:08:10\n",
            "Epochs: 18/20 || Iters: 7490/8500 || Lr: 0.004181 || Train Loss: 0.8875 || mIoU: 0.4466 || Cost Time: 1:00:01 || Estimated Time: 0:08:05\n",
            "Epochs: 18/20 || Iters: 7500/8500 || Lr: 0.004181 || Train Loss: 0.7936 || mIoU: 0.4467 || Cost Time: 1:00:04 || Estimated Time: 0:08:00\n",
            "Epochs: 18/20 || Iters: 7510/8500 || Lr: 0.004181 || Train Loss: 0.5305 || mIoU: 0.4465 || Cost Time: 1:00:09 || Estimated Time: 0:07:55\n",
            "Epochs: 18/20 || Iters: 7520/8500 || Lr: 0.004181 || Train Loss: 0.6459 || mIoU: 0.4469 || Cost Time: 1:00:12 || Estimated Time: 0:07:50\n",
            "Epochs: 18/20 || Iters: 7530/8500 || Lr: 0.004181 || Train Loss: 0.7624 || mIoU: 0.4469 || Cost Time: 1:00:17 || Estimated Time: 0:07:45\n",
            "Epochs: 18/20 || Iters: 7540/8500 || Lr: 0.004181 || Train Loss: 0.5916 || mIoU: 0.4488 || Cost Time: 1:00:21 || Estimated Time: 0:07:41\n",
            "Epochs: 18/20 || Iters: 7550/8500 || Lr: 0.004181 || Train Loss: 0.5664 || mIoU: 0.4468 || Cost Time: 1:00:26 || Estimated Time: 0:07:36\n",
            "Epochs: 18/20 || Iters: 7560/8500 || Lr: 0.004181 || Train Loss: 0.7017 || mIoU: 0.4466 || Cost Time: 1:00:29 || Estimated Time: 0:07:31\n",
            "Epochs: 18/20 || Iters: 7570/8500 || Lr: 0.004181 || Train Loss: 0.6095 || mIoU: 0.4456 || Cost Time: 1:00:33 || Estimated Time: 0:07:26\n",
            "Epochs: 18/20 || Iters: 7580/8500 || Lr: 0.004181 || Train Loss: 0.9288 || mIoU: 0.4446 || Cost Time: 1:00:37 || Estimated Time: 0:07:21\n",
            "Epochs: 18/20 || Iters: 7590/8500 || Lr: 0.004181 || Train Loss: 0.7507 || mIoU: 0.4443 || Cost Time: 1:00:42 || Estimated Time: 0:07:16\n",
            "Epochs: 18/20 || Iters: 7600/8500 || Lr: 0.004181 || Train Loss: 0.7284 || mIoU: 0.4442 || Cost Time: 1:00:45 || Estimated Time: 0:07:11\n",
            "Epochs: 18/20 || Iters: 7610/8500 || Lr: 0.004181 || Train Loss: 0.8059 || mIoU: 0.4446 || Cost Time: 1:00:50 || Estimated Time: 0:07:06\n",
            "Epochs: 18/20 || Iters: 7620/8500 || Lr: 0.004181 || Train Loss: 0.5928 || mIoU: 0.4448 || Cost Time: 1:00:53 || Estimated Time: 0:07:01\n",
            "Epochs: 18/20 || Iters: 7630/8500 || Lr: 0.004181 || Train Loss: 0.8095 || mIoU: 0.4453 || Cost Time: 1:00:58 || Estimated Time: 0:06:57\n",
            "Epochs: 18/20 || Iters: 7640/8500 || Lr: 0.004181 || Train Loss: 0.5657 || mIoU: 0.4449 || Cost Time: 1:01:02 || Estimated Time: 0:06:52\n",
            "Epochs: 18/20 || Iters: 7650/8500 || Lr: 0.004181 || Train Loss: 0.8143 || mIoU: 0.4446 || Cost Time: 1:01:06 || Estimated Time: 0:06:47\n",
            "Epochs: 18/20, Average loss: 0.651, Average mIoU: 0.444, Average pixAcc: 0.904\n",
            "Validation: Average loss: 0.788, Average mIoU: 0.398, Average pixAcc: 0.881\n",
            "Epochs: 19/20 || Iters: 7660/8500 || Lr: 0.003972 || Train Loss: 0.7223 || mIoU: 0.4683 || Cost Time: 1:01:42 || Estimated Time: 0:06:46\n",
            "Epochs: 19/20 || Iters: 7670/8500 || Lr: 0.003972 || Train Loss: 0.6585 || mIoU: 0.4584 || Cost Time: 1:01:46 || Estimated Time: 0:06:41\n",
            "Epochs: 19/20 || Iters: 7680/8500 || Lr: 0.003972 || Train Loss: 1.2409 || mIoU: 0.4488 || Cost Time: 1:01:50 || Estimated Time: 0:06:36\n",
            "Epochs: 19/20 || Iters: 7690/8500 || Lr: 0.003972 || Train Loss: 0.7833 || mIoU: 0.4436 || Cost Time: 1:01:54 || Estimated Time: 0:06:31\n",
            "Epochs: 19/20 || Iters: 7700/8500 || Lr: 0.003972 || Train Loss: 0.6388 || mIoU: 0.4409 || Cost Time: 1:01:59 || Estimated Time: 0:06:26\n",
            "Epochs: 19/20 || Iters: 7710/8500 || Lr: 0.003972 || Train Loss: 0.5328 || mIoU: 0.4454 || Cost Time: 1:02:02 || Estimated Time: 0:06:21\n",
            "Epochs: 19/20 || Iters: 7720/8500 || Lr: 0.003972 || Train Loss: 0.7022 || mIoU: 0.4453 || Cost Time: 1:02:07 || Estimated Time: 0:06:16\n",
            "Epochs: 19/20 || Iters: 7730/8500 || Lr: 0.003972 || Train Loss: 0.8333 || mIoU: 0.4381 || Cost Time: 1:02:10 || Estimated Time: 0:06:11\n",
            "Epochs: 19/20 || Iters: 7740/8500 || Lr: 0.003972 || Train Loss: 0.6579 || mIoU: 0.4362 || Cost Time: 1:02:15 || Estimated Time: 0:06:06\n",
            "Epochs: 19/20 || Iters: 7750/8500 || Lr: 0.003972 || Train Loss: 0.4765 || mIoU: 0.4378 || Cost Time: 1:02:19 || Estimated Time: 0:06:01\n",
            "Epochs: 19/20 || Iters: 7760/8500 || Lr: 0.003972 || Train Loss: 0.4382 || mIoU: 0.4378 || Cost Time: 1:02:23 || Estimated Time: 0:05:56\n",
            "Epochs: 19/20 || Iters: 7770/8500 || Lr: 0.003972 || Train Loss: 0.5451 || mIoU: 0.4391 || Cost Time: 1:02:26 || Estimated Time: 0:05:52\n",
            "Epochs: 19/20 || Iters: 7780/8500 || Lr: 0.003972 || Train Loss: 0.4743 || mIoU: 0.4393 || Cost Time: 1:02:31 || Estimated Time: 0:05:47\n",
            "Epochs: 19/20 || Iters: 7790/8500 || Lr: 0.003972 || Train Loss: 0.5862 || mIoU: 0.4404 || Cost Time: 1:02:34 || Estimated Time: 0:05:42\n",
            "Epochs: 19/20 || Iters: 7800/8500 || Lr: 0.003972 || Train Loss: 1.1924 || mIoU: 0.4414 || Cost Time: 1:02:39 || Estimated Time: 0:05:37\n",
            "Epochs: 19/20 || Iters: 7810/8500 || Lr: 0.003972 || Train Loss: 0.7725 || mIoU: 0.4435 || Cost Time: 1:02:42 || Estimated Time: 0:05:32\n",
            "Epochs: 19/20 || Iters: 7820/8500 || Lr: 0.003972 || Train Loss: 0.6956 || mIoU: 0.4436 || Cost Time: 1:02:46 || Estimated Time: 0:05:27\n",
            "Epochs: 19/20 || Iters: 7830/8500 || Lr: 0.003972 || Train Loss: 0.6637 || mIoU: 0.4437 || Cost Time: 1:02:51 || Estimated Time: 0:05:22\n",
            "Epochs: 19/20 || Iters: 7840/8500 || Lr: 0.003972 || Train Loss: 0.7780 || mIoU: 0.4424 || Cost Time: 1:02:55 || Estimated Time: 0:05:17\n",
            "Epochs: 19/20 || Iters: 7850/8500 || Lr: 0.003972 || Train Loss: 0.5912 || mIoU: 0.4427 || Cost Time: 1:02:59 || Estimated Time: 0:05:12\n",
            "Epochs: 19/20 || Iters: 7860/8500 || Lr: 0.003972 || Train Loss: 0.6297 || mIoU: 0.4413 || Cost Time: 1:03:04 || Estimated Time: 0:05:08\n",
            "Epochs: 19/20 || Iters: 7870/8500 || Lr: 0.003972 || Train Loss: 1.0369 || mIoU: 0.4441 || Cost Time: 1:03:08 || Estimated Time: 0:05:03\n",
            "Epochs: 19/20 || Iters: 7880/8500 || Lr: 0.003972 || Train Loss: 0.6847 || mIoU: 0.4443 || Cost Time: 1:03:12 || Estimated Time: 0:04:58\n",
            "Epochs: 19/20 || Iters: 7890/8500 || Lr: 0.003972 || Train Loss: 0.7199 || mIoU: 0.4435 || Cost Time: 1:03:16 || Estimated Time: 0:04:53\n",
            "Epochs: 19/20 || Iters: 7900/8500 || Lr: 0.003972 || Train Loss: 0.5367 || mIoU: 0.4439 || Cost Time: 1:03:20 || Estimated Time: 0:04:48\n",
            "Epochs: 19/20 || Iters: 7910/8500 || Lr: 0.003972 || Train Loss: 0.6103 || mIoU: 0.4439 || Cost Time: 1:03:24 || Estimated Time: 0:04:43\n",
            "Epochs: 19/20 || Iters: 7920/8500 || Lr: 0.003972 || Train Loss: 0.5330 || mIoU: 0.4440 || Cost Time: 1:03:29 || Estimated Time: 0:04:38\n",
            "Epochs: 19/20 || Iters: 7930/8500 || Lr: 0.003972 || Train Loss: 0.5210 || mIoU: 0.4439 || Cost Time: 1:03:32 || Estimated Time: 0:04:34\n",
            "Epochs: 19/20 || Iters: 7940/8500 || Lr: 0.003972 || Train Loss: 0.4824 || mIoU: 0.4440 || Cost Time: 1:03:36 || Estimated Time: 0:04:29\n",
            "Epochs: 19/20 || Iters: 7950/8500 || Lr: 0.003972 || Train Loss: 0.8849 || mIoU: 0.4438 || Cost Time: 1:03:40 || Estimated Time: 0:04:24\n",
            "Epochs: 19/20 || Iters: 7960/8500 || Lr: 0.003972 || Train Loss: 0.4606 || mIoU: 0.4442 || Cost Time: 1:03:44 || Estimated Time: 0:04:19\n",
            "Epochs: 19/20 || Iters: 7970/8500 || Lr: 0.003972 || Train Loss: 0.7541 || mIoU: 0.4455 || Cost Time: 1:03:48 || Estimated Time: 0:04:14\n",
            "Epochs: 19/20 || Iters: 7980/8500 || Lr: 0.003972 || Train Loss: 0.5120 || mIoU: 0.4456 || Cost Time: 1:03:52 || Estimated Time: 0:04:09\n",
            "Epochs: 19/20 || Iters: 7990/8500 || Lr: 0.003972 || Train Loss: 0.8213 || mIoU: 0.4468 || Cost Time: 1:03:56 || Estimated Time: 0:04:04\n",
            "Epochs: 19/20 || Iters: 8000/8500 || Lr: 0.003972 || Train Loss: 0.7699 || mIoU: 0.4466 || Cost Time: 1:04:01 || Estimated Time: 0:04:00\n",
            "Epochs: 19/20 || Iters: 8010/8500 || Lr: 0.003972 || Train Loss: 0.3821 || mIoU: 0.4458 || Cost Time: 1:04:04 || Estimated Time: 0:03:55\n",
            "Epochs: 19/20 || Iters: 8020/8500 || Lr: 0.003972 || Train Loss: 0.6285 || mIoU: 0.4468 || Cost Time: 1:04:09 || Estimated Time: 0:03:50\n",
            "Epochs: 19/20 || Iters: 8030/8500 || Lr: 0.003972 || Train Loss: 0.7360 || mIoU: 0.4471 || Cost Time: 1:04:13 || Estimated Time: 0:03:45\n",
            "Epochs: 19/20 || Iters: 8040/8500 || Lr: 0.003972 || Train Loss: 0.8409 || mIoU: 0.4473 || Cost Time: 1:04:17 || Estimated Time: 0:03:40\n",
            "Epochs: 19/20 || Iters: 8050/8500 || Lr: 0.003972 || Train Loss: 0.4944 || mIoU: 0.4467 || Cost Time: 1:04:20 || Estimated Time: 0:03:35\n",
            "Epochs: 19/20 || Iters: 8060/8500 || Lr: 0.003972 || Train Loss: 0.6469 || mIoU: 0.4467 || Cost Time: 1:04:25 || Estimated Time: 0:03:31\n",
            "Epochs: 19/20 || Iters: 8070/8500 || Lr: 0.003972 || Train Loss: 0.7816 || mIoU: 0.4463 || Cost Time: 1:04:28 || Estimated Time: 0:03:26\n",
            "Epochs: 19/20, Average loss: 0.654, Average mIoU: 0.445, Average pixAcc: 0.902\n",
            "Validation: Average loss: 0.793, Average mIoU: 0.399, Average pixAcc: 0.879\n",
            "Epochs: 20/20 || Iters: 8080/8500 || Lr: 0.003774 || Train Loss: 0.7985 || mIoU: 0.4103 || Cost Time: 1:05:05 || Estimated Time: 0:03:23\n",
            "Epochs: 20/20 || Iters: 8090/8500 || Lr: 0.003774 || Train Loss: 0.6695 || mIoU: 0.4250 || Cost Time: 1:05:09 || Estimated Time: 0:03:18\n",
            "Epochs: 20/20 || Iters: 8100/8500 || Lr: 0.003774 || Train Loss: 0.5875 || mIoU: 0.4193 || Cost Time: 1:05:13 || Estimated Time: 0:03:13\n",
            "Epochs: 20/20 || Iters: 8110/8500 || Lr: 0.003774 || Train Loss: 0.5956 || mIoU: 0.4361 || Cost Time: 1:05:17 || Estimated Time: 0:03:08\n",
            "Epochs: 20/20 || Iters: 8120/8500 || Lr: 0.003774 || Train Loss: 0.6910 || mIoU: 0.4388 || Cost Time: 1:05:21 || Estimated Time: 0:03:03\n",
            "Epochs: 20/20 || Iters: 8130/8500 || Lr: 0.003774 || Train Loss: 0.5719 || mIoU: 0.4449 || Cost Time: 1:05:25 || Estimated Time: 0:02:58\n",
            "Epochs: 20/20 || Iters: 8140/8500 || Lr: 0.003774 || Train Loss: 0.5548 || mIoU: 0.4630 || Cost Time: 1:05:29 || Estimated Time: 0:02:53\n",
            "Epochs: 20/20 || Iters: 8150/8500 || Lr: 0.003774 || Train Loss: 0.5149 || mIoU: 0.4615 || Cost Time: 1:05:33 || Estimated Time: 0:02:48\n",
            "Epochs: 20/20 || Iters: 8160/8500 || Lr: 0.003774 || Train Loss: 0.6822 || mIoU: 0.4590 || Cost Time: 1:05:37 || Estimated Time: 0:02:44\n",
            "Epochs: 20/20 || Iters: 8170/8500 || Lr: 0.003774 || Train Loss: 0.6500 || mIoU: 0.4566 || Cost Time: 1:05:41 || Estimated Time: 0:02:39\n",
            "Epochs: 20/20 || Iters: 8180/8500 || Lr: 0.003774 || Train Loss: 0.6961 || mIoU: 0.4549 || Cost Time: 1:05:45 || Estimated Time: 0:02:34\n",
            "Epochs: 20/20 || Iters: 8190/8500 || Lr: 0.003774 || Train Loss: 0.6061 || mIoU: 0.4521 || Cost Time: 1:05:49 || Estimated Time: 0:02:29\n",
            "Epochs: 20/20 || Iters: 8200/8500 || Lr: 0.003774 || Train Loss: 0.5499 || mIoU: 0.4531 || Cost Time: 1:05:53 || Estimated Time: 0:02:24\n",
            "Epochs: 20/20 || Iters: 8210/8500 || Lr: 0.003774 || Train Loss: 0.5848 || mIoU: 0.4536 || Cost Time: 1:05:57 || Estimated Time: 0:02:19\n",
            "Epochs: 20/20 || Iters: 8220/8500 || Lr: 0.003774 || Train Loss: 0.9336 || mIoU: 0.4531 || Cost Time: 1:06:02 || Estimated Time: 0:02:14\n",
            "Epochs: 20/20 || Iters: 8230/8500 || Lr: 0.003774 || Train Loss: 0.5563 || mIoU: 0.4500 || Cost Time: 1:06:05 || Estimated Time: 0:02:10\n",
            "Epochs: 20/20 || Iters: 8240/8500 || Lr: 0.003774 || Train Loss: 0.5384 || mIoU: 0.4496 || Cost Time: 1:06:10 || Estimated Time: 0:02:05\n",
            "Epochs: 20/20 || Iters: 8250/8500 || Lr: 0.003774 || Train Loss: 0.4183 || mIoU: 0.4503 || Cost Time: 1:06:13 || Estimated Time: 0:02:00\n",
            "Epochs: 20/20 || Iters: 8260/8500 || Lr: 0.003774 || Train Loss: 0.7258 || mIoU: 0.4508 || Cost Time: 1:06:18 || Estimated Time: 0:01:55\n",
            "Epochs: 20/20 || Iters: 8270/8500 || Lr: 0.003774 || Train Loss: 0.5091 || mIoU: 0.4486 || Cost Time: 1:06:21 || Estimated Time: 0:01:50\n",
            "Epochs: 20/20 || Iters: 8280/8500 || Lr: 0.003774 || Train Loss: 0.8184 || mIoU: 0.4476 || Cost Time: 1:06:25 || Estimated Time: 0:01:45\n",
            "Epochs: 20/20 || Iters: 8290/8500 || Lr: 0.003774 || Train Loss: 0.6164 || mIoU: 0.4508 || Cost Time: 1:06:29 || Estimated Time: 0:01:41\n",
            "Epochs: 20/20 || Iters: 8300/8500 || Lr: 0.003774 || Train Loss: 0.7492 || mIoU: 0.4511 || Cost Time: 1:06:34 || Estimated Time: 0:01:36\n",
            "Epochs: 20/20 || Iters: 8310/8500 || Lr: 0.003774 || Train Loss: 0.4432 || mIoU: 0.4501 || Cost Time: 1:06:38 || Estimated Time: 0:01:31\n",
            "Epochs: 20/20 || Iters: 8320/8500 || Lr: 0.003774 || Train Loss: 0.6587 || mIoU: 0.4495 || Cost Time: 1:06:42 || Estimated Time: 0:01:26\n",
            "Epochs: 20/20 || Iters: 8330/8500 || Lr: 0.003774 || Train Loss: 0.4040 || mIoU: 0.4489 || Cost Time: 1:06:45 || Estimated Time: 0:01:21\n",
            "Epochs: 20/20 || Iters: 8340/8500 || Lr: 0.003774 || Train Loss: 0.6131 || mIoU: 0.4477 || Cost Time: 1:06:50 || Estimated Time: 0:01:16\n",
            "Epochs: 20/20 || Iters: 8350/8500 || Lr: 0.003774 || Train Loss: 0.4847 || mIoU: 0.4476 || Cost Time: 1:06:54 || Estimated Time: 0:01:12\n",
            "Epochs: 20/20 || Iters: 8360/8500 || Lr: 0.003774 || Train Loss: 0.6052 || mIoU: 0.4470 || Cost Time: 1:06:58 || Estimated Time: 0:01:07\n",
            "Epochs: 20/20 || Iters: 8370/8500 || Lr: 0.003774 || Train Loss: 0.5580 || mIoU: 0.4482 || Cost Time: 1:07:02 || Estimated Time: 0:01:02\n",
            "Epochs: 20/20 || Iters: 8380/8500 || Lr: 0.003774 || Train Loss: 0.6552 || mIoU: 0.4466 || Cost Time: 1:07:06 || Estimated Time: 0:00:57\n",
            "Epochs: 20/20 || Iters: 8390/8500 || Lr: 0.003774 || Train Loss: 0.6346 || mIoU: 0.4467 || Cost Time: 1:07:10 || Estimated Time: 0:00:52\n",
            "Epochs: 20/20 || Iters: 8400/8500 || Lr: 0.003774 || Train Loss: 0.5716 || mIoU: 0.4465 || Cost Time: 1:07:14 || Estimated Time: 0:00:48\n",
            "Epochs: 20/20 || Iters: 8410/8500 || Lr: 0.003774 || Train Loss: 0.4519 || mIoU: 0.4476 || Cost Time: 1:07:18 || Estimated Time: 0:00:43\n",
            "Epochs: 20/20 || Iters: 8420/8500 || Lr: 0.003774 || Train Loss: 0.4551 || mIoU: 0.4470 || Cost Time: 1:07:22 || Estimated Time: 0:00:38\n",
            "Epochs: 20/20 || Iters: 8430/8500 || Lr: 0.003774 || Train Loss: 0.4625 || mIoU: 0.4464 || Cost Time: 1:07:26 || Estimated Time: 0:00:33\n",
            "Epochs: 20/20 || Iters: 8440/8500 || Lr: 0.003774 || Train Loss: 0.5665 || mIoU: 0.4469 || Cost Time: 1:07:31 || Estimated Time: 0:00:28\n",
            "Epochs: 20/20 || Iters: 8450/8500 || Lr: 0.003774 || Train Loss: 0.4595 || mIoU: 0.4472 || Cost Time: 1:07:34 || Estimated Time: 0:00:23\n",
            "Epochs: 20/20 || Iters: 8460/8500 || Lr: 0.003774 || Train Loss: 0.6201 || mIoU: 0.4481 || Cost Time: 1:07:39 || Estimated Time: 0:00:19\n",
            "Epochs: 20/20 || Iters: 8470/8500 || Lr: 0.003774 || Train Loss: 0.6230 || mIoU: 0.4479 || Cost Time: 1:07:42 || Estimated Time: 0:00:14\n",
            "Epochs: 20/20 || Iters: 8480/8500 || Lr: 0.003774 || Train Loss: 1.0693 || mIoU: 0.4484 || Cost Time: 1:07:47 || Estimated Time: 0:00:09\n",
            "Epochs: 20/20 || Iters: 8490/8500 || Lr: 0.003774 || Train Loss: 0.7492 || mIoU: 0.4484 || Cost Time: 1:07:50 || Estimated Time: 0:00:04\n",
            "Epochs: 20/20 || Iters: 8500/8500 || Lr: 0.003774 || Train Loss: 1.5267 || mIoU: 0.4469 || Cost Time: 1:07:56 || Estimated Time: 0:00:00\n",
            "Epochs: 20/20, Average loss: 0.651, Average mIoU: 0.447, Average pixAcc: 0.903\n",
            "Validation: Average loss: 0.790, Average mIoU: 0.398, Average pixAcc: 0.879\n",
            "Total training time: 1:08:27.071743 (0.4832s / it)\n"
          ]
        }
      ],
      "source": [
        "load = False\n",
        "load_path = \"/content/drive/MyDrive/multiclass-seg/icnet-scale1-30k/icnet_resnet50_71_0.642_best_model.pth\"\n",
        "\n",
        "model = main(load, load_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PLOT THE LOSSES AND SCORES"
      ],
      "metadata": {
        "id": "ubkvaF8GUkTk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_losses():\n",
        "\n",
        "    path = \"/content/drive/MyDrive/multiclass-seg/icnet-scale1-base-20Epoch\" # CHANGE THIS PER MODEL\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_mIoUs = []\n",
        "    val_mIoUs = []\n",
        "\n",
        "    for item in os.listdir(path):\n",
        "      checkpoint = torch.load(path + \"/\" + item)\n",
        "      train_loss = checkpoint['train_loss']\n",
        "      train_mIoU = checkpoint['train_mIoU']\n",
        "      valid_loss = checkpoint['valid_loss']\n",
        "      valid_mIoU = checkpoint['valid_mIoU']\n",
        "      train_losses.append(train_loss)\n",
        "      val_losses.append(valid_loss)\n",
        "      train_mIoUs.append(train_mIoU)\n",
        "      val_mIoUs.append(valid_mIoU)\n",
        "\n",
        "    epoch_list = checkpoint['current_epoch']\n",
        "    epoch_list = list(range(epoch_list))\n",
        "\n",
        "    plt.plot(epoch_list, train_losses, color='blue', label = \"train\")\n",
        "    plt.plot(epoch_list, val_losses, color='red', label = \"test\")\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.title(\"Loss over 20 epochs\")\n",
        "    plt.show()\n",
        "\n",
        "    print()\n",
        "\n",
        "    plt.plot(epoch_list, train_mIoUs, color='green', label = \"train\")\n",
        "    plt.plot(epoch_list, val_mIoUs, color='purple', label = \"test\")\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('mIoU')\n",
        "    plt.legend()\n",
        "    plt.title(\"mIoU over 20 epochs\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "ljfFaBvrUitC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_losses()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "IcgqTEx6jDa5",
        "outputId": "ae040b8f-1603-44e9-fa57-35b7a6c42700"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "def save_to_drive(source_path):\n",
        "  #print(source_path)\n",
        "  shutil.copy(source_path,\"/content/drive/MyDrive/multiclass-seg/icnet-scale1-base-20Epoch\")"
      ],
      "metadata": {
        "id": "i0EWIDFObPhr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.device_count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9AO3s89Ii0X",
        "outputId": "dee40807-e47e-4c05-bd8c-05d25e041d91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zq3e9IMeo6Qs"
      },
      "outputs": [],
      "source": [
        "\"\"\"Custom losses.\"\"\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.autograd import Variable\n",
        "\n",
        "__all__ = ['ICNetLoss']\n",
        "\n",
        "# TODO: optim function\n",
        "class ICNetLoss(nn.CrossEntropyLoss):\n",
        "    \"\"\"Cross Entropy Loss for ICNet\"\"\"\n",
        "    \n",
        "    def __init__(self, aux_weight=0.4, ignore_index=-1):\n",
        "        super(ICNetLoss, self).__init__(ignore_index=ignore_index)\n",
        "        self.aux_weight = aux_weight\n",
        "\n",
        "    def forward(self, *inputs):\n",
        "        preds, target = tuple(inputs)\n",
        "        inputs = tuple(list(preds) + [target])\n",
        "\n",
        "        pred, pred_sub4, pred_sub8, pred_sub16, target = tuple(inputs)\n",
        "        # [batch, H, W] -> [batch, 1, H, W]\n",
        "        target = target.unsqueeze(1).float()\n",
        "        target_sub4 = F.interpolate(target, pred_sub4.size()[2:], mode='bilinear', align_corners=True).squeeze(1).long()\n",
        "        target_sub8 = F.interpolate(target, pred_sub8.size()[2:], mode='bilinear', align_corners=True).squeeze(1).long()\n",
        "        target_sub16 = F.interpolate(target, pred_sub16.size()[2:], mode='bilinear', align_corners=True).squeeze(\n",
        "            1).long()\n",
        "        loss1 = super(ICNetLoss, self).forward(pred_sub4, target_sub4)\n",
        "        loss2 = super(ICNetLoss, self).forward(pred_sub8, target_sub8)\n",
        "        loss3 = super(ICNetLoss, self).forward(pred_sub16, target_sub16)\n",
        "        #return dict(loss=loss1 + loss2 * self.aux_weight + loss3 * self.aux_weight)\n",
        "        return loss1 + loss2 * self.aux_weight + loss3 * self.aux_weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTxALf5xpFXV"
      },
      "outputs": [],
      "source": [
        "\"\"\"Popular Learning Rate Schedulers\"\"\"\n",
        "from __future__ import division\n",
        "import math\n",
        "import torch\n",
        "\n",
        "from bisect import bisect_right\n",
        "\n",
        "__all__ = ['IterationPolyLR']\n",
        "\n",
        "class IterationPolyLR(torch.optim.lr_scheduler._LRScheduler):\n",
        "    def __init__(self, optimizer, target_lr=0, max_iters=0, power=0.9, last_epoch=-1):\n",
        "        self.target_lr = target_lr\n",
        "        self.max_iters = max_iters\n",
        "        self.power = power\n",
        "        super(IterationPolyLR, self).__init__(optimizer, last_epoch)\n",
        "        \n",
        "    def get_lr(self):\n",
        "        N = self.max_iters \n",
        "        T = self.last_epoch\n",
        "        factor = pow(1 - T / N, self.power)\n",
        "        # https://blog.csdn.net/mieleizhi0522/article/details/83113824\n",
        "        return [self.target_lr + (base_lr - self.target_lr) * factor for base_lr in self.base_lrs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ell2TX3PpG3x"
      },
      "outputs": [],
      "source": [
        "\"\"\"Evaluation Metrics for Semantic Segmentation\"\"\"\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "__all__ = ['SegmentationMetric', 'batch_pix_accuracy', 'batch_intersection_union',\n",
        "           'pixelAccuracy', 'intersectionAndUnion', 'hist_info', 'compute_score']\n",
        "\n",
        "\n",
        "class SegmentationMetric(object):\n",
        "    \"\"\"Computes pixAcc and mIoU metric scores\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, nclass):\n",
        "        super(SegmentationMetric, self).__init__()\n",
        "        self.nclass = nclass\n",
        "        self.reset()\n",
        "\n",
        "    def update(self, preds, labels):\n",
        "        \"\"\"Updates the internal evaluation result.\n",
        "        Parameters\n",
        "        ----------\n",
        "        labels : 'NumpyArray' or list of `NumpyArray`\n",
        "            The labels of the data.\n",
        "        preds : 'NumpyArray' or list of `NumpyArray`\n",
        "            Predicted values.\n",
        "        \"\"\"\n",
        "\n",
        "        def evaluate_worker(self, pred, label):\n",
        "            correct, labeled = batch_pix_accuracy(pred, label)\n",
        "            inter, union = batch_intersection_union(pred, label, self.nclass)\n",
        "\n",
        "            self.total_correct += correct\n",
        "            self.total_label += labeled\n",
        "            if self.total_inter.device != inter.device:\n",
        "                self.total_inter = self.total_inter.to(inter.device)\n",
        "                self.total_union = self.total_union.to(union.device)\n",
        "            self.total_inter += inter\n",
        "            self.total_union += union\n",
        "\n",
        "        if isinstance(preds, torch.Tensor):\n",
        "            evaluate_worker(self, preds, labels)\n",
        "        elif isinstance(preds, (list, tuple)):\n",
        "            for (pred, label) in zip(preds, labels):\n",
        "                evaluate_worker(self, pred, label)\n",
        "        \n",
        "    def get(self):\n",
        "        \"\"\"Gets the current evaluation result.\n",
        "        Returns\n",
        "        -------\n",
        "        metrics : tuple of float\n",
        "            pixAcc and mIoU\n",
        "        \"\"\"\n",
        "        pixAcc = 1.0 * self.total_correct / (2.220446049250313e-16 + self.total_label)  # remove np.spacing(1)\n",
        "        IoU = 1.0 * self.total_inter / (2.220446049250313e-16 + self.total_union)\n",
        "        mIoU = IoU.mean().item()\n",
        "        return pixAcc, mIoU\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"Resets the internal evaluation result to initial state.\"\"\"\n",
        "        self.total_inter = torch.zeros(self.nclass)\n",
        "        self.total_union = torch.zeros(self.nclass)\n",
        "        self.total_correct = 0\n",
        "        self.total_label = 0\n",
        "\n",
        "\n",
        "# pytorch version\n",
        "def batch_pix_accuracy(output, target):\n",
        "    \"\"\"PixAcc\"\"\"\n",
        "    # inputs are numpy array, output 4D, target 3D\n",
        "    predict = torch.argmax(output.long(), 1) + 1\n",
        "    target = target.long() + 1\n",
        "\n",
        "    pixel_labeled = torch.sum(target > 0).item()\n",
        "\n",
        "    try:\n",
        "        pixel_correct = torch.sum((predict == target) * (target > 0)).item()\n",
        "    except:\n",
        "        print(\"predict size: {}, target size: {}, \".format(predict.size(), target.size()))\n",
        "    assert pixel_correct <= pixel_labeled, \"Correct area should be smaller than Labeled\"\n",
        "    return pixel_correct, pixel_labeled\n",
        "    \n",
        "\n",
        "def batch_intersection_union(output, target, nclass):\n",
        "    \"\"\"mIoU\"\"\"\n",
        "    # inputs are numpy array, output 4D, target 3D\n",
        "    mini = 1\n",
        "    maxi = nclass\n",
        "    nbins = nclass\n",
        "    predict = torch.argmax(output, 1) + 1  # [N,H,W] \n",
        "    target = target.float() + 1            # [N,H,W] \n",
        "\n",
        "    predict = predict.float() * (target > 0).float()\n",
        "    intersection = predict * (predict == target).float()\n",
        "    # areas of intersection and union\n",
        "    # element 0 in intersection occur the main difference from np.bincount. set boundary to -1 is necessary.\n",
        "    area_inter = torch.histc(intersection.cpu(), bins=nbins, min=mini, max=maxi)\n",
        "    area_pred = torch.histc(predict.cpu(), bins=nbins, min=mini, max=maxi)\n",
        "    area_lab = torch.histc(target.cpu(), bins=nbins, min=mini, max=maxi)\n",
        "    area_union = area_pred + area_lab - area_inter\n",
        "    assert torch.sum(area_inter > area_union).item() == 0, \"Intersection area should be smaller than Union area\"\n",
        "    return area_inter.float(), area_union.float()\n",
        "\n",
        "\n",
        "def pixelAccuracy(imPred, imLab):\n",
        "    \"\"\"\n",
        "    This function takes the prediction and label of a single image, returns pixel-wise accuracy\n",
        "    To compute over many images do:\n",
        "    for i = range(Nimages):\n",
        "         (pixel_accuracy[i], pixel_correct[i], pixel_labeled[i]) = \\\n",
        "            pixelAccuracy(imPred[i], imLab[i])\n",
        "    mean_pixel_accuracy = 1.0 * np.sum(pixel_correct) / (np.spacing(1) + np.sum(pixel_labeled))\n",
        "    \"\"\"\n",
        "    # Remove classes from unlabeled pixels in gt image.\n",
        "    # We should not penalize detections in unlabeled portions of the image.\n",
        "    pixel_labeled = np.sum(imLab >= 0)\n",
        "    pixel_correct = np.sum((imPred == imLab) * (imLab >= 0))\n",
        "    pixel_accuracy = 1.0 * pixel_correct / pixel_labeled\n",
        "    return (pixel_accuracy, pixel_correct, pixel_labeled)\n",
        "\n",
        "\n",
        "def intersectionAndUnion(imPred, imLab, numClass):\n",
        "    \"\"\"\n",
        "    This function takes the prediction and label of a single image,\n",
        "    returns intersection and union areas for each class\n",
        "    To compute over many images do:\n",
        "    for i in range(Nimages):\n",
        "        (area_intersection[:,i], area_union[:,i]) = intersectionAndUnion(imPred[i], imLab[i])\n",
        "    IoU = 1.0 * np.sum(area_intersection, axis=1) / np.sum(np.spacing(1)+area_union, axis=1)\n",
        "    \"\"\"\n",
        "    # Remove classes from unlabeled pixels in gt image.\n",
        "    # We should not penalize detections in unlabeled portions of the image.\n",
        "    imPred = imPred * (imLab >= 0)\n",
        "\n",
        "    # Compute area intersection:\n",
        "    intersection = imPred * (imPred == imLab)\n",
        "    (area_intersection, _) = np.histogram(intersection, bins=numClass, range=(1, numClass))\n",
        "\n",
        "    # Compute area union:\n",
        "    (area_pred, _) = np.histogram(imPred, bins=numClass, range=(1, numClass))\n",
        "    (area_lab, _) = np.histogram(imLab, bins=numClass, range=(1, numClass))\n",
        "    area_union = area_pred + area_lab - area_intersection\n",
        "    return (area_intersection, area_union)\n",
        "\n",
        "\n",
        "def hist_info(pred, label, num_cls):\n",
        "    assert pred.shape == label.shape\n",
        "    k = (label >= 0) & (label < num_cls)\n",
        "    labeled = np.sum(k)\n",
        "    correct = np.sum((pred[k] == label[k]))\n",
        "\n",
        "    return np.bincount(num_cls * label[k].astype(int) + pred[k], minlength=num_cls ** 2).reshape(num_cls,\n",
        "                                                                                                 num_cls), labeled, correct\n",
        "\n",
        "\n",
        "def compute_score(hist, correct, labeled):\n",
        "    iu = np.diag(hist) / (hist.sum(1) + hist.sum(0) - np.diag(hist))\n",
        "    mean_IU = np.nanmean(iu)\n",
        "    mean_IU_no_back = np.nanmean(iu[1:])\n",
        "    freq = hist.sum(1) / hist.sum()\n",
        "    freq_IU = (iu[freq > 0] * freq[freq > 0]).sum()\n",
        "    mean_pixel_acc = correct / labeled\n",
        "\n",
        "    return iu, mean_IU, mean_IU_no_back, "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Se26g29myvZB"
      },
      "outputs": [],
      "source": [
        "\"\"\"Base segmentation dataset\"\"\"\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image, ImageOps, ImageFilter\n",
        "\n",
        "__all__ = ['SegmentationDataset']\n",
        "\n",
        "class SegmentationDataset(object):\n",
        "    \"\"\"Segmentation Base Dataset\"\"\"\n",
        "\n",
        "    def __init__(self, root, split, mode, transform, base_size=1024, crop_size=720):\n",
        "        \"\"\"\n",
        "        root: string\n",
        "        split: string\n",
        "            'train', 'val' or 'test'\n",
        "        mode:\n",
        "        transform: callable, optional\n",
        "             A function that transforms the image\n",
        "        base_size:\n",
        "            shorter size will be resized between [short_size*0.5, short_size*2.0]\n",
        "        crop_size:\n",
        "            \n",
        "        \"\"\"\n",
        "        super(SegmentationDataset, self).__init__()\n",
        "        self.root = root\n",
        "        self.transform = transform\n",
        "        self.split = split\n",
        "        self.mode = mode if mode is not None else split\n",
        "        self.base_size = base_size\n",
        "        self.crop_size = crop_size\n",
        "\n",
        "    def _val_sync_transform(self, img, mask):\n",
        "        \"\"\"\n",
        "        outsize = self.crop_size\n",
        "        short_size = outsize\n",
        "        w, h = img.size\n",
        "        if w > h:\n",
        "            oh = short_size\n",
        "            ow = int(1.0 * w * oh / h)\n",
        "        else:\n",
        "            ow = short_size\n",
        "            oh = int(1.0 * h * ow / w)\n",
        "        img = img.resize((ow, oh), Image.BILINEAR)\n",
        "        mask = mask.resize((ow, oh), Image.NEAREST)\n",
        "        # center crop\n",
        "        w, h = img.size\n",
        "        x1 = int(round((w - outsize) / 2.))\n",
        "        y1 = int(round((h - outsize) / 2.))\n",
        "        img = img.crop((x1, y1, x1 + outsize, y1 + outsize))\n",
        "        mask = mask.crop((x1, y1, x1 + outsize, y1 + outsize))\n",
        "        \"\"\"\n",
        "        # final transform\n",
        "        img, mask = self._img_transform(img), self._mask_transform(mask)\n",
        "        return img, mask\n",
        "        \n",
        "    def _sync_transform(self, img, mask):\n",
        "        # random mirror\n",
        "        if random.random() < 0.5:\n",
        "            img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "            mask = mask.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "        crop_size = self.crop_size\n",
        "        # random scale (short edge)\n",
        "        short_size = random.randint(int(self.base_size * 0.5), int(self.base_size * 2.0))\n",
        "        w, h = img.size\n",
        "        if h > w:\n",
        "            ow = short_size\n",
        "            oh = int(1.0 * h * ow / w)\n",
        "        else:\n",
        "            oh = short_size\n",
        "            ow = int(1.0 * w * oh / h)\n",
        "        img = img.resize((ow, oh), Image.BILINEAR)\n",
        "        mask = mask.resize((ow, oh), Image.NEAREST)\n",
        "        # pad crop\n",
        "        if short_size < crop_size:\n",
        "            padh = crop_size - oh if oh < crop_size else 0\n",
        "            padw = crop_size - ow if ow < crop_size else 0\n",
        "            img = ImageOps.expand(img, border=(0, 0, padw, padh), fill=0)\n",
        "            mask = ImageOps.expand(mask, border=(0, 0, padw, padh), fill=0)\n",
        "        # random crop crop_size\n",
        "        w, h = img.size\n",
        "        x1 = random.randint(0, w - crop_size)\n",
        "        y1 = random.randint(0, h - crop_size)\n",
        "        img = img.crop((x1, y1, x1 + crop_size, y1 + crop_size))\n",
        "        mask = mask.crop((x1, y1, x1 + crop_size, y1 + crop_size))\n",
        "        # gaussian blur as in PSP\n",
        "        if random.random() < 0.5:\n",
        "            img = img.filter(ImageFilter.GaussianBlur(radius=random.random()))\n",
        "        # final transform\n",
        "        img, mask = self._img_transform(img), self._mask_transform(mask)\n",
        "        return img, mask\n",
        "        \n",
        "    def _img_transform(self, img):\n",
        "        return np.array(img)\n",
        "    \n",
        "    def _mask_transform(self, mask):\n",
        "        return np.array(mask).astype('int32')\n",
        "    \n",
        "    @property\n",
        "    def num_class(self):\n",
        "        \"\"\"Number of categories.\"\"\"\n",
        "        return self.NUM_CLASS\n",
        "\n",
        "    @property\n",
        "    def pred_offset(self):\n",
        "        return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7a68y24kyQ08"
      },
      "outputs": [],
      "source": [
        "# We might not need this. Not sure.\n",
        "\"\"\"Prepare Cityscapes dataset\"\"\"\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "#from .segbase import SegmentationDataset\n",
        "\n",
        "class CityscapesDataset(SegmentationDataset):\n",
        "    NUM_CLASS = 19\n",
        "    IGNORE_INDEX=-1\n",
        "    NAME = \"cityscapes\"\n",
        "\n",
        "     # image transform\n",
        "    \"\"\"\n",
        "        transforms.ToTensor():\n",
        "            Convert a ``PIL Image`` or ``numpy.ndarray`` to tensor.\n",
        "            Converts a PIL Image or numpy.ndarray (H x W x C) in the range\n",
        "            [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0].\n",
        "    \"\"\"\n",
        "    input_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([.485, .456, .406], [.229, .224, .225])])\n",
        "\n",
        "    def __init__(self, root = './datasets/Cityscapes', split='train', base_size=1024, crop_size=720, mode=None, transform=input_transform):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "            root : string\n",
        "                Path to Cityscapes folder. Default is './datasets/Cityscapes'\n",
        "            split: string\n",
        "                'train', 'val' or 'test'\n",
        "            transform : callable, optional\n",
        "                A function that transforms the image\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "        super(CityscapesDataset, self).__init__(root, split, mode, transform,base_size, crop_size)\n",
        "        assert os.path.exists(self.root), \"Error: data root path is wrong!\"\n",
        "        self.images, self.mask_paths = _get_city_pairs(self.root, self.split)\n",
        "        assert (len(self.images) == len(self.mask_paths))\n",
        "        if len(self.images) == 0:\n",
        "            raise RuntimeError(\"Found 0 images in subfolders of:\" + root + \"\\n\")\n",
        "        # _gtFine_labelIds.png\n",
        "        self.valid_classes = [7, 8, 11, 12, 13, 17, 19, 20, 21, 22,\n",
        "                              23, 24, 25, 26, 27, 28, 31, 32, 33]\n",
        "        # reference: https://github.com/mcordts/cityscapesScripts/blob/master/cityscapesscripts/helpers/labels.py\n",
        "        # _gtFine_labelIds.png\n",
        "        self._key = np.array([-1, -1, -1, -1, -1, -1,\n",
        "                              -1, -1, 0, 1, -1, -1,\n",
        "                              2, 3, 4, -1, -1, -1,\n",
        "                              5, -1, 6, 7, 8, 9,\n",
        "                              10, 11, 12, 13, 14, 15,\n",
        "                              -1, -1, 16, 17, 18])\n",
        "        # [-1, ..., 33]\n",
        "        self._mapping = np.array(range(-1, len(self._key) - 1)).astype('int32')\n",
        "        \n",
        "    def _class_to_index(self, mask):\n",
        "        # assert the value\n",
        "        values = np.unique(mask)\n",
        "        for value in values:\n",
        "            assert (value in self._mapping)\n",
        "        # mask_mapping\n",
        "        index = np.digitize(mask.ravel(), self._mapping, right=True)\n",
        "        # key\n",
        "        return self._key[index].reshape(mask.shape)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img = Image.open(self.images[index]).convert('RGB')\n",
        "        if self.mode == 'test':\n",
        "            if self.transform is not None:\n",
        "                img = self.transform(img)\n",
        "            return img, os.path.basename(self.images[index])\n",
        "        mask = Image.open(self.mask_paths[index])\n",
        "        # synchrosized transform\n",
        "        if self.mode == 'train':\n",
        "            img, mask = self._sync_transform(img, mask)\n",
        "        elif self.mode == 'val':\n",
        "            img, mask = self._val_sync_transform(img, mask)\n",
        "        else:\n",
        "            assert self.mode == 'testval'\n",
        "            img, mask = self._img_transform(img), self._mask_transform(mask)\n",
        "        # general normalize and toTensor\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        return img, mask, os.path.basename(self.images[index])\n",
        "        \n",
        "    #mask_transform\n",
        "    def _mask_transform(self, mask):\n",
        "        target = self._class_to_index(np.array(mask).astype('int32'))\n",
        "        return torch.LongTensor(np.array(target).astype('int32'))\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    @property\n",
        "    def pred_offset(self):\n",
        "        return 0\n",
        "\n",
        "\"\"\"\n",
        "Citicapes:\n",
        "- leftImg8bit\n",
        "    - train\n",
        "        - aachen\n",
        "            - aachen_xxx_leftImg8bit.png\n",
        "            - ...\n",
        "        - ....      \n",
        "    - val\n",
        "        - frankfurt\n",
        "            - frankfurt_xxx_leftImg8bit.png\n",
        "            - ...\n",
        "        - ...\n",
        "    - test\n",
        "        - berloin\n",
        "            - berlin_xxx_leftImg8bit.png\n",
        "            - ...\n",
        "        - ...\n",
        "- gtFine \n",
        "    - train\n",
        "        - aachen\n",
        "            - aachen_xxx_gtFine_color.png\n",
        "            - aachen_xxx_gtFine_labelIds.png\n",
        "            - ...\n",
        "        - ....      \n",
        "    - val\n",
        "        - frankfurt\n",
        "            - frankfurt_xxx_gtFine_color.png\n",
        "            - frankfurt_xxx_gtFine_labelIds.png\n",
        "            - ...\n",
        "        - ...\n",
        "    - test\n",
        "        - berloin\n",
        "            - berloin_xxx_gtFine_color.png\n",
        "            - berloin_xxx_gtFine_labelIds.png\n",
        "            - ...\n",
        "        - ...\n",
        "- trainImages.txt\n",
        "- trainLabels.txt\n",
        "- valImages.txt\n",
        "- valLabels.txt\n",
        "- testImages.txt\n",
        "- testLabels.txt\n",
        "\"\"\"\n",
        "\n",
        "def _get_city_pairs(folder, split='train'):\n",
        "    def get_path_pairs(img_folder, mask_folder):\n",
        "        img_paths = []\n",
        "        mask_paths = []\n",
        "        for root, _, files in os.walk(img_folder):\n",
        "            for filename in files:\n",
        "                if filename.endswith('.png'):\n",
        "                    \"\"\"\n",
        "                    Example:\n",
        "                        root = \"./Cityscapes/leftImg8bit/train/aachen\"\n",
        "                        filename = \"aachen_xxx_leftImg8bit.png\"\n",
        "                        imgpath = \"./Cityscapes/leftImg8bit/train/aachen/aachen_xxx_leftImg8bit.png\"\n",
        "                        foldername = \"aachen\"\n",
        "                        maskname = \"aachen_xxx_gtFine_labelIds.png\"\n",
        "                        maskpath = \"./Cityscapes/gtFine/train/aachen/aachen_xxx_gtFine_labelIds\"\n",
        "                    \"\"\"\n",
        "                    imgpath = os.path.join(root, filename)\n",
        "                    foldername = os.path.basename(os.path.dirname(imgpath))\n",
        "                    maskname = filename.replace('leftImg8bit', 'gtFine_labelIds')\n",
        "                    maskpath = os.path.join(mask_folder, foldername, maskname)\n",
        "                    if os.path.isfile(imgpath) and os.path.isfile(maskpath):\n",
        "                        img_paths.append(imgpath)\n",
        "                        mask_paths.append(maskpath)\n",
        "                    else:\n",
        "                        print('cannot find the mask or image:', imgpath, maskpath)\n",
        "        print('Found {} images in the folder {}'.format(len(img_paths), img_folder))\n",
        "        return img_paths, mask_paths\n",
        "\n",
        "    if split in ('train', 'val'):\n",
        "        # \"./Cityscapes/leftImg8bit/train\" or \"./Cityscapes/leftImg8bit/val\"\n",
        "        img_folder = os.path.join(folder, 'leftImg8bit/' + split)\n",
        "        # \"./Cityscapes/gtFine/train\" or \"./Cityscapes/gtFine/val\"\n",
        "        mask_folder = os.path.join(folder, 'gtFine/' + split)\n",
        "        # img_paths,mask_paths = path pairs\n",
        "        img_paths, mask_paths = get_path_pairs(img_folder, mask_folder)\n",
        "        return img_paths, mask_paths\n",
        "    else:\n",
        "        assert split == 'trainval'\n",
        "        print('trainval set')\n",
        "        train_img_folder = os.path.join(folder, 'leftImg8bit/train')\n",
        "        train_mask_folder = os.path.join(folder, 'gtFine/train')\n",
        "        val_img_folder = os.path.join(folder, 'leftImg8bit/val')\n",
        "        val_mask_folder = os.path.join(folder, 'gtFine/val')\n",
        "        train_img_paths, train_mask_paths = get_path_pairs(train_img_folder, train_mask_folder)\n",
        "        val_img_paths, val_mask_paths = get_path_pairs(val_img_folder, val_mask_folder)\n",
        "        img_paths = train_img_paths + val_img_paths\n",
        "        mask_paths = train_mask_paths + val_mask_paths\n",
        "    return img_paths, mask_paths\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TURN IMAGES TO VIDEO(NOT PART OF THE MODEL)"
      ],
      "metadata": {
        "id": "tW_DbolSqGag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "def generate_video():\n",
        "    image_folder = '/content/drive/MyDrive/multiclass-seg/cityscapes/stuttgart_00' # Use the folder\n",
        "    video_name = 'mygeneratedvideo.avi'\n",
        "    os.chdir(\"/content/drive/MyDrive/multiclass-seg\")\n",
        "    images = [img for img in os.listdir(image_folder) if img.endswith(\".jpg\") or\n",
        "             img.endswith(\".jpeg\") or img.endswith(\"png\")]\n",
        "   \n",
        "    fourcc = cv2.VideoWriter_fourcc(*'DIVX') \n",
        "\n",
        "    # Array images should only consider \n",
        "    # the image files ignoring others if any \n",
        "    \n",
        "    frame = cv2.imread(os.path.join(image_folder, images[0]))\n",
        "    \n",
        "    # setting the frame width, height width \n",
        "    # the width, height of first image \n",
        "    height, width, layers = frame.shape\n",
        "\n",
        "    video = cv2.VideoWriter(video_name, fourcc, 30, (width, height))\n",
        "\n",
        "    # Appending the images to the video one by one \n",
        "    for image in images:\n",
        "        video.write(cv2.imread(os.path.join(image_folder,image)))\n",
        "        \n",
        "    # Deallocating memories taken for window creation \n",
        "    cv2.destroyAllWindows()\n",
        "    video.release()  # releasing the video generated \n",
        "    \n",
        "generate_video()"
      ],
      "metadata": {
        "id": "GUCLOTbvEO3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import imageio\n",
        "import os\n",
        "\n",
        "frames = []\n",
        "image_folder = '/content/drive/MyDrive/multiclass-seg/demo_video_pred_masks'\n",
        "for image_name in sorted(os.listdir(image_folder)):\n",
        "    image_path = os.path.join(image_folder, image_name)\n",
        "    frames.append(imageio.imread(image_path))\n",
        "\n",
        "imageio.mimwrite('/content/drive/MyDrive/multiclass-seg/video.mp4', frames, fps=30)"
      ],
      "metadata": {
        "id": "bzrTE0TfF_UC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Turn predicted imaged to masks"
      ],
      "metadata": {
        "id": "ZpjiF_YwFnHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_temp = torch.load(\"/content/drive/MyDrive/multiclass-seg/icnet-90-epoch-model/icnet_resnet50_90_0.644_best_model.pth\", map_location='cuda:0')\n",
        "icnet_temp = ICNet(nclass = 19, backbone='resnet50').to(\"cuda:0\")\n",
        "icnet_temp.load_state_dict(model_temp['model_state_dict'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4DgUKzK4DYJ",
        "outputId": "85518b88-f788-41ca-ae7f-56a9a4b5b4ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_to_drive_file(source_path):\n",
        "  #print(source_path)\n",
        "  shutil.copy(source_path)"
      ],
      "metadata": {
        "id": "aWgMo7kD4esN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# code to get predicted masks and upload to root folder\n",
        "\n",
        "\n",
        "#root = \"/content/drive/MyDrive/multiclass-seg/cityscapes\"\n",
        "imagePath = \"/content/drive/MyDrive/multiclass-seg/cityscapes/stuttgart_00\" \n",
        "\n",
        "\n",
        "#cityPath = imagePath + \"/\" + city\n",
        "for image in os.listdir(imagePath):\n",
        "  path = imagePath + \"/\" + image\n",
        "  img = Image.open(path)\n",
        "  img = transforms.ToTensor()(img)\n",
        "  img = img.unsqueeze(0)\n",
        "  img = img.to(\"cuda\")\n",
        "  pred = icnet_temp(img)[0][0]\n",
        "  pred = pred.cpu().detach().numpy()\n",
        "  scores_matrix = pred.argmax(axis=0)\n",
        "  scores_matrix = scores_matrix.astype(np.uint8)\n",
        "\n",
        "  final_image = plt.imshow(scores_matrix, interpolation='nearest')\n",
        "  #final_image = Image.fromarray(scores_matrix).convert('RGB')\n",
        "\n",
        "  img_path = \"/content/drive/MyDrive/multiclass-seg/demo_video_pred_masks/\" + image\n",
        "\n",
        "  plt.savefig(img_path + image)\n",
        "  #final_image.save(img_path)\n",
        "  #save_to_drive_file(img_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "AoP4Uszf2fkc",
        "outputId": "66050919-6cfe-4ea3-9242-720ad75b4dbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b8fd77127a6146e1aafe6c6b0d31b8c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_567e8cbb8a264147ba7b899f588299a4",
              "IPY_MODEL_81ffcf3cf49b4e2c8cd58194e32f3c3e",
              "IPY_MODEL_f77f89096d594bdb9477e4298653a6a0"
            ],
            "layout": "IPY_MODEL_b69bd6dbba7c41519f5427ae4055c36e"
          }
        },
        "567e8cbb8a264147ba7b899f588299a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d1ce70b87114c8e903b109b76ac4b74",
            "placeholder": "",
            "style": "IPY_MODEL_4c2fc700d9e544f4a3534ce6fadb2392",
            "value": "100%"
          }
        },
        "81ffcf3cf49b4e2c8cd58194e32f3c3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3efb2228a0ff4fb8ac35136cd8c337ac",
            "max": 102540417,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_22ab8e9bde6e427eb622fca0bc0055a5",
            "value": 102540417
          }
        },
        "f77f89096d594bdb9477e4298653a6a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88ad27a0bd714772933961ec28b062ff",
            "placeholder": "",
            "style": "IPY_MODEL_3bd00ffe85ab47eab01c9a56385293a5",
            "value": " 97.8M/97.8M [00:04&lt;00:00, 24.0MB/s]"
          }
        },
        "b69bd6dbba7c41519f5427ae4055c36e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d1ce70b87114c8e903b109b76ac4b74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c2fc700d9e544f4a3534ce6fadb2392": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3efb2228a0ff4fb8ac35136cd8c337ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22ab8e9bde6e427eb622fca0bc0055a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "88ad27a0bd714772933961ec28b062ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bd00ffe85ab47eab01c9a56385293a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}